{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a00a558",
   "metadata": {},
   "source": [
    "# CoDA (uncertainty‑aware) in Sun et al.’s near/far task — Fig. 4c/4i/4j + graph progression\n",
    "\n",
    "This notebook uses an **uncertainty‑aware split rule** for CoDA (posterior/Wilson gating on prospective contingency) and reproduces OSM‑style **Fig. 4c** (transition graph), **Fig. 4i** (final block quantification), **Fig. 4j** (decorrelation order), plus a **progression** of transition graphs across sessions showing how splits propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math, random, collections\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch, Circle\n",
    "\n",
    "# Optional posterior functions (fallback to Wilson if unavailable)\n",
    "try:\n",
    "    from mpmath import betainc, erfcinv\n",
    "    _HAS_MPMATH = True\n",
    "except Exception:\n",
    "    _HAS_MPMATH = False\n",
    "\n",
    "random.seed(0); np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def posterior_prob_p_greater_than(theta: float, success: float, failure: float, alpha0: float=0.5, beta0: float=0.5) -> float:\n",
    "    \"\"\"Posterior probability P(p > theta | Beta(alpha0+success, beta0+failure)). Uses mpmath if available, else returns 0.0 to trigger Wilson fallback.\"\"\"\n",
    "    if not _HAS_MPMATH:\n",
    "        return 0.0\n",
    "    a = alpha0 + max(0.0, float(success))\n",
    "    b = beta0 + max(0.0, float(failure))\n",
    "    cdf = betainc(a, b, 0, theta, regularized=True)\n",
    "    return float(1.0 - cdf)\n",
    "\n",
    "def wilson_lower_bound(phat: float, n: float, confidence: float=0.95) -> float:\n",
    "    \"\"\"Wilson score interval (lower bound) for a proportion at confidence level.\"\"\"\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    if _HAS_MPMATH:\n",
    "        z = float((2.0**0.5) * erfcinv(2*(1.0-confidence)))\n",
    "    else:\n",
    "        z = 1.6448536269514722  # ~95%\n",
    "    denom = 1.0 + (z*z)/n\n",
    "    center = phat + (z*z)/(2.0*n)\n",
    "    adj = z * ((phat*(1.0-phat) + (z*z)/(4.0*n))/n)**0.5\n",
    "    return (center - adj)/denom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94645e",
   "metadata": {},
   "source": [
    "## Sun et al. near/far sequences and Fig. 4 block indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "near = [1,1,1,1,1,1, 2,2,2,2, 1,1,1, 4, 6, 1,1,1, 5,5, 1,1, 7, 0,0,0]\n",
    "far  = [1,1,1,1,1,1, 3,3,3,3, 1,1,1, 4,4, 1,1,1, 5, 6, 1,1, 7, 0,0,0]\n",
    "assert len(near)==len(far)==26\n",
    "\n",
    "preR1_idx = list(range(10,13))   # between indicator and R1 visual\n",
    "preR2_idx = list(range(15,18))   # between (R1/water) and R2 visual\n",
    "\n",
    "def block_indices(rows, cols): return [(r,c) for r in rows for c in cols]\n",
    "offdiag_pairs     = block_indices(preR1_idx, preR2_idx) + block_indices(preR2_idx, preR1_idx)\n",
    "same_preR1_pairs  = block_indices(preR1_idx, preR1_idx)\n",
    "same_preR2_pairs  = block_indices(preR2_idx, preR2_idx)\n",
    "\n",
    "symbols = sorted(set(near)|set(far))\n",
    "symbols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f6011",
   "metadata": {},
   "source": [
    "## CoDA (uncertainty‑aware split rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class UncCfg:\n",
    "    gamma: float = 0.9\n",
    "    lam: float = 0.8\n",
    "    theta_split: float = 0.9\n",
    "    confidence: float = 0.95\n",
    "    alpha0: float = 0.5\n",
    "    beta0: float = 0.5\n",
    "    n_threshold: int = 5\n",
    "    min_presence_episodes: int = 3\n",
    "    min_effective_exposure: float = 10.0\n",
    "    reset_symbols: tuple = (0,)\n",
    "\n",
    "class CoDAUncAgent:\n",
    "    \"\"\"Uncertainty-aware CoDA with contextual eligibility traces and uncertainty-gated splitting.\"\"\"\n",
    "    def __init__(self, obs_symbols, cfg: UncCfg=UncCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.reset_symbols = set(cfg.reset_symbols)\n",
    "        # Latent states\n",
    "        self.states: Dict[int, Dict] = {}  # id -> {'obs':int, 'path':None/'R1'/'R2', 'parent':Optional[int]}\n",
    "        self.obs_to_state_ids: Dict[int, List[int]] = {o: [] for o in obs_symbols}\n",
    "        sid = 0\n",
    "        for o in obs_symbols:\n",
    "            self.states[sid] = {'obs': o, 'path': None, 'parent': None}\n",
    "            self.obs_to_state_ids[o].append(sid)\n",
    "            sid += 1\n",
    "        self._next_sid = sid\n",
    "        \n",
    "        # contingency / exposure\n",
    "        self.us_classes = [4,5]  # visual R1, visual R2\n",
    "        self.co_occ = {s: {u: 0.0 for u in self.us_classes} for s in self.states}  # per-state US counts\n",
    "        self.exposure = {s: 0.0 for s in self.states}                               # total eligibility mass at US times\n",
    "        self.presence_episodes = {s: 0 for s in self.states}                        # episodes containing the state\n",
    "        self.salient = {}  # s -> 'R1'/'R2'\n",
    "    \n",
    "    def _ensure(self, sid):\n",
    "        if sid not in self.co_occ:\n",
    "            self.co_occ[sid] = {u: 0.0 for u in self.us_classes}\n",
    "            self.exposure[sid] = 0.0\n",
    "            self.presence_episodes[sid] = 0\n",
    "    \n",
    "    def _clone_state(self, orig_state_id: int, path: str) -> int:\n",
    "        orig = self.states[orig_state_id]\n",
    "        cid = self._next_sid\n",
    "        self.states[cid] = {'obs': orig['obs'], 'path': path, 'parent': orig_state_id}\n",
    "        self.obs_to_state_ids[orig['obs']].append(cid)\n",
    "        self._ensure(cid)\n",
    "        self._next_sid += 1\n",
    "        return cid\n",
    "    \n",
    "    def _select_state_for_obs(self, obs: int, context: Optional[str]) -> int:\n",
    "        cands = self.obs_to_state_ids[obs]\n",
    "        if context is not None:\n",
    "            for sid in cands:\n",
    "                if self.states[sid]['path'] == context:\n",
    "                    return sid\n",
    "        for sid in cands:\n",
    "            if self.states[sid]['path'] is None:\n",
    "                return sid\n",
    "        return cands[0]\n",
    "    \n",
    "    def run_episode(self, obs_seq: List[int], learn=True):\n",
    "        context = None\n",
    "        latent_seq = []\n",
    "        visited = set()\n",
    "        for obs in obs_seq:\n",
    "            sid = self._select_state_for_obs(obs, context)\n",
    "            latent_seq.append(sid)\n",
    "            visited.add(sid)\n",
    "            if sid in self.salient:\n",
    "                context = self.salient[sid]\n",
    "            if obs in self.reset_symbols:\n",
    "                context = None\n",
    "        \n",
    "        if not learn:\n",
    "            return latent_seq\n",
    "        \n",
    "        # presence gate\n",
    "        for sid in visited:\n",
    "            self.presence_episodes[sid] = self.presence_episodes.get(sid, 0) + 1\n",
    "        \n",
    "        # US events: visual R1 (4), visual R2 (5)\n",
    "        us_positions = {4: [i for i,o in enumerate(obs_seq) if o==4],\n",
    "                        5: [i for i,o in enumerate(obs_seq) if o==5]}\n",
    "        \n",
    "        # contextual eligibility accumulation\n",
    "        for u, pos_list in us_positions.items():\n",
    "            for t_us in pos_list:\n",
    "                e = np.zeros(self._next_sid, dtype=float)\n",
    "                for t in range(t_us+1):\n",
    "                    sid = latent_seq[t]\n",
    "                    e *= (self.cfg.gamma * self.cfg.lam)\n",
    "                    e[sid] += 1.0\n",
    "                for s_id, val in enumerate(e):\n",
    "                    if val>0 and s_id in self.states:\n",
    "                        self._ensure(s_id)\n",
    "                        self.co_occ[s_id][u] += val\n",
    "                        self.exposure[s_id] += val\n",
    "        \n",
    "        # P(u|s)\n",
    "        P = {}\n",
    "        for s in self.states:\n",
    "            tot = sum(self.co_occ[s][u] for u in self.us_classes)\n",
    "            P[s] = {u: (self.co_occ[s][u]/tot if tot>0 else 0.0) for u in self.us_classes}\n",
    "        \n",
    "        # uncertainty‑aware splitting\n",
    "        newly_salient = []\n",
    "        for s in list(self.states.keys()):\n",
    "            if s in self.salient: \n",
    "                continue\n",
    "            tot = sum(self.co_occ[s][u] for u in self.us_classes)\n",
    "            if tot < self.cfg.n_threshold: \n",
    "                continue\n",
    "            if self.presence_episodes.get(s,0) < self.cfg.min_presence_episodes:\n",
    "                continue\n",
    "            if self.exposure.get(s,0.0) < self.cfg.min_effective_exposure:\n",
    "                continue\n",
    "            u_star = max(self.us_classes, key=lambda u: P[s][u])\n",
    "            success = self.co_occ[s][u_star]\n",
    "            failure = tot - success\n",
    "            phat = success / (tot if tot>0 else 1.0)\n",
    "            pass_test = False\n",
    "            post = posterior_prob_p_greater_than(self.cfg.theta_split, success, failure,\n",
    "                                                 self.cfg.alpha0, self.cfg.beta0)\n",
    "            if post == 0.0:\n",
    "                lb = wilson_lower_bound(phat, tot, confidence=self.cfg.confidence)\n",
    "                pass_test = (lb > self.cfg.theta_split)\n",
    "            else:\n",
    "                pass_test = (post >= self.cfg.confidence)\n",
    "            if pass_test:\n",
    "                path = 'R1' if u_star==4 else 'R2'\n",
    "                self.salient[s] = path\n",
    "                newly_salient.append((s, path))\n",
    "        \n",
    "        # propagate: clone immediate successors following each cue occurrence\n",
    "        for s, path in newly_salient:\n",
    "            context=None\n",
    "            for t, obs in enumerate(obs_seq[:-1]):\n",
    "                sid = self._select_state_for_obs(obs, context)\n",
    "                if sid == s:\n",
    "                    nxt_obs = obs_seq[t+1]\n",
    "                    cands = self.obs_to_state_ids[nxt_obs]\n",
    "                    if not any(self.states[c]['path']==path for c in cands):\n",
    "                        self._clone_state(cands[0], path)\n",
    "                if sid in self.salient:\n",
    "                    context = self.salient[sid]\n",
    "                if obs_seq[t+1] in self.reset_symbols:\n",
    "                    context = None\n",
    "        \n",
    "        return latent_seq\n",
    "    \n",
    "    # analysis helpers\n",
    "    def encode_sequence(self, obs_seq: List[int]) -> np.ndarray:\n",
    "        lat = self.run_episode(obs_seq, learn=False)\n",
    "        S = self._next_sid\n",
    "        X = np.zeros((len(lat), S), dtype=float)\n",
    "        for t, sid in enumerate(lat):\n",
    "            X[t, sid] = 1.0\n",
    "        return X[:, :self._next_sid]\n",
    "    \n",
    "    def near_far_corr(self, near_seq, far_seq) -> np.ndarray:\n",
    "        A = self.encode_sequence(near_seq); B = self.encode_sequence(far_seq)\n",
    "        C = np.zeros((A.shape[0], B.shape[0]))\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(B.shape[0]):\n",
    "                a = A[i]; b = B[j]\n",
    "                if np.allclose(a,0) or np.allclose(b,0):\n",
    "                    C[i,j] = 0.0\n",
    "                else:\n",
    "                    a0 = a - a.mean(); b0 = b - b.mean()\n",
    "                    denom = (np.linalg.norm(a0)*np.linalg.norm(b0))\n",
    "                    C[i,j] = (a0@b0)/denom if denom>0 else 0.0\n",
    "        return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e90e452",
   "metadata": {},
   "source": [
    "## Train across sessions; cache matrices (for Fig. 4i/4j) and checkpoints (for progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_RUNS   = 8\n",
    "SESSIONS = 9\n",
    "TRIALS_PER_SESSION = 80\n",
    "THRESH   = 0.3\n",
    "\n",
    "def block_mean(C, pairs): \n",
    "    return float(np.mean([C[i,j] for (i,j) in pairs])) if pairs else np.nan\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "all_final_blocks = []\n",
    "all_time_to_thr  = []\n",
    "mat_by_session   = {s: [] for s in [1,3,4,9]}\n",
    "checkpoint_sessions = [1,3,4,9]\n",
    "demo_checkpoints = {}\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    agent = CoDAUncAgent(obs_symbols=sorted(set(near)|set(far)), cfg=UncCfg())\n",
    "    tt = {'offdiag': None, 'preR2': None, 'preR1': None}\n",
    "    for session in range(1, SESSIONS+1):\n",
    "        episodes = [near]*(TRIALS_PER_SESSION//2) + [far]*(TRIALS_PER_SESSION//2)\n",
    "        rng.shuffle(episodes)\n",
    "        for ep in episodes:\n",
    "            agent.run_episode(ep, learn=True)\n",
    "        C = agent.near_far_corr(near, far)\n",
    "        if session in mat_by_session:\n",
    "            mat_by_session[session].append(C)\n",
    "        if run==0 and session in checkpoint_sessions:\n",
    "            # stash a lightweight snapshot (shallow copies)\n",
    "            snap = CoDAUncAgent(obs_symbols=sorted(set(near)|set(far)), cfg=agent.cfg)\n",
    "            snap.states = {k: v.copy() for k,v in agent.states.items()}\n",
    "            snap._next_sid = agent._next_sid\n",
    "            snap.obs_to_state_ids = {k: list(v) for k,v in agent.obs_to_state_ids.items()}\n",
    "            snap.co_occ = {k: dict(v) for k,v in agent.co_occ.items()}\n",
    "            snap.exposure = dict(agent.exposure)\n",
    "            snap.presence_episodes = dict(agent.presence_episodes)\n",
    "            snap.salient = dict(agent.salient)\n",
    "            demo_checkpoints[session] = snap\n",
    "        \n",
    "        b_off = block_mean(C, offdiag_pairs)\n",
    "        b_r2  = block_mean(C, same_preR2_pairs)\n",
    "        b_r1  = block_mean(C, same_preR1_pairs)\n",
    "        if tt['offdiag'] is None and b_off < THRESH: tt['offdiag'] = session\n",
    "        if tt['preR2']  is None and b_r2  < THRESH: tt['preR2']  = session\n",
    "        if tt['preR1']  is None and b_r1  < THRESH: tt['preR1']  = session\n",
    "    \n",
    "    # final bars\n",
    "    C_final = agent.near_far_corr(near, far)\n",
    "    all_final_blocks.append((run, block_mean(C_final, offdiag_pairs),\n",
    "                                  block_mean(C_final, same_preR2_pairs),\n",
    "                                  block_mean(C_final, same_preR1_pairs)))\n",
    "    def norm(x): return x/SESSIONS if x is not None else np.nan\n",
    "    all_time_to_thr.append((run, norm(tt['offdiag']), norm(tt['preR2']), norm(tt['preR1'])))\n",
    "\n",
    "blocks_df = pd.DataFrame(all_final_blocks, columns=['run','offdiag','preR2','preR1']).set_index('run')\n",
    "times_df  = pd.DataFrame(all_time_to_thr,  columns=['run','offdiag_t','preR2_t','preR1_t']).set_index('run')\n",
    "\n",
    "display(blocks_df.describe())\n",
    "display(times_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690798d",
   "metadata": {},
   "source": [
    "## Fig. 4c — ring layout (clean) and **progression** of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06589c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def canonical_latents(agent, seq):\n",
    "    lat = agent.run_episode(seq, learn=False)\n",
    "    out = []\n",
    "    for t,(obs,sid) in enumerate(zip(seq, lat)):\n",
    "        if obs==0: break\n",
    "        out.append((t, obs, sid, agent.states[sid]['path']))\n",
    "    return out\n",
    "\n",
    "def ring_positions(T: int, r_base=1.0, r_near=1.12, r_far=0.88, start_angle=np.pi/2):\n",
    "    pos_by_t = {}\n",
    "    for t in range(T):\n",
    "        theta = start_angle - 2*np.pi*(t / max(T,1))\n",
    "        pos_by_t[t] = {\n",
    "            'base': (r_base*np.cos(theta), r_base*np.sin(theta)),\n",
    "            'R1':   (r_near*np.cos(theta), r_near*np.sin(theta)),\n",
    "            'R2':   (r_far*np.cos(theta),  r_far*np.sin(theta)),\n",
    "        }\n",
    "    return pos_by_t\n",
    "\n",
    "def draw_ring_graph(ax, agent, title=None, alpha_grey=0.35, key_only=True):\n",
    "    near_lat = canonical_latents(agent, near)\n",
    "    far_lat  = canonical_latents(agent, far)\n",
    "    T = max(len(near_lat), len(far_lat))\n",
    "    pos = ring_positions(T)\n",
    "\n",
    "    # Node palette\n",
    "    col_node = {None:'#cfcfcf','R1':'#ff9bb0','R2':'#8fbff5'}\n",
    "    col_edge_near = '#d64b5a'\n",
    "    col_edge_far  = '#2f6db3'\n",
    "    \n",
    "    # Draw nodes on three rings; grey corridor nodes at low alpha\n",
    "    def draw_nodes(lat_seq):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            x, y = pos[t][ring]\n",
    "            alpha = alpha_grey if obs==1 else 0.95\n",
    "            circ = Circle((x,y), radius=0.045, facecolor=col_node[path], edgecolor='white', lw=0.7, alpha=alpha)\n",
    "            ax.add_patch(circ)\n",
    "            if key_only and obs in (2,3,4,5,6,7):\n",
    "                lbl = f'{obs if obs not in (2,3) else (\"2N\" if obs==2 else \"3F\")}'\n",
    "                ax.text(x, y+0.08, lbl, ha='center', va='bottom', fontsize=7, color='k', alpha=0.9)\n",
    "\n",
    "    draw_nodes(near_lat)\n",
    "    draw_nodes(far_lat)\n",
    "\n",
    "    # Draw edges as short chords between consecutive time indices on each ring\n",
    "    def draw_edges(lat_seq, edge_color):\n",
    "        for i in range(len(lat_seq)-1):\n",
    "            t, obs, sid, path = lat_seq[i]\n",
    "            t2, obs2, sid2, path2 = lat_seq[i+1]\n",
    "            ring = 'base' if path is None else path\n",
    "            ring2= 'base' if path2 is None else path2\n",
    "            x1,y1 = pos[t][ring];   x2,y2 = pos[t2][ring2]\n",
    "            arr = FancyArrowPatch((x1,y1),(x2,y2), arrowstyle='-|>', mutation_scale=6,\n",
    "                                  lw=1.4, color=edge_color, alpha=0.9, shrinkA=2, shrinkB=2)\n",
    "            ax.add_patch(arr)\n",
    "\n",
    "    draw_edges(near_lat, '#d64b5a')\n",
    "    draw_edges(far_lat,  '#2f6db3')\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    if title: ax.set_title(title)\n",
    "\n",
    "# Single snapshot (final)\n",
    "final_session = max([s for s in [1,3,4,9] if s in demo_checkpoints])\n",
    "fig, ax = plt.subplots(figsize=(8,3.2), constrained_layout=True)\n",
    "draw_ring_graph(ax, demo_checkpoints[final_session], title=\"CoDA (uncertainty‑aware) — final transition graph (Fig. 4c style)\")\n",
    "plt.show()\n",
    "\n",
    "# Progression panels\n",
    "fig, axes = plt.subplots(1, len(demo_checkpoints), figsize=(4.5*len(demo_checkpoints),3.2), constrained_layout=True)\n",
    "for ax, s in zip(axes, sorted(demo_checkpoints.keys())):\n",
    "    draw_ring_graph(ax, demo_checkpoints[s], title=f\"Session {s}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96280091",
   "metadata": {},
   "source": [
    "### Near–far correlation matrices (mean across runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c37dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_sessions = [1,3,4,9]\n",
    "mean_mats = {s: np.mean(mat_by_session[s], axis=0) for s in check_sessions}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(check_sessions), figsize=(4.5*len(check_sessions),4), constrained_layout=True)\n",
    "vmin, vmax = -0.1, 1.0\n",
    "for ax, s in zip(axes, check_sessions):\n",
    "    im = ax.imshow(mean_mats[s], vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
    "    ax.set_title(f\"Session {s}\")\n",
    "    ax.set_xlabel(\"Far position index\")\n",
    "    ax.set_ylabel(\"Near position index\")\n",
    "fig.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423d60f",
   "metadata": {},
   "source": [
    "## Fig. 4i and Fig. 4j — OSM‑style bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cd75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fig. 4i\n",
    "means = blocks_df.mean(); ses = blocks_df.sem()\n",
    "labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels)); y = [means[l] for l in labels]; yerr = [ses[l] for l in labels]\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(labels)\n",
    "ax.set_ylim(0,1.0)\n",
    "ax.set_ylabel(\"Mean correlation (final)\")\n",
    "ax.set_title(\"CoDA (uncertainty‑aware) — Fig. 4i analogue\")\n",
    "for i,val in enumerate(y): ax.text(i, val+0.03, f\"{val:.2f}\", ha='center', fontsize=9)\n",
    "plt.show()\n",
    "\n",
    "# Fig. 4j\n",
    "means_t = times_df.mean(skipna=True); ses_t = times_df.sem(skipna=True)\n",
    "labels_t = ['offdiag_t','preR2_t','preR1_t']; disp = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels_t)); y = [means_t[l] for l in labels_t]; yerr = [ses_t[l] for l in labels_t]\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(disp)\n",
    "ax.set_ylim(0,1.05)\n",
    "ax.set_ylabel(\"Fraction of training (first corr < 0.3)\")\n",
    "ax.set_title(\"CoDA (uncertainty‑aware) — Fig. 4j analogue\")\n",
    "for i,val in enumerate(y): ax.text(i, min(1.02, val+0.04), f\"{val:.2f}\", ha='center', fontsize=9)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
