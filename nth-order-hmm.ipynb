{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_hmm_transition_graph(T, niter=0,\n",
    "                              highlight_node=-1, highlight_node_2=-1,\n",
    "                              threshold=0.01, save=False, savename='img'):\n",
    "    \"\"\"\n",
    "    Plot the HMM's transition matrix as a directed graph, using NetworkX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T : 2D np.array of shape (N, N)\n",
    "        Transition matrix (T[i,j] = P(z_{t+1}=j | z_t=i)).\n",
    "    niter : int\n",
    "        An iteration or epoch number (used in the figure title).\n",
    "    highlight_node : int\n",
    "        Index of a node to highlight in red (default: -1 = none).\n",
    "    highlight_node_2 : int\n",
    "        Index of a node to highlight in yellow (default: -1 = none).\n",
    "    threshold : float\n",
    "        Only plot edges with probability > threshold (to avoid clutter).\n",
    "    save : bool\n",
    "        Whether to save the figure to disk.\n",
    "    savename : str\n",
    "        Filename prefix for saving.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of hidden states\n",
    "    n_state = T.shape[0]\n",
    "\n",
    "    # Initialize a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes (one per hidden state)\n",
    "    for s in range(n_state):\n",
    "        G.add_node(s)\n",
    "\n",
    "    # Edge-adding + edge labels\n",
    "    edge_colors = []\n",
    "    for s in range(n_state):\n",
    "        for s_next in range(n_state):\n",
    "            prob = T[s, s_next]\n",
    "            if prob > threshold:  # filter out very small probabilities\n",
    "                label = f\"p={prob:.2f}\"\n",
    "                G.add_edge(s, s_next, label=label)\n",
    "                # (optional) color all edges the same or by probability\n",
    "                edge_colors.append(\"blue\")\n",
    "\n",
    "    # Layout for the nodes (you can use nx.circular_layout, nx.spring_layout, etc.)\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    # Prepare figure\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Node coloring\n",
    "    colors = []\n",
    "    for node in G.nodes():\n",
    "        if node == highlight_node:\n",
    "            colors.append(\"red\")\n",
    "        elif node == highlight_node_2:\n",
    "            colors.append(\"yellow\")\n",
    "        else:\n",
    "            colors.append(\"lightblue\")\n",
    "\n",
    "    # Draw nodes and labels\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=1200)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_color='black')\n",
    "\n",
    "    # Draw edges\n",
    "    edges = list(G.edges())\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges,\n",
    "                           edge_color=edge_colors,\n",
    "                           arrowstyle='->', arrowsize=20, width=2)\n",
    "\n",
    "    # Edge labels\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        G, pos,\n",
    "        edge_labels=nx.get_edge_attributes(G, 'label'),\n",
    "        font_size=10, label_pos=0.5\n",
    "    )\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"HMM Transition Graph at iteration {niter}\", size=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f\"{savename}_iteration_{niter}.png\", dpi=200)\n",
    "        print(f\"Saved figure to {savename}_iteration_{niter}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_nth_order_observations(sequence, n):\n",
    "    \"\"\"\n",
    "    Convert a single sequence of discrete observations into an n-th order 'super-observation' sequence.\n",
    "    \n",
    "    E.g., if sequence = [2, 5, 5, 1] and n=2,\n",
    "    we create pairs:\n",
    "      (2, 5), (5, 5), (5, 1)\n",
    "    Then we map each pair to a unique integer ID (so we can use it in a MultinomialHMM).\n",
    "    \n",
    "    Returns: \n",
    "      - X: a 1D numpy array of encoded observations \n",
    "    \"\"\"\n",
    "    if len(sequence) < n:\n",
    "        return np.array([])  # not enough data to form even one super-observation\n",
    "    \n",
    "    # Create a sliding window of size n\n",
    "    # Example: n=2 => [(seq[0], seq[1]), (seq[1], seq[2]), ...]\n",
    "    windows = [tuple(sequence[i:i+n]) for i in range(len(sequence) - n + 1)]\n",
    "    \n",
    "    # We must map each unique window to a unique integer.\n",
    "    # We'll do this globally below, so just return the list of tuples for now.\n",
    "    return windows\n",
    "\n",
    "def encode_super_observations(all_windows):\n",
    "    \"\"\"\n",
    "    Given a list of lists of 'super-observations' (tuples),\n",
    "    map each unique tuple to a unique integer code.\n",
    "    \n",
    "    Returns:\n",
    "      - X_cat: a concatenated 1D numpy array of encoded observations\n",
    "      - lengths: a list for each sequence length (required by hmmlearn for multiple sequences)\n",
    "      - mapping_dict: the dictionary that maps each tuple to an integer ID\n",
    "    \"\"\"\n",
    "    # Flatten all super-observation tuples across all sequences\n",
    "    flattened = [obs for seq in all_windows for obs in seq]\n",
    "    unique_obs = list(set(flattened))\n",
    "    \n",
    "    # Create a mapping from tuple -> integer\n",
    "    mapping_dict = {obs_tuple: i for i, obs_tuple in enumerate(unique_obs)}\n",
    "    \n",
    "    # Encode each sequence\n",
    "    encoded_sequences = []\n",
    "    lengths = []\n",
    "    for seq in all_windows:\n",
    "        encoded_seq = [mapping_dict[tup] for tup in seq]\n",
    "        encoded_sequences.append(encoded_seq)\n",
    "        lengths.append(len(encoded_seq))\n",
    "    \n",
    "    # Concatenate into one big array (hmmlearn’s fit expects a 2D array of shape (n_samples, 1))\n",
    "    X_cat = np.concatenate([np.array(es) for es in encoded_sequences])\n",
    "    X_cat = X_cat.reshape(-1, 1)  # shape (total_length, 1)\n",
    "    \n",
    "    return X_cat, lengths, mapping_dict\n",
    "\n",
    "def train_nth_order_hmm(\n",
    "    sequences, n=2, hidden_states_range=[2, 3, 4, 5], \n",
    "    max_iter=100, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    sequences: list of lists, each an integer-coded sequence of observations\n",
    "    n: order of the Markov model\n",
    "    hidden_states_range: list of possible numbers of hidden states to try\n",
    "    max_iter: maximum EM iterations\n",
    "    \"\"\"\n",
    "    # 1. Create n-th order super-observations for each sequence\n",
    "    all_windows = [create_nth_order_observations(seq, n) for seq in sequences]\n",
    "    \n",
    "    # 2. Encode these super-observations into integers\n",
    "    X_cat, lengths, mapping = encode_super_observations(all_windows)\n",
    "    \n",
    "    best_model = None\n",
    "    best_bic = float(\"inf\")\n",
    "    best_num_states = None\n",
    "    \n",
    "    # We'll do a simple model selection loop over number of hidden states\n",
    "    for n_states in hidden_states_range:\n",
    "        # Create and fit a MultinomialHMM\n",
    "        model = hmm.MultinomialHMM(\n",
    "            n_components=n_states, \n",
    "            n_iter=max_iter, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        model.fit(X_cat, lengths=lengths)\n",
    "        \n",
    "        # Compute the log-likelihood on the training data\n",
    "        log_likelihood = model.score(X_cat, lengths=lengths)\n",
    "        \n",
    "        # Number of parameters for a MultinomialHMM:\n",
    "        #   ~ n_states - 1 (initial state distribution) \n",
    "        #   + n_states*(n_states - 1) (transition matrix) \n",
    "        #   + n_states*(num_observation_symbols - 1) (emission matrix)\n",
    "        # This is approximate. For a fully correct count, see your HMM’s parameterization.\n",
    "        num_obs_symbols = len(mapping) \n",
    "        n_params = (n_states - 1) \\\n",
    "                   + n_states*(n_states - 1) \\\n",
    "                   + n_states*(num_obs_symbols - 1)\n",
    "        \n",
    "        # BIC = -2 * log(L) + n_params * log(N)\n",
    "        # where N is total number of data points\n",
    "        N = X_cat.shape[0]\n",
    "        bic = -2 * log_likelihood + n_params * np.log(N)\n",
    "        \n",
    "        print(f\"States={n_states}, LogLik={log_likelihood:.2f}, BIC={bic:.2f}\")\n",
    "        \n",
    "        if bic < best_bic:\n",
    "            best_bic = bic\n",
    "            best_model = model\n",
    "            best_num_states = n_states\n",
    "    \n",
    "    print(f\"\\nBest model: {best_num_states} hidden states, BIC={best_bic:.2f}\")\n",
    "    return best_model, mapping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States=2, LogLik=-0.00, BIC=81.45\n",
      "States=3, LogLik=0.00, BIC=133.58\n",
      "States=4, LogLik=0.00, BIC=192.23\n",
      "States=5, LogLik=0.00, BIC=257.39\n",
      "\n",
      "Best model: 2 hidden states, BIC=81.45\n",
      "\n",
      "Learned Transition Matrix:\n",
      "[[0.87827377 0.12172623]\n",
      " [0.99887354 0.00112646]]\n",
      "\n",
      "Learned Emission Matrix (rows = hidden states, columns = super-observation symbols):\n",
      "[[1.]\n",
      " [1.]]\n",
      "\n",
      "Decoded hidden state sequence for new data:\n",
      "[1 0 0 0]\n",
      "Log-likelihood of that sequence: -0.45\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Example Usage\n",
    "# ---------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "# Suppose we have discrete sequences of observations (actions/states) coded as integers\n",
    "# For instance, \"actions\" might be 0..5, or 0..10, etc.\n",
    "# We’ll create a small dummy dataset:\n",
    "sequences = [\n",
    "    [2, 2, 5, 1, 1, 5, 3, 2],\n",
    "    [2, 5, 5, 1, 2, 2],\n",
    "    [1, 1, 5, 5, 5, 3, 2, 2, 1],\n",
    "    [2, 2, 5, 3, 3, 1, 5],\n",
    "]\n",
    "\n",
    "# Train a 2nd-order HMM, trying 2..5 hidden states\n",
    "best_model, obs_mapping = train_nth_order_hmm(sequences, n=2, hidden_states_range=[2, 3, 4, 5])\n",
    "\n",
    "# After training, 'best_model' has your HMM parameters\n",
    "# e.g., transition matrix:\n",
    "print(\"\\nLearned Transition Matrix:\")\n",
    "print(best_model.transmat_)\n",
    "\n",
    "print(\"\\nLearned Emission Matrix (rows = hidden states, columns = super-observation symbols):\")\n",
    "print(best_model.emissionprob_)\n",
    "\n",
    "# If you want to decode a new sequence, do:\n",
    "new_sequence = [2, 5, 1, 1, 5]\n",
    "new_windows = create_nth_order_observations(new_sequence, n=2)\n",
    "new_encoded = [obs_mapping[tup] for tup in new_windows]  # map to integers\n",
    "X_test = np.array(new_encoded).reshape(-1,1)\n",
    "\n",
    "log_prob, hidden_state_seq = best_model.decode(X_test, algorithm=\"viterbi\")\n",
    "print(\"\\nDecoded hidden state sequence for new data:\")\n",
    "print(hidden_state_seq)\n",
    "print(f\"Log-likelihood of that sequence: {log_prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure to my_hmm_graph_iteration_1.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxrklEQVR4nO3de5yWdYH///cwB0DkpAIqguc8ZSgeE0sJH6vbprukW62pCFJmSrat1ea3UrNt222VTO2XbYhH1lCrVcNDutCWx3TxkOYhRUART+CJMzP374/ZmXVkQOAzw8zA8/l4zCO7r/u+rs913/fc3K+5TlWVSqUSAACAAt06egAAAEDXJywAAIBiwgIAACgmLAAAgGLCAgAAKCYsAACAYsICAAAoJiwAAIBiwgIAACgmLKAVO+ywQ6qqqnLFFVes8X6HH354qqqqcu6557a4fcaMGamqqmr+mTlz5hrns9deezXfd/z48S2mPf/88y3m9ctf/nKN8/qrv/qr5vseccQRa7xvk3fPf21/Dj/88LWad2fV9NrNmDFjgz62IzzzzDP52te+lgMPPDADBgxIbW1t+vbtmz333DMnnHBCpkyZkiVLlnT0MNfKueee2+rvXFd08sknr9XnzMbiiiuuSFVVVU4++eSOHsoaTZs2Leeee26OPvrobLvtts2feS+88EJHDw06vZqOHgBsCi6//PJcfPHFrU6777778sQTT6zTvEaPHt3qtBdffDG33377Oo9vzJgxq9w2f/785nm1Nn333Xdf5+V0Beeee27OO++8nHPOOV3+y+vKlSvz9a9/PT/84Q/T0NCQPn365IADDsjAgQOzZMmSzJo1K1OmTMm1116bgQMH5u67784uu+zS0cPuMtrrvXLFFVdk7NixGTNmTJeJjueffz477rhjtt9++zz//PMdPZwixx9/fN58882OHgZ0ScIC2tHQoUOzdOnSTJkyJf/2b/+W7t27r3Kfyy+/PElywAEH5A9/+MNq51VdXZ299947t912W+bPn5+tt956lftceeWVqa+vf995vVdrX15mzJjRHBZd5cvNurjqqquyePHiDB06dIM+dkM64YQT8vOf/zx9+vTJxIkTc9JJJ6WmpuXH/ssvv5zLLrssF1xwQV577TVhsQH98z//c/7xH/8x22yzTUcPZYMYPXp0Dj744PTt27ejh7JGn/zkJ7Prrrtm+PDhGT58eAYOHNjRQ4Iuw65Q0I5qa2tzwgknZMGCBfnVr361yvTFixfnuuuuy+DBg3PkkUe+7/zGjRuXlStX5sorr2x1+uTJk9OjR48cf/zxpUPf6A0dOjS77757Nttssw362A1l0qRJ+fnPf566urrcddddGTdu3CpRkSSDBg3Kt7/97Tz++OPZfvvtO2Ckm65tttkmu+++e6f/ot1W+vbtm913373Th9Tll1+eb3zjGznyyCMzYMCAjh4OdCnCAtrZuHHjkvzflol3u/766/P222/npJNOSnV19fvO67Of/Wy6d++eyZMnrzLtt7/9bf785z9n9OjR6devX/G41+Td+7nPmTMnp5xySoYMGZLa2toW+0//4he/yPjx4/PBD34w/fv3T48ePbLjjjtm3Lhxeeqpp1qd97v3O581a1ZOPPHEbL311unevXt23nnnfPOb38yyZctWeVxDQ0N++tOfZsSIEenXr19qa2szcODADBs2LBMmTFhl94zWjpOoqqrKeeedlyQ577zzWhxT8u71WtMxFitXrsxPfvKTHHLIIenbt2969OiRXXfdNV/60pfy4osvtrrOTctIkhtvvDGHHnpo+vTpk169emXEiBGZNm1aq49bnUqlku9+97tJktNPPz3777//+z5mu+22W+UL34Z6nR955JF88pOfzIABA9KzZ8986EMfykUXXZT6+vo1jvnVV1/N6aefniFDhqSuri5DhgzJhAkT8sYbb7zv+r7Xuq7D2r5X1qS1Yyx22GGHjB07NknjFsj3O67phhtuyFFHHZUBAwakrq4ugwcPzgknnNDq7pVNx2vtsMMOqa+vz4UXXph99903m2++efP7L0meeOKJnHPOORkxYkQGDx6curq6bLnlljniiCMyderUVtdjxx13TJLMnj17leOxmrzfMRYPPPBAPvWpT2XbbbdNXV1dBg4cmKOPPjq/+c1v3vf5W5fPCqD92BUK2tlee+2VAw88MHfeeWfmzp2bIUOGNE+bNGlSkmTs2LG59tpr33deW2yxRf76r/86U6dOzd13350RI0asMq9x48ZtsIMMn3nmmey7776pq6vLiBEjUqlUstVWWzVP/9SnPpXu3btnzz33zMc+9rGsXLkyf/zjHzN58uRMnTo1d9xxRw455JBW5/3www/nzDPPTP/+/XPYYYdlwYIFufvuu/NP//RPefzxx1c5iH38+PHNW2wOPfTQDBgwIAsWLMhzzz2XSy65JKNGjcoOO+ywxvUZM2ZMHn744TzyyCMZNmxY9tlnn+Zphx566Ps+H8uWLcsnPvGJ3HnnnenRo0dGjhyZPn365J577snFF1+c//iP/8jtt9+e4cOHt/r4c845J+eff34OOeSQfPzjH8+TTz6Ze+65J5/4xCdy4403rvbYmvd69NFHm0PqxBNPXKvHrEl7vs4PPPBATjvttGy99dYZNWpUFi5cmBkzZuTLX/5yfv/732fq1Kktvpw2mTt3boYPH54VK1ZkxIgRWbp0ae6+++5ccskluf/++3P33XentrZ2rddxXdeh9L2yOscdd1zuu+++3H333dl5551bzOvdxzWtXLkyn/3sZzN16tR07949++23XwYPHpynn3461157bX7xi1/kF7/4RY466qhVllGpVPLJT34yt912Wz7ykY9kjz32yOOPP948/cILL8ykSZOy++67Z++9906/fv0yZ86cTJ8+PXfddVfuu+++XHjhhS3W95133smNN96YXr165bjjjlvn9f73f//3fOELX0hDQ0P23XffHH744Zk9e3ZuueWW3HLLLTn33HNzzjnntPrYdf2sANpRBVjF9ttvX0lSmTx58hrvd9hhh1WSVM4555wWt0+fPr2SpLLzzjtXKpVK5bLLLqskqXznO99pvs/TTz9dSVL56Ec/WqlUKpVzzjmnkqRyyimntJjXrFmzKkkq1dXVlUqlUrn99tsrSSrjxo1rvs+bb75Z2WyzzSo77LBDpaGhoTJ58uRKksqoUaPW9yloXofWPiaaxpqkcsIJJ1SWLl3a6jyuu+66yjvvvNPitoaGhsqll15aSVLZa6+9Kg0NDS2mjxkzpnne/+///b/KypUrm6c99thjlV69elWSVO65557m22fPnl1JUtluu+0qL7300irjeOKJJyqzZ89ucVvTazd9+vRW1+29r+naPPbrX/968+s+a9as5tuXL19eOeWUUypJKjvuuGNl2bJlLR7XtL79+vWr3Hfffa2O5wMf+MBqx/NekyZNqiSp1NXVtXj+1tWGep2/+MUvVlasWNE87Y9//GNlwIABlSSVn/zkJ6sd08knn9xiTHPmzKkMHjy4kqQyZcqUdVrX9VmHtXmvrEnTc/Dez5mm398xY8as9rFnn312JUnloIMOqjz33HMtpl1//fWV6urqSv/+/SsLFy5svr3ps6Tpd+Wpp55qdd4zZsyoPPvss6vc/uSTT1a22267SpLK/fff32Ja07y333771Y55dev16KOPVmpqaipVVVWVq666qsW0adOmVerq6ipJKnfccUeLaevzWbE+mpYxd+7covnApsCuULAGY8eOXeMpV3/729+u1Xw+85nPZLPNNssVV1yRSqWS5P92jWraVWptHXHEERk6dGimTp2aRYsWJUn+4z/+I4sXL27eNWBD2WKLLXLJJZe0elB6knz6059Or169WtxWVVWVL37xi/nwhz+cxx9/PH/6059afex+++2X888/v8UuYh/84Aeb/wJ/5513Nt/+8ssvJ0mGDx/e6kHte+yxR7sfaL106dJceumlSZKJEye22DpSW1ubH/3oRxk0aFBmzZqVG264odV5fOc738lBBx3U4rZvfOMb6du3b55++unMnTt3rcby2muvJWl8fVrbxW7ZsmU5+eSTV/n52c9+1ur82vN13mabbXLBBRe0OP5jr732yre//e0kyQUXXNDq47bbbrtceumlLcbUtCtU0vL9sTZK1mFDW7BgQSZOnJgePXrkxhtvbN4Nqclxxx2XU089NQsXLsw111zT6jy+973v5QMf+ECr0w477LDstNNOq9y+22675Vvf+laSrPY9vD4uuuiirFy5MqNHj15lC9tf/uVf5vOf/3yS5Ac/+EGrj1+XzwqgfdkVCtZgxIgRazxLzm233db8pXZN+vTpk2OPPTZXX311ZsyYkY9+9KO56qqr0rt37/zt3/7tOo2pW7duGTNmTM4///xMnTo1Y8eOzeWXX55u3bpt8PPDH3HEEe974Omf//zn3Hbbbfnzn/+ct99+u3m/+abn7amnnsqee+65yuM+8YlPtBpJe+yxR5K0OF5h9913T+/evTNt2rT80z/9U44//vhVvmy1twcffDDvvPNOtthiixx99NGrTN9ss83ymc98JhdddFGmT5/e6gH2rT2ue/fu2WmnnTJz5sy8+OKLLXalW18rVqxY7QkA3nsdlaR9X+dPfepT6dGjxyq3jxkzJhMmTMgzzzyTefPmZdttt20xfdSoUa0ePN/a+2Ntre86bGjTp0/PkiVLMmrUqAwePLjV+xx++OH58Y9/nHvuuSdnnHHGKtOPPfbYNS7jnXfeya233pqZM2fmtddey/Lly5MkL730UpKs9tiZ9dF0rNLqPr9OOeWUXHLJJfnd736X+vr6VWJ5XT4rgPYlLGANxo8fv8Yv64cffvhahUXSuGXi6quvzuWXX57Fixdn3rx5GT9+/HqdWWjs2LH57ne/m8svvzwHHnhgHnjggRxxxBEb/Kw+azpmob6+PmeccUYuu+yy5q00rXnrrbdavX11Wxj69OmTpHELQZPevXtn8uTJGTt2bL75zW/mm9/8ZrbZZpscfPDBOeqoo3L88cdn8803X4s1Wn9NX17WFDQ777xzi/u+17qs85o0Hf+wcOHCVr+Ibb755i1ek+9+97vNf4luTXu+zqt7vnr37p0tt9wyr7/+el544YVVwqKtnqukfB02tOeeey5Jctddd73vFspXX311ldsGDhy4xs+dm2++OWPHjs3rr7++2vu05XPxfr87Tb83S5cuzeuvv77K6V/b8r0AlLErFGwghx12WHbeeefceOON+eEPf5hk3XeDarLjjjvm8MMPz+9///t84xvfKJpXiZ49e6522kUXXZSf/OQnGTRoUKZMmZLnn38+S5YsSaVSSaVSyd/93d8lyWq/yHXrtm4fT8cee2zmzp2bq666Kp/73OfSv3///PKXv8ypp56aXXbZJY899tg6za8jrOs6r07TweHLli1rk/Vuz9d5bbT22LZ6rpINsw5tqaGhIUmyyy67ZMyYMWv8GTVq1CqPX9Pr+eKLL+bTn/50Xn/99Xzta1/LI488kjfffDP19fWpVCrN17bpLM9F0rbvBaCMLRawgTSdZvFb3/pW7rzzzuyxxx758Ic/vN7zGzduXKZPn56bb745/fv3X+szBm0oTaelvOyyy3LMMcesMv2ZZ55p82X27ds3J554YvO+1XPnzs2ECRPyn//5nznjjDPW+piY9dG0S8qsWbNWe5+mvzSvbveVtjJs2LBsv/32mT17dq655poWZyxqa6Wv8+qer7fffrv5L+bbbbdd4SjXrCPeqyWadofbbbfd2vzilTfffHOWLFmS0aNH51/+5V9Wmd4ez8XgwYPz7LPP5rnnnssHP/jBVaY3/d706NEjW2yxRZsvH2g7Mh82oJNPPjkDBgzIlltumVNPPbVoXscee2y23377bLnllhk7dmyr+6l3pAULFiRJq7tnPf7443n44YfbfQxDhgxpvtbA2i6vrq4uSePpPNfF/vvvn8033zwLFizITTfdtMr0JUuW5LrrrkuSjBw5cp3mva6qqqpy9tlnJ0kuueSSzJw5s92WVfo6X3/99a1ea+Dqq69O0vhX+fYOsfVdh/V9r7yf95vvqFGjUldXlxkzZuSVV15p02Wv6bmoVCqZMmVKq48reS6ars+xukhqOtHFRz7ykVYv8gh0HsICNqDtttsur7zySl577bWceeaZRfPq2bNnnn/++bz22murPXNOR2o6cPLSSy9t3nUjaTz486STTmrTL2MzZ87Mz3/+8yxZsmSVaTfffHOS1r8otabpr+PvPq//2ujRo0dOP/30JMk//MM/ZPbs2c3TVqxYkTPPPDPz58/PjjvuuF7n+V9Xn/vc53Lcccdl2bJlGTlyZK644opWn/O33347jz766Hovp/R1njdvXs4666wWF8P705/+lO985ztJkr//+79f77GtrfVdh/V9r7yfpvm2dpG7pPFq6RMmTMiiRYty9NFHt7q727Jly3LTTTflySefXKdlNz0XN9xwQ/OB2knjcSjf/va3c88997T6uKYL9M2fP785TtbWmWeemZqamvzqV79a5SxWd9xxRy677LIkyVlnnbVO8wU2POkPtIuzzz47t912W/793/8906dPz/Dhw/PWW2/lt7/9bXbaaaeMHj26zS5cNXv27HzmM59Jz549M3z48AwZMiQrV67MY489lqeeeip1dXX513/917Wa15FHHplevXrlV7/6VQ499NDsuuuuqa6uzogRI5qviLw65513Xh588MHcdddd2WOPPTJy5Mj07t079957b+bMmZMtt9wy119/ffNfd9tTVVVVpkyZksGDB+fiiy/O2LFj8+UvfzkHHHBABg4cmPr6+rzwwgt58MEHs2zZsgwcODCf+MQn1nk5pa/zF77whfzsZz/Lr3/96xx00EFZuHBhpk+fnuXLl2f06NE57bTTSp6Gdl2HkvfKmhx88MHZdtttM3PmzAwfPjx77713amtrs9tuu+WrX/1qkuT73/9+XnrppUyZMiX77LNPhg0blp122ik1NTV54YUX8vDDD2fRokW59dZbW1xY7/0cffTR2W+//fLQQw/lAx/4QA477LD06tUr999/f+bNm5evf/3rre4iVVtbm2OOOSY33HBD9tlnnxx66KHNB4iv7jTGTfbee+9ceumlOe2003LiiSdm4sSJ2X333TN79uzcc889qVQqOffcc/MXf/EX6/Asrr/zzz8/v/71r1e5/Zhjjmn+3R0+fHh+/OMfb5DxQFdiiwXQLg466KA8+OCDOeaYY7Jo0aLcdNNNefbZZzNhwoTce++9zWdsaQsHH3xwvv/972fkyJGZN29ebrrpptxxxx2prq7O6aefnkcffbTVKxC3ZtCgQbn11ltzxBFH5IknnshVV12VSZMmrdXxGd27d89tt92WH//4xxk2bFh+97vf5Ze//GVqa2szYcKEPPLII9lvv/1KV3et1dbW5oc//GGeeOKJnHXWWdlll13yP//zP5k6dWqmTZuW1157LaNHj84111yTWbNmrdeWlNLX+aCDDso999yTD37wg/nNb36TGTNmZNddd82FF1642qtut7X1XYeS98qa1NXV5fbbb88xxxyTF154Iddcc00mTZrU4stuTU1Nrr322kybNi1/8zd/k1deeSU33XRTbr/99ixYsCBHH310pkyZko9+9KPrtOyamprMmDEjZ599dgYPHpy77rorM2bMyL777pt77713jb9Hl112WU499dRUVVXlhhtuyKRJkzJp0qS1Wu7nP//53HPPPTnuuOMyb968TJ06NU8++WQ+/vGP54477ljtVbfbw7PPPpv777+/+afJzJkzm29b3dYk2NRVVTrTqR0A2CScfPLJufLKKzN58uQNfv0VANqHLRYAAEAxYQEAABQTFgAAQDHHWAAAAMVssQAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACK1XT0ADqzSqWSxSvqs3DZiry9bGVWNlRSX6mkqiqprqpKXXW39Otem349alNXrdEAALqkhQuT//mfxp/XX0+WLEnq65OePZNevZI990z22y/ZaaekqqqjR9tpCYv3WLyiPrPfXJxXFy/PG8tWZGVDJUnS2luo8q7/7lnTLVv0qMs2m3fP4N49U93Nmw4AoFNaujS54Ybk5puTe+9N5s5tvL26Oun2nj8WVyrJypWN/927d2NgHH54Mm5cMmTIBh12Z1dVqVQq73+3jVulUskri5fnuYWL8tKiZalKy2hYW02Pq+1WlR37bZYd+26WXnXaDQCgU5g1K7nsssafN95oDIn6+nWfT3V10tCQHH10MmFC8rGPrRokm6BNPizmv7M0D7/yVhavqF/voGhN07y23bx7hg3qm5411W00ZwAA1sm8eckZZyS/+lVjAKxPTLSmpqZxa8ZOOyWXXpocdVTbzLeL2mTDYkV9Qx595a3MfmtJuy6nKo3HYwwb1CdD+/RMlf3yAAA2jEolueqqxq0Kixe3XVC8V7dujVswxo5NJk5M+vZtn+V0cptkWMxftDQPvfRmltc3tNkWirUxqFf3DN/a1gsAgHY3b14yfnxy662NB1xviK+81dXJgAHJ5Mmb5NaLTS4snlnwTh579e0OWXZVktrqqnxkyJbp2722Q8YAALDRe/TRxuMe3nij/bZSrE7T1osLLki+8pUNu+wOtkkdZfLEa293WFQkjcdcrKiv5LdzXs+CJcs7bBwAAButBx5IDj20Y6IiaYyKJPmHf0jOOWfDL78DbTJbLJ56/Z08/lrHRcV71XSrymFDbbkAAGgzjz2WjBjRvsdTrKvvfz/5+tc7ehQbxCYRFnPeXJwH57/Z0cNooWm3qFE7DHDMBQBAqXnzkmHDGi9211miosmVVyYnndTRo2h3G/2uUItX1Gfmy2919DBW0bRb1Mz5b2YTaDsAgPZTqSSf+1zH7f70fk47LZkzp6NH0e426rCoVCp5aP4baeikX9wrSeYvWpa57XzKWwCAjdrVVyfTpv3fFbI7m+XLG6/U3Um/k7aVjTosnn9zSV5dvHyDnlJ2fTz8yltZsrIT1jUAQGfXdPG7znytsJUrk7vuSiZN6uiRtKuNNiyWrazPo690vl2gWlPfUMmjnXB3LQCATu9LX2o8WLsrbA0488zk1Vc7ehTtZqMNi+ffXJL6rvAGS+MuUS++szSLV9hqAQCw1p5/PvnFLzrncRWtWbp0o95qsVGGRaVSybNvLOroYayTqiSzutiYAQA61E9/2nhBuq6ioSG55JKuE0LrqAu9Emtv/qJlWbqyoaOHsU4qSZ57Y3HqG7rGVhYAgA61bFnyk590vS/pL76Y3HprR4+iXWyUYfHswkVpy8N3lixalOt+9IOcP/74jDlozxy7+7b5r1/8vA2X0GhFQyXz3lna5vMFANjo3Hhj4zUr2tCyJF9Psm2SnkkOSvKbNl1Ckurq5OKL23quncJGFxb1DZU2PxPU2wsX5PofT8wLzz2T7Xfbsw3n3FJVkpfeWZo//jH5whcaT3m8yN5RAACruuWWxi/pbejkJBcm+WySi5JUJ/l4kt+35ULq6xvPELV04/tj8kYXFm8uW9Hmp5ftP3Bgfva7h3PZf/0hJ331W2089/9TSfLk7BX50IeSyy5r3Lp3yy3ttjiA1TrzzDOz//77p0ePHhk+fPhaPWbZsmU5/fTTs9VWW6V379457rjj8sorr7S4z9y5c/NXf/VX6dWrV7beeut87WtfS0ND19p1Fegk7r23TXeDeiDJdUn+OckPknw+yX8l2T7J19psKf+rvj559NG2nmuH2+jCYuHSFW0+z9q67uk/YGCbz7c1m29Rnx6bNf4jO3RocuihG2SxAC1UVVXllFNOyWc+85m1fsyXv/zl/PrXv86NN96Y//7v/868efNy7LHHNk9vaGjIxz/+8axcuTL33XdfrrzyylxxxRX59re/3R6rAGzM3nyz8YxQbeiGNG6h+Py7buuR5JQk9yaZ24bLakhS/8ADbTjHzmGjC4s3lq1o0+MrOsLwQ1bkgguSP/0pGTy4o0cDdAUjR47MhAkTMmHChPTr1y8DBgwo+sL+wx/+MKeddlp23HHHtbr/W2+9lcsvvzwTJ07MYYcdln333TeTJ0/O3XffnQf+9x/P22+/PU8++WSuvfba7L333jnyyCNz/vnn59JLL83Kznq1XKBzmjmz7WeZ5ANJ+rzn9gP/938fbsNl1Sd557//uw3n2DlsdGGxcEnb7wq1IVUqyU+vXpGvfCXZbLOOHg3QlVx11VWpra3NH/7wh/zoRz/KhRdemEn/e7700047Lb17917tT58+7/2ndN089NBDWblyZUaNGtV822677ZahQ4fm3nvvTZLcd9992XvvvbPVVls13+fII4/Mm2++mccff7xo+cAmZubMtPVOlC8l2aaV25tum9eGy6pN0udPf2rDOXYONR09gLa2rL6L76tbSf7nkUp+/3xHDwTobD7+8catmFWr2Sw7ZMiQXHjhhUmSXXfdNY8++mgmTpyYU045Jeeff36++tWvttvY5s+fn7q6ulUCZdCgQZk/f37zfQYNGrTK9KZpw4YNazGtUmk8K+O0ae02bKCT23XXZOTIVia8/nrqq6rSrQ0vhrwkSfdWbu/xrultqWrBgjaeY8fb6MKioYtcbXt16uuT39xVyVX/2tEjATqb3/xmzbtHHnzwwS3+/4c//OFceOGFqVQq2WqrrVpsKegqnnwyOfXUjh4F0FFOPHE1YbGkrb/mN55edlkrty991/S2VFmypMvvvv9eG92uUF07Kxr/QteVLiAJdA3tvSvU1ltvneXLl+ett95qcfvLL7+crbfeuvk+L7/88irTm6YBrLV2OJvcNmncHeq9mm7bto2Xt2JZaxnTtW10Wyyqq6qysgvnRbduyRb9k7U8uyOwCende83T77///hb//957782uu+6aqqqqdt8Var/99ktNTU3uuuuujB49Okny1FNPZc6cOTnkkEOSNG5B+d73vpfXXnuteevJHXfckb59+2bPPVu/RlDv3j4PYVO2ww6rmdCjx2omrL99kkxP8lZaHsB9/7umt6X62to2nmPH2/jColtV46H2XVR1TfK5U6pyQZufMBnY2M2ZMydnnXVWPv/5z+ehhx7KJZdckokTJybJOu8K9eyzz+btt9/OSy+9lCVLluSRRx5Jkuy1116pqanJvHnzMmrUqFx99dXZf//906dPn5xyyin5yle+kv79+6d379750pe+lBEjRuSAAw5IkvzFX/xF9txzz5x44on5l3/5l7z00kv51re+lTPOOCO1rfwDW1WVHHRQ8tBDbfDkABuXXr1S1ca7vx+X5N+S/DTJWf9727Ikk9N4Be4hbbq0pLZv3zaeY8fb6MKib/eaLF7R9mUx7ZrLs/jtt7LglcbN9g9O/00WvNy4cewvTxiXXr3LdiN4t6t+Wpvxn0522qnNZglsAk466aQsWbIkBx54YGpqavL3f//3GT9+/HrNa/z48fnvd50KsekiebNmzcrQoUOzYsWKPP3001m8eHHzfSZOnJjq6uocd9xxWbZsWY466qhceumlzdO7deuWW265JaeddloOOeSQ9OrVKyeffHLOO++89VxjYJO1115t/iX2oCR/m+QbSV5JskuSK5M8n2RSGy+r0q1bavbbr43n2vGqKpUufrTzezz5+tv502vvtPnOUF/42IF5dd4LrU77/+68PwO3a7uO/fzhA/PGq9U59dTkRz9q86vVAxuhkSNHZt99920+KxTARm3OnGT77dt8tkuTfCvJNUkWJvlQkvOTHNnWC6quTr7zneTss9t6zh1qo9ti0a9HbbscYfGT/9owV0dc9FZVXp/fePT2j3/ceCaE447bIIsGAOgahgzJ2zU16d3GF9fskeQH//vTrurrk41wi8VGd/6h/t279oEwQ7aqzXnnVaV//2TAgGTvvTt6REBXULW6i1sAbIyqqvKn3r3b/CJ5G9RGGBYb3a5QSXL7c69kUTscZ7Eh7LVV7+y25eapVBpjtmaj26YEANAG/vmfk29+s11OPduuqqqSXXZJnn66o0fS5ja6LRZJsnO/Xh09hPVSlWT7vo2XX6mqEhUAAKt18smNX5i6otNP7+gRtIuNMiyG9u2Zbl3sfVaVZNvePdKjxpHaAADva5ttkk9+suv9JbauLhkzpqNH0S42yrCoq+6WIb17dqnLpFeS7Nxvs44eBgBA13H66UkbH8DdrmpqkhNOSPr16+iRtIuNMiySZKf+vbrU9bc3r6vOlj3rOnoYAABdx0c/muy2W9Kti3ylXblyo90NKtmIw6J/j9oM7dN1tlrsO6ivs7oAAKyLqqrG8/N3hQO4q6uTsWOTffft6JG0m402LJLkQwP7pK6686/ijn03y4DNunf0MAAAup6PfSz5whc691aLbt0aryMwcWJHj6RddeJXoFxddbfst3Xfjh7GGvWs6Za9B/bu6GEAAHRdP/hBsu22nTcuGhqSyZOTvp37e2mpTvrst52tN++R7fv07OhhrNb+2/RLTWf9JQAA6Ao23zy56qrOuUtUt26Nu0AddVRHj6TdbRLfaPcZ1Ddb9ux8V+QeNrCPXaAAANrCyJHJJZd09Chaqq5ODj208TiQTcAmERbV3apyyHZbpF/3mk5zMPdeW/XOzv275oX8AAA6pdNPT773vY4eRaPq6mSffZJbbkl69Ojo0WwQm0RYJEltt275yJAts0Un2HLxoQF9stuWm3f0MAAANj7f+Mb/HSTdUWfc7NYtGTEimT496b3pHEu7yYRFktRWd8uh223ZIcdcVCWpqarKAdv0yy5b2FIBANBuvvzl5LrrGo+9qK7ecMttOm527Njk9ts3qahIkqpKpdKVriPXZua/szQPzX8zy+sbNsiF9AZt1j3Dt+mbnjUb8M0NALApmzcv+dznkmnTGrdetOfX3urqxlPKXnFFcuSR7becTmyTDYskWV7fkMdeeSuz31qSqqRdAqOmqirDBvVpvFifC+ABAGxYlUpyzTWNx18sWtT2Z46qqWm8ova4ccmFF270p5Rdk006LJq8sXRFnntjUea8tSQNhc9GU6BsVtMtO/fvlaF9N0v3LnCRPgCAjdqCBY1bEy6+OHn++f8LgvXR9Mfi7t2Tk05KvvjFZNiwthpplyUs3mV5fUPmvLUkzy1clHdW1CfJ+27JePf0qiSDenXPzv17ZeBmdbZQAAB0Ng0NyZ13NgbG7bcnK1Y03r6m0Gg6TqO+8fthdt+9MSZOOmmT3kLxXsJiNZbXN+SNpSuycOmKvLF0Rd5YtiL1DZXUVyqpqqpKdVXjlb236FGXfj1q079Hbfp0r0k3MQEA0DUsX548/njy0EONPw88kLz6arJ0aWNE9OiR9OrVeNrY/fZr/Bk+PNlii44eeackLAAAgGJ2/gcAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACKCQsAAKCYsAAAAIoJCwAAoJiwAAAAigkLAACgmLAAAACK/f8bfbWY5xsnbwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume you've already fit your model and have 'best_model'\n",
    "trans_mat = best_model.transmat_\n",
    "\n",
    "# Plot it\n",
    "plot_hmm_transition_graph(\n",
    "    T=trans_mat,\n",
    "    niter=1,             # or any iteration number\n",
    "    highlight_node=0,    # e.g., highlight state 0\n",
    "    highlight_node_2=2,  # highlight state 2\n",
    "    threshold=0.05,      # omit edges with probability below 0.05\n",
    "    save=True,\n",
    "    savename='my_hmm_graph'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('cscg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
