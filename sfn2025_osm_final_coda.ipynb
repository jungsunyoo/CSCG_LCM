{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CoDA (uncertainty‑aware) — OSM Fig. 4c/4i/4j with **CSCG‑style color‑coded states**\n",
    "\n",
    "**New:** CSCG‑style node colors (uniform gray arrows), three coloring modes (`blocks`, `state_id`, `obs_step`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch, Circle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def posterior_prob_p_greater_than(theta: float, success: float, failure: float, alpha0: float=0.5, beta0: float=0.5) -> float:\n",
    "    if not _HAS_MPMATH:\n",
    "        return 0.0\n",
    "    a = alpha0 + max(0.0, float(success))\n",
    "    b = beta0 + max(0.0, float(failure))\n",
    "    cdf = betainc(a, b, 0, theta, regularized=True)\n",
    "    return float(1.0 - cdf)\n",
    "\n",
    "def wilson_lower_bound(phat: float, n: float, confidence: float=0.95) -> float:\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    if _HAS_MPMATH:\n",
    "        z = float((2.0**0.5) * erfcinv(2*(1.0-confidence)))\n",
    "    else:\n",
    "        z = 1.6448536269514722\n",
    "    denom = 1.0 + (z*z)/n\n",
    "    center = phat + (z*z)/(2.0*n)\n",
    "    adj = z * ((phat*(1.0-phat) + (z*z)/(4.0*n))/n)**0.5\n",
    "    return (center - adj)/denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "near = [1,1,1,1,1,1, 2,2,2,2, 1,1,1, 4,6, 1,1,1, 5,5, 1,1, 7, 0,0,0]\n",
    "far  = [1,1,1,1,1,1, 3,3,3,3, 1,1,1, 4,4, 1,1,1, 5,6, 1,1, 7, 0,0,0]\n",
    "\n",
    "preR1_idx = list(range(10,13))\n",
    "preR2_idx = list(range(15,18))\n",
    "\n",
    "def block_indices(rows, cols): return [(r,c) for r in rows for c in cols]\n",
    "offdiag_pairs     = block_indices(preR1_idx, preR2_idx) + block_indices(preR2_idx, preR1_idx)\n",
    "same_preR1_pairs  = block_indices(preR1_idx, preR1_idx)\n",
    "same_preR2_pairs  = block_indices(preR2_idx, preR2_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CoDA agent (trial-by-trial) ---\n",
    "# This block replaces the placeholder \"agent\" with a runnable CoDA implementation\n",
    "# consistent with the paper's idea: outcome-conditioned eligibility traces drive\n",
    "# state-splitting (cloning) via prospective contingency, with optional merge via\n",
    "# prospective×retrospective utility.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Set, Tuple\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class UncCfg:\n",
    "    # Eligibility traces (Algorithm 1)\n",
    "    gamma: float = 0.9\n",
    "    lam: float = 0.8\n",
    "\n",
    "    # Split criterion (Algorithm 2)\n",
    "    theta_split: float = 0.8            # split if a state predicts some US with high confidence\n",
    "    confidence: float = 0.95            # one-sided confidence for Wilson bound\n",
    "    n_threshold: int = 5                # minimum effective evidence before testing\n",
    "    min_presence_episodes: int = 3      # minimum number of episodes in which state appeared\n",
    "    min_effective_exposure: float = 10.0# minimum eligibility mass exposure\n",
    "\n",
    "    # Optional merge (paper: utility = PC * RC; merge if < theta_merge)\n",
    "    theta_merge: float = 0.0            # set >0 to enable merges; keep 0.0 to disable in this demo\n",
    "\n",
    "    # Symbols that reset context (e.g., ITI / end markers)\n",
    "    reset_symbols: tuple = (0,)\n",
    "\n",
    "def _z_one_sided(confidence: float) -> float:\n",
    "    \"\"\"Small lookup for common one-sided z; defaults to 0.95 -> 1.64485.\"\"\"\n",
    "    # one-sided z such that P(Z <= z) = confidence\n",
    "    table = {0.90: 1.2815515655446004,\n",
    "             0.95: 1.6448536269514722,\n",
    "             0.975: 1.959963984540054,\n",
    "             0.99: 2.3263478740408408}\n",
    "    # nearest key\n",
    "    key = min(table.keys(), key=lambda k: abs(k - confidence))\n",
    "    return table[key]\n",
    "\n",
    "def wilson_lower_bound_local(phat: float, n: float, confidence: float=0.95) -> float:\n",
    "    \"\"\"One-sided Wilson lower bound for a Bernoulli proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    z = _z_one_sided(confidence)\n",
    "    denom = 1.0 + (z*z)/n\n",
    "    center = phat + (z*z)/(2.0*n)\n",
    "    adj = z * math.sqrt((phat*(1.0-phat) + (z*z)/(4.0*n))/n)\n",
    "    return (center - adj)/denom\n",
    "\n",
    "class CoDAUncAgent:\n",
    "    \"\"\"\n",
    "    CoDA-style state-splitting for a 1D symbol stream.\n",
    "\n",
    "    Latent states are (obs, path) pairs:\n",
    "      - original states have path=None\n",
    "      - clones have path like \"R1\"/\"R2\" (context label) created after a salient cue\n",
    "\n",
    "    Context update:\n",
    "      - if current latent state is a salient cue, set context = salient_path\n",
    "      - if current obs is in reset_symbols, context=None\n",
    "\n",
    "    Learning:\n",
    "      - For each US class u (default: 4 and 5), accumulate outcome-conditioned eligibility\n",
    "        mass co_occ[s][u] from eligibility snapshots at each US occurrence.\n",
    "      - Prospective contingency is P(u | s) = co_occ[s][u] / sum_u co_occ[s][u].\n",
    "      - If max_u P(u|s) is confidently > theta_split, mark s salient and clone successor\n",
    "        observations into the corresponding context path.\n",
    "      - Optional merge can be enabled via theta_merge>0 using utility = PC*RC.\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_symbols, cfg: UncCfg = UncCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.reset_symbols: Set[int] = set(cfg.reset_symbols)\n",
    "\n",
    "        # Define US classes used in this notebook (matches symbol design)\n",
    "        self.us_classes = [4, 5]\n",
    "\n",
    "        # Latent state storage\n",
    "        self.states: Dict[int, Dict] = {}\n",
    "        self.obs_to_state_ids: Dict[int, List[int]] = {o: [] for o in obs_symbols}\n",
    "\n",
    "        sid = 0\n",
    "        for o in obs_symbols:\n",
    "            self.states[sid] = {'obs': o, 'path': None, 'parent': None}\n",
    "            self.obs_to_state_ids[o].append(sid)\n",
    "            sid += 1\n",
    "        self._next_sid = sid\n",
    "\n",
    "        # Outcome-conditioned eligibility accumulators: co_occ[s][u] and exposure[s]\n",
    "        self.co_occ: Dict[int, Dict[int, float]] = {s: {u: 0.0 for u in self.us_classes} for s in self.states}\n",
    "        self.exposure: Dict[int, float] = {s: 0.0 for s in self.states}\n",
    "\n",
    "        # Episode presence counters (for evidence gates + retrospective)\n",
    "        self.presence_episodes: Dict[int, int] = {s: 0 for s in self.states}\n",
    "        self.us_episode_counts: Dict[int, int] = {u: 0 for u in self.us_classes}\n",
    "        self.cs_us_presence: Dict[int, Dict[int, int]] = {s: {u: 0 for u in self.us_classes} for s in self.states}\n",
    "\n",
    "        # Salient cue map: sid -> path label (\"R1\"/\"R2\")\n",
    "        self.salient: Dict[int, str] = {}\n",
    "\n",
    "        # Optional bookkeeping: cue -> clones created (for cleanup/merging if desired)\n",
    "        self.cue_to_clones: Dict[int, Set[int]] = {}\n",
    "\n",
    "    def _ensure(self, sid: int) -> None:\n",
    "        if sid not in self.co_occ:\n",
    "            self.co_occ[sid] = {u: 0.0 for u in self.us_classes}\n",
    "            self.exposure[sid] = 0.0\n",
    "            self.presence_episodes[sid] = 0\n",
    "            self.cs_us_presence[sid] = {u: 0 for u in self.us_classes}\n",
    "\n",
    "    def _clone_state(self, orig_state_id: int, path: str) -> int:\n",
    "        orig = self.states[orig_state_id]\n",
    "        cid = self._next_sid\n",
    "        self.states[cid] = {'obs': orig['obs'], 'path': path, 'parent': orig_state_id}\n",
    "        self.obs_to_state_ids[orig['obs']].append(cid)\n",
    "        self._ensure(cid)\n",
    "        self._next_sid += 1\n",
    "        return cid\n",
    "\n",
    "    def _select_state_for_obs(self, obs: int, context: Optional[str]) -> int:\n",
    "        cands = self.obs_to_state_ids[obs]\n",
    "        if context is not None:\n",
    "            for sid in cands:\n",
    "                if self.states[sid]['path'] == context:\n",
    "                    return sid\n",
    "        # prefer canonical (path=None)\n",
    "        for sid in cands:\n",
    "            if self.states[sid]['path'] is None:\n",
    "                return sid\n",
    "        return cands[0]\n",
    "\n",
    "    def prospective(self, sid: int) -> Dict[int, float]:\n",
    "        \"\"\"Return P(u|sid) over us_classes.\"\"\"\n",
    "        tot = sum(self.co_occ.get(sid, {}).get(u, 0.0) for u in self.us_classes)\n",
    "        if tot <= 0:\n",
    "            return {u: 0.0 for u in self.us_classes}\n",
    "        return {u: self.co_occ[sid][u] / tot for u in self.us_classes}\n",
    "\n",
    "    def retrospective(self, sid: int, u: int) -> float:\n",
    "        \"\"\"Return P(sid present | US=u present) using episode counts.\"\"\"\n",
    "        denom = self.us_episode_counts.get(u, 0)\n",
    "        if denom <= 0:\n",
    "            return 0.0\n",
    "        return float(self.cs_us_presence.get(sid, {}).get(u, 0)) / float(denom)\n",
    "\n",
    "    def _maybe_merge(self) -> None:\n",
    "        \"\"\"Optional: merge by dropping salient status when utility falls below threshold.\"\"\"\n",
    "        if self.cfg.theta_merge <= 0:\n",
    "            return\n",
    "        # for each cue, compute utility = PC * RC for its associated US\n",
    "        for cue in list(self.salient.keys()):\n",
    "            path = self.salient[cue]\n",
    "            u_star = 4 if path == 'R1' else 5\n",
    "            P = self.prospective(cue)\n",
    "            pc = P.get(u_star, 0.0)\n",
    "            rc = self.retrospective(cue, u_star)\n",
    "            if pc * rc < self.cfg.theta_merge:\n",
    "                # Remove salient tag; clones will simply stop being selected because context no longer set.\n",
    "                self.salient.pop(cue, None)\n",
    "\n",
    "    def run_episode(self, obs_seq: List[int], learn: bool = True) -> List[int]:\n",
    "        # --- inference / latent assignment ---\n",
    "        context: Optional[str] = None\n",
    "        latent_seq: List[int] = []\n",
    "        visited: Set[int] = set()\n",
    "\n",
    "        for obs in obs_seq:\n",
    "            sid = self._select_state_for_obs(obs, context)\n",
    "            latent_seq.append(sid)\n",
    "            visited.add(sid)\n",
    "\n",
    "            # context update\n",
    "            if sid in self.salient:\n",
    "                context = self.salient[sid]\n",
    "            if obs in self.reset_symbols:\n",
    "                context = None\n",
    "\n",
    "        if not learn:\n",
    "            return latent_seq\n",
    "\n",
    "        # --- episode-level presence bookkeeping ---\n",
    "        for sid in visited:\n",
    "            self.presence_episodes[sid] = self.presence_episodes.get(sid, 0) + 1\n",
    "\n",
    "        # US present flags for retrospective counts\n",
    "        us_present = {u: any(o == u for o in obs_seq) for u in self.us_classes}\n",
    "        for u, pres in us_present.items():\n",
    "            if pres:\n",
    "                self.us_episode_counts[u] = self.us_episode_counts.get(u, 0) + 1\n",
    "                for sid in visited:\n",
    "                    self._ensure(sid)\n",
    "                    self.cs_us_presence[sid][u] = self.cs_us_presence[sid].get(u, 0) + 1\n",
    "\n",
    "        # --- outcome-conditioned eligibility traces (multi-US version) ---\n",
    "        decay = self.cfg.gamma * self.cfg.lam\n",
    "        trace: Dict[int, float] = {}\n",
    "        snapshots: List[Dict[int, float]] = []\n",
    "        for sid in latent_seq:\n",
    "            # decay\n",
    "            for k in list(trace.keys()):\n",
    "                trace[k] *= decay\n",
    "                if trace[k] < 1e-12:\n",
    "                    trace.pop(k, None)\n",
    "            trace[sid] = trace.get(sid, 0.0) + 1.0\n",
    "            snapshots.append(dict(trace))\n",
    "\n",
    "        # Add eligibility mass to co_occ for each US occurrence\n",
    "        for u in self.us_classes:\n",
    "            positions = [i for i, o in enumerate(obs_seq) if o == u]\n",
    "            for t_us in positions:\n",
    "                snap = snapshots[t_us]\n",
    "                for s_id, val in snap.items():\n",
    "                    self._ensure(s_id)\n",
    "                    self.co_occ[s_id][u] += float(val)\n",
    "                    self.exposure[s_id] += float(val)\n",
    "\n",
    "        # --- cue discovery & splitting (Algorithm 2 spirit) ---\n",
    "        newly_salient: List[Tuple[int, str]] = []\n",
    "        for s in list(self.states.keys()):\n",
    "            if s in self.salient:\n",
    "                continue\n",
    "\n",
    "            tot = sum(self.co_occ[s][u] for u in self.us_classes)\n",
    "            if tot < self.cfg.n_threshold:\n",
    "                continue\n",
    "            if self.presence_episodes.get(s, 0) < self.cfg.min_presence_episodes:\n",
    "                continue\n",
    "            if self.exposure.get(s, 0.0) < self.cfg.min_effective_exposure:\n",
    "                continue\n",
    "\n",
    "            P = self.prospective(s)\n",
    "            u_star = max(self.us_classes, key=lambda u: P[u])\n",
    "            phat = P[u_star]\n",
    "            # Wilson lower bound gate for \"confidently above theta_split\"\n",
    "            lb = wilson_lower_bound_local(phat, tot, self.cfg.confidence)\n",
    "            if lb > self.cfg.theta_split:\n",
    "                path = 'R1' if u_star == 4 else 'R2'\n",
    "                self.salient[s] = path\n",
    "                newly_salient.append((s, path))\n",
    "\n",
    "        # Clone successors for newly salient cues (split)\n",
    "        # Here, \"successor\" is the next observation symbol along the experienced trajectory.\n",
    "        for cue, path in newly_salient:\n",
    "            self.cue_to_clones.setdefault(cue, set())\n",
    "            context = None\n",
    "            for t, obs in enumerate(obs_seq[:-1]):\n",
    "                sid = self._select_state_for_obs(obs, context)\n",
    "                if sid == cue:\n",
    "                    nxt_obs = obs_seq[t + 1]\n",
    "                    cands = self.obs_to_state_ids[nxt_obs]\n",
    "                    if not any(self.states[c]['path'] == path for c in cands):\n",
    "                        # clone the canonical state for nxt_obs (prefer path=None)\n",
    "                        base = next((c for c in cands if self.states[c]['path'] is None), cands[0])\n",
    "                        clone_id = self._clone_state(base, path)\n",
    "                        self.cue_to_clones[cue].add(clone_id)\n",
    "\n",
    "                if sid in self.salient:\n",
    "                    context = self.salient[sid]\n",
    "                if obs_seq[t + 1] in self.reset_symbols:\n",
    "                    context = None\n",
    "\n",
    "        # Optional merge (disabled by default in this notebook)\n",
    "        self._maybe_merge()\n",
    "\n",
    "        return latent_seq\n",
    "\n",
    "    def encode_sequence(self, obs_seq: List[int]) -> np.ndarray:\n",
    "        lat = self.run_episode(obs_seq, learn=False)\n",
    "        S = self._next_sid\n",
    "        X = np.zeros((len(lat), S), dtype=float)\n",
    "        for t, sid in enumerate(lat):\n",
    "            X[t, sid] = 1.0\n",
    "        return X[:, :self._next_sid]\n",
    "\n",
    "    def near_far_corr(self, near_seq, far_seq) -> np.ndarray:\n",
    "        A = self.encode_sequence(near_seq)\n",
    "        B = self.encode_sequence(far_seq)\n",
    "        C = np.zeros((A.shape[0], B.shape[0]))\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(B.shape[0]):\n",
    "                a = A[i]; b = B[j]\n",
    "                if np.allclose(a, 0) or np.allclose(b, 0):\n",
    "                    C[i, j] = 0.0\n",
    "                    continue\n",
    "                a0 = a - a.mean()\n",
    "                b0 = b - b.mean()\n",
    "                den = (np.linalg.norm(a0) * np.linalg.norm(b0))\n",
    "                C[i, j] = (a0 @ b0) / den if den > 0 else 0.0\n",
    "        return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_RUNS=6; SESSIONS=9; TRIALS_PER_SESSION=80; THRESH=0.3\n",
    "def block_mean(C, pairs): \n",
    "    return float(np.mean([C[i,j] for (i,j) in pairs])) if pairs else np.nan\n",
    "rng=np.random.default_rng(123)\n",
    "all_final_blocks=[]; all_time_to_thr=[]; mat_by_session={s:[] for s in [1,3,4,9]}\n",
    "checkpoint_sessions=[1,3,4,9]; demo_checkpoints={}\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    agent=CoDAUncAgent(obs_symbols=sorted(set(near)|set(far)), cfg=UncCfg())\n",
    "    tt={'offdiag':None,'preR2':None,'preR1':None}\n",
    "    for session in range(1, SESSIONS+1):\n",
    "        episodes=[near]*(TRIALS_PER_SESSION//2)+[far]*(TRIALS_PER_SESSION//2)\n",
    "        rng.shuffle(episodes)\n",
    "        for ep in episodes: agent.run_episode(ep, learn=True)\n",
    "        C=agent.near_far_corr(near, far)\n",
    "        if session in mat_by_session: mat_by_session[session].append(C)\n",
    "        if run==0 and session in checkpoint_sessions:\n",
    "            snap=CoDAUncAgent(obs_symbols=sorted(set(near)|set(far)), cfg=agent.cfg)\n",
    "            snap.states={k:v.copy() for k,v in agent.states.items()}\n",
    "            snap._next_sid=agent._next_sid\n",
    "            snap.obs_to_state_ids={k:list(v) for k,v in agent.obs_to_state_ids.items()}\n",
    "            snap.co_occ={k:dict(v) for k,v in agent.co_occ.items()}\n",
    "            snap.exposure=dict(agent.exposure); snap.presence_episodes=dict(agent.presence_episodes)\n",
    "            snap.salient=dict(agent.salient); demo_checkpoints[session]=snap\n",
    "        b_off=block_mean(C,offdiag_pairs); b_r2=block_mean(C,same_preR2_pairs); b_r1=block_mean(C,same_preR1_pairs)\n",
    "        if tt['offdiag'] is None and b_off<THRESH: tt['offdiag']=session\n",
    "        if tt['preR2']  is None and b_r2<THRESH: tt['preR2']=session\n",
    "        if tt['preR1']  is None and b_r1<THRESH: tt['preR1']=session\n",
    "    C_final=agent.near_far_corr(near, far)\n",
    "    all_final_blocks.append((run, block_mean(C_final, offdiag_pairs), block_mean(C_final, same_preR2_pairs), block_mean(C_final, same_preR1_pairs)))\n",
    "    def norm(x): return x/SESSIONS if x is not None else np.nan\n",
    "    all_time_to_thr.append((run, norm(tt['offdiag']), norm(tt['preR2']), norm(tt['preR1'])))\n",
    "\n",
    "blocks_df=pd.DataFrame(all_final_blocks, columns=['run','offdiag','preR2','preR1']).set_index('run')\n",
    "times_df =pd.DataFrame(all_time_to_thr, columns=['run','offdiag_t','preR2_t','preR1_t']).set_index('run')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def canonical_latents(agent, seq):\n",
    "    lat = agent.run_episode(seq, learn=False)\n",
    "    out = []\n",
    "    for t, (obs, sid) in enumerate(zip(seq, lat)):\n",
    "        if obs == 0:\n",
    "            break\n",
    "        out.append((t, obs, sid, agent.states[sid]['path']))\n",
    "    return out\n",
    "\n",
    "\n",
    "def ring_positions(T: int, r_base=1.0, r_near=1.12, r_far=0.88, start_angle=np.pi/2):\n",
    "    pos_by_t = {}\n",
    "    for t in range(T):\n",
    "        theta = start_angle - 2 * np.pi * (t / max(T, 1))\n",
    "        pos_by_t[t] = {\n",
    "            'theta': theta,\n",
    "            'base': (r_base * np.cos(theta), r_base * np.sin(theta)),\n",
    "            'R1': (r_near * np.cos(theta), r_near * np.sin(theta)),\n",
    "            'R2': (r_far * np.cos(theta), r_far * np.sin(theta)),\n",
    "        }\n",
    "    return pos_by_t\n",
    "\n",
    "\n",
    "def build_color_assignments(scheme: str, near_lat, far_lat):\n",
    "    import matplotlib as mpl\n",
    "\n",
    "    colors = {'near': {}, 'far': {}}\n",
    "\n",
    "    def set_color(target, lat_seq, fn):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            target[(t, ring)] = fn(t, obs, sid, ring)\n",
    "\n",
    "    if scheme == 'state_id':\n",
    "        tab20 = mpl.cm.get_cmap('tab20')\n",
    "        set_color(colors['near'], near_lat, lambda t, o, s, ring: tab20(s % 20))\n",
    "        set_color(colors['far'],  far_lat,  lambda t, o, s, ring: tab20(s % 20))\n",
    "\n",
    "    elif scheme == 'obs_step':\n",
    "        hsv = mpl.cm.get_cmap('hsv')\n",
    "        set_color(colors['near'], near_lat, lambda t, o, s, ring: hsv((t % 26) / 26.0))\n",
    "        set_color(colors['far'],  far_lat,  lambda t, o, s, ring: hsv((t % 26) / 26.0))\n",
    "\n",
    "    else:\n",
    "        # Default: color-code by the \"third element\" (latent state id) with overrides\n",
    "        unique_sids = sorted({sid for (_, _, sid, _) in near_lat + far_lat})\n",
    "        cmap = mpl.cm.get_cmap('tab20', max(1, len(unique_sids)))\n",
    "        sid_to_color = {sid: cmap(i % cmap.N) for i, sid in enumerate(unique_sids)}\n",
    "        overrides = {1: '#b3b3b3', 5: '#9467bd', 9: '#6a6a6a', 11: '#000000', 6: '#d62728', 8: '#d62728'}\n",
    "        sid_to_color.update({sid: color for sid, color in overrides.items() if sid in unique_sids})\n",
    "\n",
    "        set_color(colors['near'], near_lat, lambda t, o, s, ring: sid_to_color[s])\n",
    "        set_color(colors['far'],  far_lat,  lambda t, o, s, ring: sid_to_color[s])\n",
    "\n",
    "    return colors\n",
    "\n",
    "\n",
    "def draw_cscg_style_ring(\n",
    "    ax,\n",
    "    agent,\n",
    "    title=None,\n",
    "    scheme='blocks',\n",
    "    close_loop=True,\n",
    "    edge_color='#5a5a5a',\n",
    "    edge_lw=2.2,\n",
    " ):\n",
    "    # --- build sequences and ring geometry ---\n",
    "    near_lat = canonical_latents(agent, near)\n",
    "    far_lat = canonical_latents(agent, far)\n",
    "    T = max(len(near_lat), len(far_lat))\n",
    "    pos = ring_positions(T)\n",
    "\n",
    "    # --- node colors and occupancy ---\n",
    "    node_colors = build_color_assignments(scheme, near_lat, far_lat)\n",
    "    from collections import defaultdict\n",
    "    occupancy = defaultdict(list)\n",
    "    sid_shared = set()\n",
    "    near_by_t = {t: sid for (t, _, sid, _) in near_lat}\n",
    "    far_by_t = {t: sid for (t, _, sid, _) in far_lat}\n",
    "    for t, sid in near_by_t.items():\n",
    "        if far_by_t.get(t) == sid:\n",
    "            sid_shared.add((t, sid))\n",
    "    for label, lat_seq in (('near', near_lat), ('far', far_lat)):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            occupancy[(t, ring)].append((label, sid))\n",
    "\n",
    "    node_positions = {}\n",
    "    offset_mag = 0.07\n",
    "    radial_offset = 0.09\n",
    "    prev_pos = {'near': None, 'far': None}\n",
    "    all_times = sorted({t for (t, _) in occupancy.keys()})\n",
    "    rings_order = ['base', 'R1', 'R2']\n",
    "    force_swap_times = {6, 19}\n",
    "    arrow_mutation = 14.0\n",
    "\n",
    "    for t in all_times:\n",
    "        for ring in rings_order:\n",
    "            key = (t, ring)\n",
    "            if key not in occupancy:\n",
    "                continue\n",
    "            entries = occupancy[key]\n",
    "            base_x, base_y = pos[t][ring]\n",
    "            sids = {sid for (_, sid) in entries}\n",
    "            shared_here = any((t, sid) in sid_shared for (_, sid) in entries)\n",
    "            if len(entries) == 1 or (len(sids) == 1 and shared_here):\n",
    "                for label, sid in entries:\n",
    "                    node_positions[(label, t, ring)] = (base_x, base_y)\n",
    "                    prev_pos[label] = (base_x, base_y)\n",
    "                continue\n",
    "            labels_here = {label for (label, _) in entries}\n",
    "            vx, vy = base_x, base_y\n",
    "            norm = (vx * vx + vy * vy) ** 0.5\n",
    "            if norm == 0.0:\n",
    "                ux, uy = 1.0, 0.0\n",
    "            else:\n",
    "                ux, uy = vx / norm, vy / norm\n",
    "            if len(entries) == 2 and labels_here == {'near', 'far'}:\n",
    "                def assign(sign_map):\n",
    "                    out = {}\n",
    "                    for label, sid in entries:\n",
    "                        direction = radial_offset * sign_map[label]\n",
    "                        out[label] = (base_x + direction * ux, base_y + direction * uy)\n",
    "                    return out\n",
    "\n",
    "                default_map = {'near': 1.0, 'far': -1.0}\n",
    "                swapped_map = {'near': -1.0, 'far': 1.0}\n",
    "\n",
    "                def mapping_cost(mapped):\n",
    "                    cost = 0.0\n",
    "                    for label, (x, y) in mapped.items():\n",
    "                        prev = prev_pos.get(label)\n",
    "                        if prev is None:\n",
    "                            continue\n",
    "                        px, py = prev\n",
    "                        cost += (x - px) * (x - px) + (y - py) * (y - py)\n",
    "                    return cost\n",
    "\n",
    "                opt_default = assign(default_map)\n",
    "                opt_swapped = assign(swapped_map)\n",
    "                if t in force_swap_times:\n",
    "                    chosen = opt_swapped\n",
    "                elif mapping_cost(opt_swapped) < mapping_cost(opt_default):\n",
    "                    chosen = opt_swapped\n",
    "                else:\n",
    "                    chosen = opt_default\n",
    "                for label, coords in chosen.items():\n",
    "                    node_positions[(label, t, ring)] = coords\n",
    "                    prev_pos[label] = coords\n",
    "                continue\n",
    "            if len(entries) == 1:\n",
    "                label, sid = entries[0]\n",
    "                node_positions[(label, t, ring)] = (base_x, base_y)\n",
    "                prev_pos[label] = (base_x, base_y)\n",
    "                continue\n",
    "            if norm == 0.0:\n",
    "                px, py = 0.0, 1.0\n",
    "            else:\n",
    "                px, py = -vy / norm, vx / norm\n",
    "            ordered = sorted(entries, key=lambda item: item[0])\n",
    "            span = len(ordered) - 1\n",
    "            for idx, (label, sid) in enumerate(ordered):\n",
    "                factor = idx - span / 2.0\n",
    "                coords = (base_x + factor * offset_mag * px, base_y + factor * offset_mag * py)\n",
    "                node_positions[(label, t, ring)] = coords\n",
    "                prev_pos[label] = coords\n",
    "\n",
    "    def node_xy(label, t, ring):\n",
    "        return node_positions[(label, t, ring)]\n",
    "\n",
    "    def draw_edges(lat_seq, label, z=1):\n",
    "        for i in range(len(lat_seq) - 1):\n",
    "            t, _, _, p = lat_seq[i]\n",
    "            t2, _, _, p2 = lat_seq[i + 1]\n",
    "            r1 = 'base' if p is None else p\n",
    "            r2 = 'base' if p2 is None else p2\n",
    "            x1, y1 = node_xy(label, t, r1)\n",
    "            x2, y2 = node_xy(label, t2, r2)\n",
    "            ax.add_patch(\n",
    "                FancyArrowPatch(\n",
    "                    (x1, y1),\n",
    "                    (x2, y2),\n",
    "                    arrowstyle='-|>',\n",
    "                    mutation_scale=arrow_mutation,\n",
    "                    lw=edge_lw,\n",
    "                    color=edge_color,\n",
    "                    alpha=0.9,\n",
    "                    shrinkA=2.5,\n",
    "                    shrinkB=2.5,\n",
    "                    zorder=z,\n",
    "                )\n",
    "            )\n",
    "        if close_loop and len(lat_seq) >= 2:\n",
    "            t0, _, _, p0 = lat_seq[0]\n",
    "            tL, _, _, pL = lat_seq[-1]\n",
    "            r0 = 'base' if p0 is None else p0\n",
    "            rL = 'base' if pL is None else pL\n",
    "            x1, y1 = node_xy(label, tL, rL)\n",
    "            x2, y2 = node_xy(label, t0, r0)\n",
    "            ax.add_patch(\n",
    "                FancyArrowPatch(\n",
    "                    (x1, y1),\n",
    "                    (x2, y2),\n",
    "                    arrowstyle='-|>',\n",
    "                    mutation_scale=arrow_mutation,\n",
    "                    lw=edge_lw,\n",
    "                    color=edge_color,\n",
    "                    alpha=0.9,\n",
    "                    shrinkA=2.5,\n",
    "                    shrinkB=2.5,\n",
    "                    zorder=z,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def draw_nodes(lat_seq, label, z=3):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            x, y = node_xy(label, t, ring)\n",
    "            face = node_colors[label].get((t, ring), '#bfbfbf')\n",
    "            ax.add_patch(\n",
    "                Circle(\n",
    "                    (x, y),\n",
    "                    radius=0.065,\n",
    "                    facecolor=face,\n",
    "                    edgecolor='#3a3a3a',\n",
    "                    lw=1.1,\n",
    "                    alpha=0.98,\n",
    "                    zorder=z,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    draw_edges(near_lat, 'near', z=1)\n",
    "    draw_edges(far_lat, 'far', z=1)\n",
    "    draw_nodes(far_lat, 'far', z=3)\n",
    "    draw_nodes(near_lat, 'near', z=4)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(-1.55, 1.55)\n",
    "    ax.set_ylim(-1.55, 1.55)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_lat = canonical_latents(demo_checkpoints[4], near)\n",
    "near_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "far_lat = canonical_latents(demo_checkpoints[4], far)\n",
    "far_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"figures/poster\", exist_ok=True)\n",
    "\n",
    "export_specs = [\n",
    "    (\"svg\", {\"format\": \"svg\"}),\n",
    "    (\"pdf\", {\"format\": \"pdf\"}),\n",
    "    (\"png\", {\"format\": \"png\", \"dpi\": 400})\n",
    "]\n",
    "\n",
    "final_session = max([s for s in [1, 3, 4, 9] if s in demo_checkpoints])\n",
    "fig, ax = plt.subplots(figsize=(7.4, 4.6), constrained_layout=True)\n",
    "draw_cscg_style_ring(\n",
    "    ax,\n",
    "    demo_checkpoints[final_session],\n",
    "    title=\"CoDA — transition graph (CSCG-style colors)\",\n",
    "    scheme='blocks'\n",
    ")\n",
    "for ext, kwargs in export_specs:\n",
    "    fig.savefig(\n",
    "        os.path.join(\"figures\", \"poster\", f\"coda_transition_final_session.{ext}\"),\n",
    "        bbox_inches='tight',\n",
    "        **kwargs\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "for s in sorted(demo_checkpoints.keys()):\n",
    "    fig_s, ax_s = plt.subplots(figsize=(7.4, 4.6), constrained_layout=True)\n",
    "    draw_cscg_style_ring(\n",
    "        ax_s,\n",
    "        demo_checkpoints[s],\n",
    "        title=f\"Session {s}\",\n",
    "        scheme='blocks'\n",
    "    )\n",
    "    for ext, kwargs in export_specs:\n",
    "        fig_s.savefig(\n",
    "            os.path.join(\"figures\", \"poster\", f\"coda_transition_session_{s}.{ext}\"),\n",
    "            bbox_inches='tight',\n",
    "            **kwargs\n",
    "        )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Trajectory of decorrelation during learning (CSCG-style) ===\n",
    "import matplotlib as mpl\n",
    "\n",
    "check_sessions = [1, 3, 4, 9]\n",
    "mean_mats = {s: np.mean(mat_by_session[s], axis=0) for s in check_sessions}\n",
    "\n",
    "# CSCG-style colormap (dark background, warm high values)\n",
    "# 'magma' or 'inferno' gives similar look; both start dark→warm→bright\n",
    "cmap = mpl.cm.get_cmap('magma')\n",
    "\n",
    "# Pre/indicator windows to highlight (indices are inclusive, 0-based)\n",
    "highlight_windows = [(6, 10), (13, 15), (18, 20)]\n",
    "dash_lines = [6, 10, 13, 15, 18, 20]\n",
    "\n",
    "# Make independent figures for each checkpoint session\n",
    "for s in check_sessions:\n",
    "    fig, ax = plt.subplots(figsize=(4.8, 4.8), constrained_layout=True)\n",
    "\n",
    "    last_im = ax.imshow(\n",
    "        mean_mats[s],\n",
    "        vmin=-0.1,\n",
    "        vmax=1.0,\n",
    "        cmap=cmap,\n",
    "        origin='upper',\n",
    "        aspect='equal',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    ny, nx = mean_mats[s].shape\n",
    "    ax.set_xticks(np.arange(-0.5, nx, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, ny, 1), minor=True)\n",
    "    ax.grid(which='minor', color='white', linestyle=':', linewidth=0.4)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(colors='white', labelsize=0, length=0)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    for idx in dash_lines:\n",
    "        if idx <= nx:\n",
    "            ax.axvline(idx - 0.5, color='white', linewidth=1.2, linestyle=(0, (2, 4)))\n",
    "        if idx <= ny:\n",
    "            ax.axhline(idx - 0.5, color='white', linewidth=1.2, linestyle=(0, (2, 4)))\n",
    "\n",
    "    for low, high in highlight_windows:\n",
    "        if high <= min(nx, ny):\n",
    "            x0, x1 = low - 0.5, high - 0.5\n",
    "            y0, y1 = low - 0.5, high - 0.5\n",
    "            ax.plot(\n",
    "                [x0, x1, x1, x0, x0],\n",
    "                [y0, y0, y1, y1, y0],\n",
    "                color='white',\n",
    "                linewidth=2.5\n",
    "            )\n",
    "\n",
    "    fig.patch.set_facecolor('black')\n",
    "    ax.set_facecolor('black')\n",
    "\n",
    "    cbar = fig.colorbar(last_im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"\")\n",
    "    cbar.set_ticks([])\n",
    "    cbar.ax.tick_params(length=0)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fig. 4i\n",
    "means = blocks_df.mean(); ses = blocks_df.sem()\n",
    "labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels)); y = [means[l] for l in labels]; yerr = [ses[l] for l in labels]\n",
    "fig, ax = plt.subplots(figsize=(6.5,4.6))\n",
    "bars = ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(labels)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Mean correlation (final)\")\n",
    "ax.set_title(\"CoDA (uncertainty‑aware) — Fig. 4i analogue\")\n",
    "for i, (b, val) in enumerate(zip(bars, y)):\n",
    "    ax.text(b.get_x()+b.get_width()/2, (val-0.05 if val>0.85 else min(1.02, val+0.05)), f\"{val:.2f}\", ha='center',\n",
    "            va=('top' if val>0.85 else 'bottom'), color=('white' if val>0.85 else 'black'), fontsize=9)\n",
    "fig.tight_layout(); plt.show()\n",
    "\n",
    "# Fig. 4j\n",
    "means_t = times_df.mean(skipna=True); ses_t = times_df.sem(skipna=True)\n",
    "labels_t = ['offdiag_t','preR2_t','preR1_t']; disp = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels_t)); y = [means_t[l] for l in labels_t]; yerr = [ses_t[l] for l in labels_t]\n",
    "fig, ax = plt.subplots(figsize=(6.5,4.6))\n",
    "bars = ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(disp)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Fraction of training (first corr < 0.3)\")\n",
    "ax.set_title(\"CoDA (uncertainty‑aware) — Fig. 4j analogue\")\n",
    "for i, (b, val) in enumerate(zip(bars, y)):\n",
    "    ax.text(b.get_x()+b.get_width()/2, min(1.02, val+0.05), f\"{val:.2f}\", ha='center', va='bottom', fontsize=9)\n",
    "fig.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
