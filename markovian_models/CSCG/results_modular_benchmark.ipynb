{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cscg_actions_orig import *\n",
    "from ged import *\n",
    "from util import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import random\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custom_colors(num_unique_observations):\n",
    "    # Define a fixed set of custom colors as RGB values\n",
    "    predefined_colors = np.array([\n",
    "        [214, 214, 214],\n",
    "        [85, 35, 157],\n",
    "        [253, 252, 144],\n",
    "        [114, 245, 144],\n",
    "        [151, 38, 20],\n",
    "        [239, 142, 192],\n",
    "        [214, 134, 48],\n",
    "        [140, 194, 250],\n",
    "        [72, 160, 162],\n",
    "    ])\n",
    "\n",
    "    # If the number of unique observations is greater than the number of predefined colors,\n",
    "    # cycle through the predefined colors to ensure enough colors are available\n",
    "    if num_unique_observations > len(predefined_colors):\n",
    "        extra_colors_needed = num_unique_observations - len(predefined_colors)\n",
    "        additional_colors = np.tile(predefined_colors, (extra_colors_needed // len(predefined_colors) + 1, 1))\n",
    "        custom_colors = np.vstack((predefined_colors, additional_colors))[:num_unique_observations]\n",
    "    else:\n",
    "        custom_colors = predefined_colors[:num_unique_observations]\n",
    "\n",
    "    return custom_colors\n",
    "\n",
    "\n",
    "# Function to create a lattice graph with variable nodes, observations, and aliased states\n",
    "def create_modular_graph_varied(num_nodes=15, num_observations=10000, num_aliased_states=10, num_modules=3):\n",
    "    if num_nodes < 4:\n",
    "        raise ValueError(\"num_nodes must be at least 4 to allow for meaningful connectivity.\")\n",
    "\n",
    "    if num_nodes < num_modules:\n",
    "        raise ValueError(\"Number of nodes must be at least equal to the number of modules to form a meaningful structure.\")\n",
    "\n",
    "    # Initialize the adjacency matrix\n",
    "    T = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Calculate the size of each module\n",
    "    module_size = num_nodes // num_modules\n",
    "\n",
    "    for module_index in range(num_modules):\n",
    "        module_start = module_index * module_size\n",
    "        # For the last module, extend to the end of the node list\n",
    "        module_end = module_start + module_size if module_index < num_modules - 1 else num_nodes\n",
    "\n",
    "        # Fully connect nodes within the module\n",
    "        for i in range(module_start, module_end):\n",
    "            for j in range(module_start, module_end):\n",
    "                if i != j:\n",
    "                    T[i, j] = 1.0\n",
    "    # Optionally, add sparse inter-module connections\n",
    "    # Example: Connecting last node of one module to first node of the next module\n",
    "    for module_index in range(num_modules - 1):\n",
    "        module_end = (module_index + 1) * module_size - 1\n",
    "        next_module_start = (module_end + 1) % num_nodes\n",
    "        T[module_end, next_module_start] = 1.0\n",
    "        T[next_module_start, module_end] = 1.0\n",
    "    # connect first and last module\n",
    "    T[0, num_nodes-1] = 1.0\n",
    "    T[num_nodes-1,0] = 1.0\n",
    "\n",
    "\n",
    "\n",
    "    # Generate observations based on random walks on the lattice graph\n",
    "    states = [np.random.choice(range(num_nodes))]  # Start from a random state\n",
    "    for _ in range(1, num_observations):\n",
    "        current_state = states[-1]\n",
    "        possible_next_states = np.where(T[current_state, :] > 0)[0]\n",
    "        next_state = np.random.choice(possible_next_states)\n",
    "        states.append(next_state)\n",
    "\n",
    "\n",
    "    # Map states to observations with aliasing\n",
    "    if num_aliased_states > num_nodes or num_aliased_states < 1:\n",
    "        raise ValueError(\"num_aliased_states must be between 1 and the number of nodes.\")\n",
    "\n",
    "\n",
    "    unique_obs = np.arange(num_nodes - num_aliased_states)\n",
    "    for n in range(num_aliased_states):\n",
    "      unique_obs = np.append(unique_obs,random.choice(unique_obs))\n",
    "    state_to_obs = unique_obs # Aliasing version\n",
    "\n",
    "    # Create observation data\n",
    "    x = state_to_obs[states]\n",
    "\n",
    "    # plt.matshow(T)\n",
    "    # plt.show()\n",
    "\n",
    "    return x\n",
    "\n",
    "# Function to create a lattice graph with variable nodes, observations, and aliased states\n",
    "def create_lattice_graph_varied(num_nodes=15, num_observations=10000, num_aliased_states=10):\n",
    "    if num_nodes < 4:\n",
    "        raise ValueError(\"num_nodes must be at least 4 to allow for meaningful connectivity.\")\n",
    "\n",
    "    # Initialize the adjacency matrix\n",
    "    T = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Connect each node to its immediate and second-order neighbors with wrapping\n",
    "    for i in range(num_nodes):\n",
    "        for offset in [-2, -1, 1, 2]:  # Immediate and second-order neighbors\n",
    "            j = (i + offset) % num_nodes\n",
    "            T[i, j] = 1.0\n",
    "\n",
    "    # Generate observations based on random walks on the lattice graph\n",
    "    states = [np.random.choice(range(num_nodes))]  # Start from a random state\n",
    "    for _ in range(1, num_observations):\n",
    "        current_state = states[-1]\n",
    "        possible_next_states = np.where(T[current_state, :] > 0)[0]\n",
    "        next_state = np.random.choice(possible_next_states)\n",
    "        states.append(next_state)\n",
    "\n",
    "\n",
    "    # Map states to observations with aliasing\n",
    "    if num_aliased_states > num_nodes or num_aliased_states < 1:\n",
    "        raise ValueError(\"num_aliased_states must be between 1 and the number of nodes.\")\n",
    "\n",
    "\n",
    "    unique_obs = np.arange(num_nodes - num_aliased_states)\n",
    "    for n in range(num_aliased_states):\n",
    "      unique_obs = np.append(unique_obs,random.choice(unique_obs))\n",
    "    state_to_obs = unique_obs # Aliasing version\n",
    "\n",
    "    # Create observation data\n",
    "    x = state_to_obs[states]\n",
    "\n",
    "    # plt.matshow(T)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a lattice graph with variable nodes, observations, and aliased states\n",
    "def return_gt_modular(num_nodes=15, num_observations=10000, num_aliased_states=10, num_modules=3):\n",
    "    if num_nodes < 4:\n",
    "        raise ValueError(\"num_nodes must be at least 4 to allow for meaningful connectivity.\")\n",
    "\n",
    "    if num_nodes < num_modules:\n",
    "        raise ValueError(\"Number of nodes must be at least equal to the number of modules to form a meaningful structure.\")\n",
    "\n",
    "    # Initialize the adjacency matrix\n",
    "    T = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Calculate the size of each module\n",
    "    module_size = num_nodes // num_modules\n",
    "\n",
    "    for module_index in range(num_modules):\n",
    "        module_start = module_index * module_size\n",
    "        # For the last module, extend to the end of the node list\n",
    "        module_end = module_start + module_size if module_index < num_modules - 1 else num_nodes\n",
    "\n",
    "        # Fully connect nodes within the module\n",
    "        for i in range(module_start, module_end):\n",
    "            for j in range(module_start, module_end):\n",
    "                if i != j:\n",
    "                    T[i, j] = 1.0\n",
    "    # Optionally, add sparse inter-module connections\n",
    "    # Example: Connecting last node of one module to first node of the next module\n",
    "    for module_index in range(num_modules - 1):\n",
    "        module_end = (module_index + 1) * module_size - 1\n",
    "        next_module_start = (module_end + 1) % num_nodes\n",
    "        T[module_end, next_module_start] = 1.0\n",
    "        T[next_module_start, module_end] = 1.0\n",
    "    # connect first and last module\n",
    "    T[0, num_nodes-1] = 1.0\n",
    "    T[num_nodes-1,0] = 1.0\n",
    "\n",
    "\n",
    "    return T\n",
    "\n",
    "# Function to create a lattice graph with variable nodes, observations, and aliased states\n",
    "def return_gt_lattice(num_nodes=15, num_observations=10000, num_aliased_states=10):\n",
    "    if num_nodes < 4:\n",
    "        raise ValueError(\"num_nodes must be at least 4 to allow for meaningful connectivity.\")\n",
    "\n",
    "    # Initialize the adjacency matrix\n",
    "    T = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Connect each node to its immediate and second-order neighbors with wrapping\n",
    "    for i in range(num_nodes):\n",
    "        for offset in [-2, -1, 1, 2]:  # Immediate and second-order neighbors\n",
    "            j = (i + offset) % num_nodes\n",
    "            T[i, j] = 1.0\n",
    "\n",
    "\n",
    "    return T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create observation data\n",
    "\n",
    "num_nodes = 30\n",
    "num_observations = 50000\n",
    "num_aliased_states = 2  # Adjust this to change the number of aliased states\n",
    "num_clones = 10\n",
    "num_modules=3\n",
    "var_clones = np.arange(1,15,1)\n",
    "total_modularity_scores = []\n",
    "var_aliasing = np.arange(2,4,1)\n",
    "\n",
    "aliasing = 3\n",
    "\n",
    "num_aliased_states = num_nodes//aliasing  # Adjust this to change the number of aliased states\n",
    "\n",
    "\n",
    "x = create_modular_graph_varied(num_nodes, num_observations, num_aliased_states, num_modules)\n",
    "gA = return_gt_modular(num_nodes, num_observations, num_aliased_states, num_modules)\n",
    "a = np.zeros(len(x), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nclone=1\n",
    "# a,x,rc = datagen_structured_obs_room(room, length=50000)\n",
    "results_nclones = []\n",
    "results_totalclone = []\n",
    "results_ncomm=[]\n",
    "results_ged = []\n",
    "# alphas = np.arange(0.1, 1, 0.1)\n",
    "nclones = np.arange(3,10,2)\n",
    "seeds = np.arange(0,100,1)\n",
    "currmodel = 'modular'\n",
    "n_orig_clones = 70\n",
    "\n",
    "#   # Create observation data\n",
    "#   x = create_modular_graph_varied(num_nodes, num_observations, num_aliased_states, num_modules)\n",
    "#   a = np.zeros(len(x), dtype=int)\n",
    "\n",
    "#   n_clones = np.ones(max(x)+1, dtype=np.int64) * num_clones\n",
    "#   container = TableContainer()\n",
    "total_modularity_scores = []\n",
    "for nclone in nclones: \n",
    "    seed_results_totalclone = []\n",
    "    seed_results_nclones = []\n",
    "    seed_results_ncomm = []\n",
    "    modularity_scores = []\n",
    "    seed_results_ged = []\n",
    "    for seed in seeds: \n",
    "        filename = 'model_modular_benchmark_nclone_' + str(nclone) + '_seed_' + str(seed) + '.pkl'\n",
    "        folderpath = 'models'\n",
    "        fullpath = os.path.join(folderpath, filename)\n",
    "        if os.path.isfile(fullpath):\n",
    "            try: \n",
    "                print(filename)\n",
    "                with open(fullpath, 'rb') as file: \n",
    "                    chmm = pickle.load(file)\n",
    "            except (pickle.UnpicklingError, EOFError) as e: \n",
    "                print(\"failed\")\n",
    "                \n",
    "        chmm.pseudocount = 2e-10\n",
    "        chmm.T += chmm.pseudocount\n",
    "        states = chmm.decode(x, a)[1]\n",
    "        n_states = len(np.unique(states))\n",
    "\n",
    "        custom_colors = generate_custom_colors(max(x)+1)/256\n",
    "        arr = np.arange(max(x)+1)\n",
    "        np.random.shuffle(arr)\n",
    "        cmap = colors.ListedColormap(custom_colors[arr])\n",
    "\n",
    "        temp_output_file = f\"modular_graph_benchmark_num_nodes_{num_nodes}.png\"  # Temporary file for each clone\n",
    "        # ged = graph_edit_distance_nx(chmm, x, a, gA, output_file=temp_output_file, cmap=cmap)\n",
    "        # print(ged)                \n",
    "        \n",
    "        \n",
    "        # comm = plot_graph_infomap(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "        # graph, modularity_score, v, g = plot_graph_modularity(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "        graph, v, g = plot_graph(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "        # print('Ground truth number of nodes: {}, number of nodes recovered {}'.format(num_nodes, len(v)))\n",
    "        # Display the image inline\n",
    "        # display(Image(filename=temp_output_file))\n",
    "        # seed_results_ncomm.append(comm)\n",
    "        \n",
    "        # modularity_scores.append(modularity_score)\n",
    "        # seed_results_nclones.append(len(v))\n",
    "        n_clones = len(v)\n",
    "\n",
    "        # n_clones = 0\n",
    "        # container = chmm.container\n",
    "        # table = []\n",
    "        # for roomid in range(len(container.groups_of_tables)):\n",
    "        #     print(\"Room {} has {} tables (clones)\".format(roomid, len(container.groups_of_tables[roomid])))\n",
    "        #     n_clones+=len(container.groups_of_tables[roomid])\n",
    "        #     table.append(len(container.groups_of_tables[roomid]))\n",
    "        # print(\"Total clones used: {}\".format(n_clones))\n",
    "        # print(\"Clones that would have been used by the original code: {}\".format(len(container.groups_of_tables) * 5))       \n",
    "        \n",
    "        seed_results_nclones.append(n_clones)\n",
    "    #     seed_results_nclones.append(table)\n",
    "        # seed_results_ged.append(ged)\n",
    "    # alpha_results_totalclone.append(seed_results_totalclone)\n",
    "    results_nclones.append(seed_results_nclones)\n",
    "    # total_modularity_scores.append(modularity_scores)\n",
    "    # results_ged.append(seed_results_ged)\n",
    "    # results_ncomm.append(seed_results_ncomm)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert to a numpy array\n",
    "data_array = np.array(results_nclones)\n",
    "\n",
    "# Check original shape\n",
    "print(\"Original shape:\", data_array.shape)  # Should print (10, 100)\n",
    "\n",
    "# Reshape to (100, 10)\n",
    "reshaped_array = data_array.transpose()  # Transpose to change rows to columns and vice versa\n",
    "\n",
    "# Check reshaped array's shape\n",
    "print(\"Reshaped array shape:\", reshaped_array.shape)  # Should print (100, 10)\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(reshaped_array)\n",
    "\n",
    "# Export to CSV\n",
    "csv_filename = 'modular_results_benchmark.csv'\n",
    "df.to_csv(csv_filename, index=False)  # index=False means do not write row indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nclones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('modular_results_benchmark.csv', results_nclones, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ged_modular_benchmark.npy', results_ged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_modularity_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(total_modularity_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(total_modularity_scores, axis=1))\n",
    "print(np.std(total_modularity_scores, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(results_nclones, axis=1))\n",
    "print(np.std(results_nclones, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clones = 0\n",
    "container = TableContainer()\n",
    "# n_clones = np.ones(n_emissions, dtype=np.int64) * nclone\n",
    "# container = TableContainer()\n",
    "chmm = CHMM_LCM(n_clones=n_clones, pseudocount=2e-3, x=x, a=a, container=container,alpha=alpha,seed=42)  # Initialize the model\n",
    "progression = chmm.learn_em_T(x, a, n_iter=20,\n",
    "                            # term_early=False,\n",
    "                            )  # Training   use n_iter=1000 for better training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(chmm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = chmm.decode(x, a)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the graph edit distance with the ground-truth graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "def grid_to_directed_igraph(grid):\n",
    "    \"\"\"\n",
    "    Convert a 2D numpy array to a directed igraph.Graph.\n",
    "    Each cell has bidirectional connections to its horizontal and vertical neighbors.\n",
    "    \"\"\"\n",
    "    rows, cols = grid.shape\n",
    "    adjacency_matrix = np.zeros((rows * cols, rows * cols), dtype=int)\n",
    "\n",
    "    index = lambda r, c: r * cols + c\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            current_index = index(r, c)\n",
    "\n",
    "            # North\n",
    "            if r > 0:\n",
    "                north_index = index(r - 1, c)\n",
    "                adjacency_matrix[current_index, north_index] = 1\n",
    "                adjacency_matrix[north_index, current_index] = 1\n",
    "\n",
    "            # South\n",
    "            if r < rows - 1:\n",
    "                south_index = index(r + 1, c)\n",
    "                adjacency_matrix[current_index, south_index] = 1\n",
    "                adjacency_matrix[south_index, current_index] = 1\n",
    "\n",
    "            # East\n",
    "            if c < cols - 1:\n",
    "                east_index = index(r, c + 1)\n",
    "                adjacency_matrix[current_index, east_index] = 1\n",
    "                adjacency_matrix[east_index, current_index] = 1\n",
    "\n",
    "            # West\n",
    "            if c > 0:\n",
    "                west_index = index(r, c - 1)\n",
    "                adjacency_matrix[current_index, west_index] = 1\n",
    "                adjacency_matrix[west_index, current_index] = 1\n",
    "\n",
    "    # Creating an igraph from the adjacency matrix\n",
    "    graph = ig.Graph.Adjacency((adjacency_matrix > 0).tolist(), mode=ig.ADJ_DIRECTED)\n",
    "    return graph\n",
    "\n",
    "# Example room array\n",
    "room = np.array([\n",
    "    [1, 2, 3, 0, 3, 1, 1, 1],\n",
    "    [1, 1, 3, 2, 3, 2, 3, 1],\n",
    "    [1, 1, 2, 0, 1, 2, 1, 0],\n",
    "    [0, 2, 1, 1, 3, 0, 0, 2],\n",
    "    [3, 3, 1, 0, 1, 0, 3, 0],\n",
    "    [2, 1, 2, 3, 3, 3, 2, 0],\n",
    "])\n",
    "\n",
    "directed_igraph = grid_to_directed_igraph(room)\n",
    "print(\"Directed Graph Representation with igraph:\")\n",
    "print(directed_igraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def heuristic(graph1, graph2):\n",
    "    \"\"\"\n",
    "    Heuristic that considers both vertices and edges.\n",
    "    \"\"\"\n",
    "    v_diff = abs(len(graph1.vs) - len(graph2.vs))\n",
    "    e_diff = abs(len(graph1.es) - len(graph2.es))\n",
    "    return v_diff + e_diff\n",
    "\n",
    "def graph_edit_distance_igraph(graph1, graph2, max_iterations=10000):\n",
    "    \"\"\"\n",
    "    Computes the approximate graph edit distance between two graphs\n",
    "    using the A* algorithm with practical limitations.\n",
    "    \"\"\"\n",
    "    frontier = PriorityQueue()\n",
    "    graph_id = 0\n",
    "    graphs = {graph_id: graph1}\n",
    "    frontier.put((heuristic(graph1, graph2), 0, graph_id))\n",
    "    graph_id += 1\n",
    "\n",
    "    iterations = 0\n",
    "    while not frontier.empty() and iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        estimated_cost, actual_cost, current_graph_id = frontier.get()\n",
    "        current_graph = graphs[current_graph_id]\n",
    "\n",
    "        # Check if we reached the target structure\n",
    "        if heuristic(current_graph, graph2) == 0:\n",
    "            return actual_cost\n",
    "\n",
    "        # Try adding and removing vertices and edges\n",
    "        if len(current_graph.vs) < 20:  # Limit vertex count for demo purposes\n",
    "            new_graph = current_graph.copy()\n",
    "            new_graph.add_vertices(1)\n",
    "            new_cost = actual_cost + 1\n",
    "            graphs[graph_id] = new_graph\n",
    "            frontier.put((new_cost + heuristic(new_graph, graph2), new_cost, graph_id))\n",
    "            graph_id += 1\n",
    "\n",
    "        if len(current_graph.vs) > 1:\n",
    "            for v in range(len(current_graph.vs)):\n",
    "                new_graph = current_graph.copy()\n",
    "                new_graph.delete_vertices(v)\n",
    "                new_cost = actual_cost + 1\n",
    "                graphs[graph_id] = new_graph\n",
    "                frontier.put((new_cost + heuristic(new_graph, graph2), new_cost, graph_id))\n",
    "                graph_id += 1\n",
    "                break  # Limit to one vertex modification per expansion for demo\n",
    "\n",
    "        # Check if edges can be modified if graphs are similar in vertices but differ in edges\n",
    "        if len(current_graph.vs) == len(graph2.vs):\n",
    "            for e in current_graph.es:\n",
    "                new_graph = current_graph.copy()\n",
    "                new_graph.delete_edges(e.index)\n",
    "                new_cost = actual_cost + 1\n",
    "                graphs[graph_id] = new_graph\n",
    "                frontier.put((new_cost + heuristic(new_graph, graph2), new_cost, graph_id))\n",
    "                graph_id += 1\n",
    "                break  # Limit to one edge modification for demo\n",
    "\n",
    "    return float('inf')  # Return infinity if no solution found within the constraints\n",
    "\n",
    "# Example usage would involve defining specific igraph instances to test this function.\n",
    "\n",
    "# # Example usage with igraph.Graph\n",
    "# room_graph = ig.Graph.Adjacency((room > 0).tolist())\n",
    "# target_graph = ig.Graph.Adjacency((np.random.randint(0, 2, room.shape) > 0).tolist())\n",
    "\n",
    "# ged = graph_edit_distance_igraph(room_graph, target_graph)\n",
    "# print(f\"Graph Edit Distance: {ged}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_similarity(graph1, graph2):\n",
    "    L1 = np.array(graph1.laplacian())\n",
    "    L2 = np.array(graph2.laplacian())\n",
    "    eigenvalues1 = np.sort(np.linalg.eigvals(L1))\n",
    "    eigenvalues2 = np.sort(np.linalg.eigvals(L2))\n",
    "\n",
    "    # Pad the smaller array of eigenvalues to match the larger one\n",
    "    max_len = max(len(eigenvalues1), len(eigenvalues2))\n",
    "    eigenvalues1 = np.pad(eigenvalues1, (0, max_len - len(eigenvalues1)), 'constant')\n",
    "    eigenvalues2 = np.pad(eigenvalues2, (0, max_len - len(eigenvalues2)), 'constant')\n",
    "\n",
    "    # Calculate the Euclidean distance between the eigenvalue arrays\n",
    "    distance = np.linalg.norm(eigenvalues1 - eigenvalues2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclone=1\n",
    "a,x,rc = datagen_structured_obs_room(room, length=50000)\n",
    "# alpha_results_nclones = []\n",
    "# alpha_results_totalclone = []\n",
    "geds = []\n",
    "alphas = np.arange(0.1, 1, 0.1)\n",
    "seeds = np.arange(0,100,10) # modified to save time\n",
    "currmodel = 'spatial'\n",
    "n_orig_clones = 70\n",
    "for alpha in alphas: \n",
    "    # seed_results_totalclone = []\n",
    "    # seed_results_nclones = []\n",
    "    seed_geds = []\n",
    "    for seed in seeds: \n",
    "        filename = 'model_' + currmodel + '_alpha_' + str(alpha) + '_seed_' + str(seed) + '.pkl'\n",
    "        folderpath = 'models'\n",
    "        fullpath = os.path.join(folderpath, filename)\n",
    "        if os.path.isfile(fullpath):\n",
    "            try: \n",
    "                print(filename)\n",
    "                with open(fullpath, 'rb') as file: \n",
    "                    chmm = pickle.load(file)\n",
    "            except (pickle.UnpicklingError, EOFError) as e: \n",
    "                print(\"failed\")\n",
    "        chmm.pseudocount = 0.01\n",
    "\n",
    "        temp_output_file = f\"rectangular_room_graph_large_num_clones_{nclone}.png\" # Temporary file for each clone\n",
    "        # graph, v, g = plot_graph(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "\n",
    "        graph, v, g = plot_graph(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "        # score = graph_edit_distance_igraph(g, directed_igraph)\n",
    "        score = spectral_similarity(g,directed_igraph)\n",
    "        seed_geds.append(score)\n",
    "        print(score)\n",
    "    geds.append(seed_geds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(geds,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(geds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_similarity(g, directed_igraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
