{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cscg_actions_orig import *\n",
    "from ged import *\n",
    "from util import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "def generate_custom_colors(num_unique_observations):\n",
    "    # Define a fixed set of custom colors as RGB values\n",
    "    predefined_colors = np.array([\n",
    "        [214, 214, 214],\n",
    "        [85, 35, 157],\n",
    "        [253, 252, 144],\n",
    "        [114, 245, 144],\n",
    "        [151, 38, 20],\n",
    "        [239, 142, 192],\n",
    "        [214, 134, 48],\n",
    "        [140, 194, 250],\n",
    "        [72, 160, 162],\n",
    "    ])\n",
    "\n",
    "    # If the number of unique observations is greater than the number of predefined colors,\n",
    "    # cycle through the predefined colors to ensure enough colors are available\n",
    "    if num_unique_observations > len(predefined_colors):\n",
    "        extra_colors_needed = num_unique_observations - len(predefined_colors)\n",
    "        additional_colors = np.tile(predefined_colors, (extra_colors_needed // len(predefined_colors) + 1, 1))\n",
    "        custom_colors = np.vstack((predefined_colors, additional_colors))[:num_unique_observations]\n",
    "    else:\n",
    "        custom_colors = predefined_colors[:num_unique_observations]\n",
    "\n",
    "    return custom_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room = np.array(\n",
    "#     [\n",
    "#         [1, 2, 3, 0, 3,],\n",
    "#         [1, 1, 3, 2, 3,],\n",
    "#         [1, 1, 2, 0, 1,],\n",
    "#         [0, 2, 1, 1, 3,],\n",
    "#         [3, 3, 1, 0, 1,],\n",
    "#         [2, 1, 2, 3, 3,],\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Uncomment this for generating data from a bigger room. Will take longer to train.\n",
    "\n",
    "room = np.array(\n",
    "    [\n",
    "        [1, 2, 3, 0, 3, 1, 1, 1],\n",
    "        [1, 1, 3, 2, 3, 2, 3, 1],\n",
    "        [1, 1, 2, 0, 1, 2, 1, 0],\n",
    "        [0, 2, 1, 1, 3, 0, 0, 2],\n",
    "        [3, 3, 1, 0, 1, 0, 3, 0],\n",
    "        [2, 1, 2, 3, 3, 3, 2, 0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the layout of the room\n",
    "cmap = colors.ListedColormap(custom_colors[-4:])\n",
    "plt.matshow(room, cmap=cmap)\n",
    "plt.title('Spatial environment (room)')\n",
    "plt.savefig(\"figures/rectangular_room_layout.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rows = 6\n",
    "cols = 8\n",
    "total_nodes = rows * cols\n",
    "adjacency_matrix = np.zeros((total_nodes, total_nodes), dtype=int)\n",
    "\n",
    "# Helper function to convert 2D grid coordinates to 1D index\n",
    "def node_index(row, col):\n",
    "    return row * cols + col\n",
    "\n",
    "# Fill the adjacency matrix\n",
    "for row in range(rows):\n",
    "    for col in range(cols):\n",
    "        index = node_index(row, col)\n",
    "\n",
    "        # Self-connection for boundary nodes\n",
    "        if row == 0 or row == rows - 1 or col == 0 or col == cols - 1:\n",
    "            adjacency_matrix[index, index] = 1\n",
    "\n",
    "        # Check for connection to the right\n",
    "        if col + 1 < cols:\n",
    "            right_index = node_index(row, col + 1)\n",
    "            adjacency_matrix[index, right_index] = 1\n",
    "        \n",
    "        # Check for connection to the left\n",
    "        if col - 1 >= 0:\n",
    "            left_index = node_index(row, col - 1)\n",
    "            adjacency_matrix[index, left_index] = 1\n",
    "        \n",
    "        # Check for connection above\n",
    "        if row - 1 >= 0:\n",
    "            up_index = node_index(row - 1, col)\n",
    "            adjacency_matrix[index, up_index] = 1\n",
    "        \n",
    "        # Check for connection below\n",
    "        if row + 1 < rows:\n",
    "            down_index = node_index(row + 1, col)\n",
    "            adjacency_matrix[index, down_index] = 1\n",
    "\n",
    "# Optionally print the matrix\n",
    "print(adjacency_matrix)\n",
    "gt_A = adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nclone=1\n",
    "a,x,rc = datagen_structured_obs_room(room, length=50000)\n",
    "results_nclones = []\n",
    "results_totalclone = []\n",
    "results_ged = []\n",
    "# alphas = np.arange(0.1, 1, 0.1)\n",
    "nclones = np.arange(10,251,60)\n",
    "seeds = np.arange(0,100,1)\n",
    "currmodel = 'spatial'\n",
    "n_orig_clones = 70\n",
    "for nclone in nclones: \n",
    "    seed_results_totalclone = []\n",
    "    seed_results_nclones = []\n",
    "    seed_results_ged = []\n",
    "    for seed in seeds: \n",
    "        # filename = 'model_' + currmodel + '_alpha_' + str(nclone) + '_seed_' + str(seed) + '.pkl'\n",
    "        filename = 'model_spatial_benchmark_nclone_' + str(nclone) + '_seed_' + str(seed) + '.pkl'\n",
    "        folderpath = 'models'\n",
    "        fullpath = os.path.join(folderpath, filename)\n",
    "        if os.path.isfile(fullpath):\n",
    "            try: \n",
    "                print(filename)\n",
    "                with open(fullpath, 'rb') as file: \n",
    "                    chmm = pickle.load(file)\n",
    "            except (pickle.UnpicklingError, EOFError) as e: \n",
    "                print(\"failed\")\n",
    "        chmm.pseudocount = 2e-3\n",
    "\n",
    "        temp_output_file = f\"rectangular_room_graph_large_benchmark_num_clones_{nclone}.png\" # Temporary file for each clone\n",
    "        \n",
    "        ged = graph_edit_distance_nx_norm(chmm, x, a, gt_A, output_file=temp_output_file, cmap=cmap)\n",
    "        print(ged)\n",
    "        \n",
    "        \n",
    "        graph, v, g = plot_graph(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "        # print(\"Ground truth number of nodes: {}, number of nodes recovered {}\".format(len(room.flatten()), len(v)))\n",
    "        \n",
    "        # # display the image inline\n",
    "        # display(Image(filename=temp_output_file))\n",
    "        \n",
    "        n_clones = 0 \n",
    "        # container = chmm.container\n",
    "        table = []\n",
    "        \n",
    "        # for roomid in range(len(container.groups_of_tables)):\n",
    "        #     # print(\"Room {} has {} tables (clones)\".format(roomid, len(container.groups_of_tables[roomid])))\n",
    "        #     n_clones += len(container.groups_of_tables[roomid])\n",
    "        #     table.append(len(container.groups_of_tables[roomid]))\n",
    "        # print(\"Total clones used: {}\".format(n_clones))\n",
    "        # print(\"Clones that would have been used by the original code: {}\".format(len(container.groups_of_tables)*n_orig_clones))\n",
    "        n_clones = len(v)\n",
    "        seed_results_totalclone.append(n_clones)\n",
    "        seed_results_ged.append(ged)\n",
    "    #     seed_results_nclones.append(table)\n",
    "    results_totalclone.append(seed_results_totalclone)\n",
    "    results_ged.append(seed_results_ged)\n",
    "    # results_nclones.append(seed_results_nclones)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert to a numpy array\n",
    "data_array = np.array(results_totalclone)\n",
    "\n",
    "# Check original shape\n",
    "print(\"Original shape:\", data_array.shape)  # Should print (10, 100)\n",
    "\n",
    "# Reshape to (100, 10)\n",
    "reshaped_array = data_array.transpose()  # Transpose to change rows to columns and vice versa\n",
    "\n",
    "# Check reshaped array's shape\n",
    "print(\"Reshaped array shape:\", reshaped_array.shape)  # Should print (100, 10)\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(reshaped_array)\n",
    "\n",
    "# Export to CSV\n",
    "csv_filename = 'spatial_results_benchmark.csv'\n",
    "df.to_csv(csv_filename, index=False)  # index=False means do not write row indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ged_norm_spatial_benchmark.npy', results_ged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ged_norm_spatial_benchmark.npy', results_ged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_totalclone,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(results_totalclone,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the graph edit distance with the ground-truth graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import igraph as ig\n",
    "\n",
    "\n",
    "def grid_to_directed_igraph(grid):\n",
    "    \"\"\"\n",
    "    Convert a 2D numpy array to a directed igraph.Graph.\n",
    "    Each cell has bidirectional connections to its horizontal and vertical neighbors.\n",
    "    \"\"\"\n",
    "    rows, cols = grid.shape\n",
    "    adjacency_matrix = np.zeros((rows * cols, rows * cols), dtype=int)\n",
    "\n",
    "    index = lambda r, c: r * cols + c\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            current_index = index(r, c)\n",
    "\n",
    "            # North\n",
    "            if r > 0:\n",
    "                north_index = index(r - 1, c)\n",
    "                adjacency_matrix[current_index, north_index] = 1\n",
    "                adjacency_matrix[north_index, current_index] = 1\n",
    "\n",
    "            # South\n",
    "            if r < rows - 1:\n",
    "                south_index = index(r + 1, c)\n",
    "                adjacency_matrix[current_index, south_index] = 1\n",
    "                adjacency_matrix[south_index, current_index] = 1\n",
    "\n",
    "            # East\n",
    "            if c < cols - 1:\n",
    "                east_index = index(r, c + 1)\n",
    "                adjacency_matrix[current_index, east_index] = 1\n",
    "                adjacency_matrix[east_index, current_index] = 1\n",
    "\n",
    "            # West\n",
    "            if c > 0:\n",
    "                west_index = index(r, c - 1)\n",
    "                adjacency_matrix[current_index, west_index] = 1\n",
    "                adjacency_matrix[west_index, current_index] = 1\n",
    "\n",
    "    # Creating an igraph from the adjacency matrix\n",
    "    graph = ig.Graph.Adjacency((adjacency_matrix > 0).tolist(), mode=ig.ADJ_DIRECTED)\n",
    "    return graph\n",
    "\n",
    "# Example room array\n",
    "room = np.array([\n",
    "    [1, 2, 3, 0, 3, 1, 1, 1],\n",
    "    [1, 1, 3, 2, 3, 2, 3, 1],\n",
    "    [1, 1, 2, 0, 1, 2, 1, 0],\n",
    "    [0, 2, 1, 1, 3, 0, 0, 2],\n",
    "    [3, 3, 1, 0, 1, 0, 3, 0],\n",
    "    [2, 1, 2, 3, 3, 3, 2, 0],\n",
    "])\n",
    "\n",
    "directed_igraph = grid_to_directed_igraph(room)\n",
    "print(\"Directed Graph Representation with igraph:\")\n",
    "print(directed_igraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def heuristic(graph1, graph2):\n",
    "    \"\"\"\n",
    "    Heuristic that considers both vertices and edges.\n",
    "    \"\"\"\n",
    "    v_diff = abs(len(graph1.vs) - len(graph2.vs))\n",
    "    e_diff = abs(len(graph1.es) - len(graph2.es))\n",
    "    return v_diff + e_diff\n",
    "\n",
    "def graph_edit_distance_igraph(graph1, graph2, max_iterations=10000):\n",
    "    \"\"\"\n",
    "    Computes the approximate graph edit distance between two graphs\n",
    "    using the A* algorithm with practical limitations.\n",
    "    \"\"\"\n",
    "    frontier = PriorityQueue()\n",
    "    graph_id = 0\n",
    "    graphs = {graph_id: graph1}\n",
    "    frontier.put((heuristic(graph1, graph2), 0, graph_id))\n",
    "    graph_id += 1\n",
    "\n",
    "    iterations = 0\n",
    "    while not frontier.empty() and iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        estimated_cost, actual_cost, current_graph_id = frontier.get()\n",
    "        current_graph = graphs[current_graph_id]\n",
    "\n",
    "        # Check if we reached the target structure\n",
    "        if heuristic(current_graph, graph2) == 0:\n",
    "            return actual_cost\n",
    "\n",
    "        # Try adding and removing vertices and edges\n",
    "        if len(current_graph.vs) < 20:  # Limit vertex count for demo purposes\n",
    "            new_graph = current_graph.copy()\n",
    "            new_graph.add_vertices(1)\n",
    "            new_cost = actual_cost + 1\n",
    "            graphs[graph_id] = new_graph\n",
    "            frontier.put((new_cost + heuristic(new_graph, graph2), new_cost, graph_id))\n",
    "            graph_id += 1\n",
    "\n",
    "        if len(current_graph.vs) > 1:\n",
    "            for v in range(len(current_graph.vs)):\n",
    "                new_graph = current_graph.copy()\n",
    "                new_graph.delete_vertices(v)\n",
    "                new_cost = actual_cost + 1\n",
    "                graphs[graph_id] = new_graph\n",
    "                frontier.put((new_cost + heuristic(new_graph, graph2), new_cost, graph_id))\n",
    "                graph_id += 1\n",
    "                break  # Limit to one vertex modification per expansion for demo\n",
    "\n",
    "        # Check if edges can be modified if graphs are similar in vertices but differ in edges\n",
    "        if len(current_graph.vs) == len(graph2.vs):\n",
    "            for e in current_graph.es:\n",
    "                new_graph = current_graph.copy()\n",
    "                new_graph.delete_edges(e.index)\n",
    "                new_cost = actual_cost + 1\n",
    "                graphs[graph_id] = new_graph\n",
    "                frontier.put((new_cost + heuristic(new_graph, graph2), new_cost, graph_id))\n",
    "                graph_id += 1\n",
    "                break  # Limit to one edge modification for demo\n",
    "\n",
    "    return float('inf')  # Return infinity if no solution found within the constraints\n",
    "\n",
    "# Example usage would involve defining specific igraph instances to test this function.\n",
    "\n",
    "# # Example usage with igraph.Graph\n",
    "# room_graph = ig.Graph.Adjacency((room > 0).tolist())\n",
    "# target_graph = ig.Graph.Adjacency((np.random.randint(0, 2, room.shape) > 0).tolist())\n",
    "\n",
    "# ged = graph_edit_distance_igraph(room_graph, target_graph)\n",
    "# print(f\"Graph Edit Distance: {ged}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_similarity(graph1, graph2):\n",
    "    L1 = np.array(graph1.laplacian())\n",
    "    L2 = np.array(graph2.laplacian())\n",
    "    eigenvalues1 = np.sort(np.linalg.eigvals(L1))\n",
    "    eigenvalues2 = np.sort(np.linalg.eigvals(L2))\n",
    "\n",
    "    # Pad the smaller array of eigenvalues to match the larger one\n",
    "    max_len = max(len(eigenvalues1), len(eigenvalues2))\n",
    "    eigenvalues1 = np.pad(eigenvalues1, (0, max_len - len(eigenvalues1)), 'constant')\n",
    "    eigenvalues2 = np.pad(eigenvalues2, (0, max_len - len(eigenvalues2)), 'constant')\n",
    "\n",
    "    # Calculate the Euclidean distance between the eigenvalue arrays\n",
    "    distance = np.linalg.norm(eigenvalues1 - eigenvalues2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclone=1\n",
    "a,x,rc = datagen_structured_obs_room(room, length=50000)\n",
    "# alpha_results_nclones = []\n",
    "# alpha_results_totalclone = []\n",
    "geds = []\n",
    "alphas = np.arange(0.1, 1, 0.1)\n",
    "seeds = np.arange(0,100,10) # modified to save time\n",
    "currmodel = 'spatial'\n",
    "n_orig_clones = 70\n",
    "for alpha in alphas: \n",
    "    # seed_results_totalclone = []\n",
    "    # seed_results_nclones = []\n",
    "    seed_geds = []\n",
    "    for seed in seeds: \n",
    "        filename = 'model_' + currmodel + '_alpha_' + str(alpha) + '_seed_' + str(seed) + '.pkl'\n",
    "        folderpath = 'models'\n",
    "        fullpath = os.path.join(folderpath, filename)\n",
    "        if os.path.isfile(fullpath):\n",
    "            try: \n",
    "                print(filename)\n",
    "                with open(fullpath, 'rb') as file: \n",
    "                    chmm = pickle.load(file)\n",
    "            except (pickle.UnpicklingError, EOFError) as e: \n",
    "                print(\"failed\")\n",
    "        chmm.pseudocount = 0.01\n",
    "\n",
    "        temp_output_file = f\"rectangular_room_graph_large_num_clones_{nclone}.png\" # Temporary file for each clone\n",
    "        # graph, v, g = plot_graph(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "\n",
    "        graph, v, g = plot_graph(chmm, x, a, output_file=temp_output_file, cmap=cmap)\n",
    "        # score = graph_edit_distance_igraph(g, directed_igraph)\n",
    "        score = spectral_similarity(g,directed_igraph)\n",
    "        seed_geds.append(score)\n",
    "        print(score)\n",
    "    geds.append(seed_geds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(geds,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(geds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_similarity(g, directed_igraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cscg",
   "language": "python",
   "name": "cscg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
