{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chmm_actions import CHMM, forwardE, datagen_structured_obs_room\n",
    "import matplotlib.pyplot as plt\n",
    "import igraph \n",
    "from matplotlib import cm, colors\n",
    "import os\n",
    "\n",
    "custom_colors = (\n",
    "    np.array(\n",
    "        [\n",
    "            [214, 214, 214],\n",
    "            [85, 35, 157],\n",
    "            [253, 252, 144],\n",
    "            [114, 245, 144],\n",
    "            [151, 38, 20],\n",
    "            [239, 142, 192],\n",
    "            [214, 134, 48],\n",
    "            [140, 194, 250],\n",
    "            [72, 160, 162],\n",
    "        ]\n",
    "    )\n",
    "    / 256\n",
    ")\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(\n",
    "    chmm, x, a, output_file, cmap=cm.Spectral, multiple_episodes=False, vertex_size=30\n",
    "):\n",
    "    states = chmm.decode(x, a)[1]\n",
    "\n",
    "    v = np.unique(states)\n",
    "    if multiple_episodes:\n",
    "        T = chmm.C[:, v][:, :, v][:-1, 1:, 1:]\n",
    "        v = v[1:]\n",
    "    else:\n",
    "        T = chmm.C[:, v][:, :, v]\n",
    "    A = T.sum(0)\n",
    "    A /= A.sum(1, keepdims=True)\n",
    "\n",
    "    g = igraph.Graph.Adjacency((A > 0).tolist())\n",
    "    node_labels = np.arange(x.max() + 1).repeat(n_clones)[v]\n",
    "    if multiple_episodes:\n",
    "        node_labels -= 1\n",
    "    colors = [cmap(nl)[:3] for nl in node_labels / node_labels.max()]\n",
    "    out = igraph.plot(\n",
    "        g,\n",
    "        output_file,\n",
    "        layout=g.layout(\"kamada_kawai\"),\n",
    "        vertex_color=colors,\n",
    "        vertex_label=v,\n",
    "        vertex_size=vertex_size,\n",
    "        margin=50,\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mess_fwd(chmm, x, pseudocount=0.0, pseudocount_E=0.0):\n",
    "    n_clones = chmm.n_clones\n",
    "    E = np.zeros((n_clones.sum(), len(n_clones)))\n",
    "    last = 0\n",
    "    for c in range(len(n_clones)):\n",
    "        E[last : last + n_clones[c], c] = 1\n",
    "        last += n_clones[c]\n",
    "    E += pseudocount_E\n",
    "    norm = E.sum(1, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    E /= norm\n",
    "    T = chmm.C + pseudocount\n",
    "    norm = T.sum(2, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    T /= norm\n",
    "    T = T.mean(0, keepdims=True)\n",
    "    log2_lik, mess_fwd = forwardE(\n",
    "        T.transpose(0, 2, 1), E, chmm.Pi_x, chmm.n_clones, x, x * 0, store_messages=True\n",
    "    )\n",
    "    return mess_fwd\n",
    "\n",
    "\n",
    "def place_field(mess_fwd, rc, clone):\n",
    "    assert mess_fwd.shape[0] == rc.shape[0] and clone < mess_fwd.shape[1]\n",
    "    field = np.zeros(rc.max(0) + 1)\n",
    "    count = np.zeros(rc.max(0) + 1, int)\n",
    "    for t in range(mess_fwd.shape[0]):\n",
    "        r, c = rc[t]\n",
    "        field[r, c] += mess_fwd[t, clone]\n",
    "        count[r, c] += 1\n",
    "    count[count == 0] = 1\n",
    "    return field / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for setting up the environment\n",
    "class GridEnvRightDownNoSelf:\n",
    "    \"\"\"\n",
    "    A 3x3 grid with states numbered 1..9:\n",
    "\n",
    "        1   2   3\n",
    "        4   5   6\n",
    "        7   8   9\n",
    "\n",
    "    - The agent can only move RIGHT (0) or DOWN (1).\n",
    "    - No self-transitions at borders:\n",
    "        If an action would go out of bounds, that action is not allowed\n",
    "        from that state.\n",
    "    - Same cue logic: must visit 5 for a +1 reward at 9, else goes to 10 with -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cue_state=2):\n",
    "        # Grid layout: (row, col) -> state\n",
    "        self.pos_to_state = {\n",
    "            (0,0): 0, (0,1): 1, (0,2): 2, (0,3): 3,\n",
    "            (1,0): 4, (1,1): 5, (1,2): 6, (1,3): 7,\n",
    "            (2,0): 8, (2,1): 9, (2,2): 10, (2,3): 11,\n",
    "            (3,0): 12, (3,1): 13, (3,2): 14, (3,3): 15,\n",
    "        }\n",
    "        self.state_to_pos = {s: rc for rc, s in self.pos_to_state.items()}\n",
    "        \n",
    "        # Actions as integers: 0=right, 1=down\n",
    "        # right => (0, +1)\n",
    "        # down  => (+1, 0)\n",
    "        self.base_actions = {\n",
    "            0: (0, +1),   # right\n",
    "            1: (+1, 0)    # down\n",
    "        }\n",
    "        \n",
    "        # Instead of having a static [0,1] action space, we have a\n",
    "        # per-state action set (no invalid moves).\n",
    "        self.valid_actions = self._build_valid_actions()\n",
    "\n",
    "        # Special states\n",
    "        self.start_state = 0\n",
    "        self.cue_state = cue_state\n",
    "        self.rewarded_terminal = 15\n",
    "        self.unrewarded_terminal = 16  # not in the grid, just a label\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _build_valid_actions(self):\n",
    "        \"\"\"\n",
    "        Precompute valid actions for each non-terminal grid state.\n",
    "        A 'valid' action is one that leads to a NEW in-bounds state.\n",
    "        \"\"\"\n",
    "        valid_dict = {}\n",
    "        for row in range(4):\n",
    "            for col in range(4):\n",
    "                s = self.pos_to_state[(row, col)]\n",
    "                # We'll store all actions that yield a different state (no self-transitions)\n",
    "                valid_dict[s] = []\n",
    "                for a, (dr, dc) in self.base_actions.items():\n",
    "                    new_r = row + dr\n",
    "                    new_c = col + dc\n",
    "                    if 0 <= new_r < 4 and 0 <= new_c < 4:\n",
    "                        next_s = self.pos_to_state[(new_r, new_c)]\n",
    "                        # Only count it if next_s != s (which can't happen in 3x3, but let's be explicit)\n",
    "                        if next_s != s:\n",
    "                            valid_dict[s].append(a)\n",
    "\n",
    "        # For terminal states 9 and 10, no actions are valid\n",
    "        # valid_dict[9] = []\n",
    "        # valid_dict[10] = []\n",
    "        valid_dict[15] = []\n",
    "        valid_dict[16] = []\n",
    "\n",
    "        return valid_dict\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset environment to the start:\n",
    "          - current_state=1\n",
    "          - visited_cue=False\n",
    "        Returns current_state (1).\n",
    "        \"\"\"\n",
    "        self.current_state = self.start_state\n",
    "        self.visited_cue = False\n",
    "        return self.current_state\n",
    "\n",
    "    def get_valid_actions(self, state=None):\n",
    "        \"\"\"\n",
    "        Return the list of valid actions for the current state\n",
    "        (or a given state).\n",
    "        \"\"\"\n",
    "        if state is None:\n",
    "            state = self.current_state\n",
    "        return self.valid_actions[state]\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Step with a guaranteed valid action. If an invalid action is given,\n",
    "        we can either ignore or raise an Exception. We'll raise an error.\n",
    "        \"\"\"\n",
    "        if action not in self.get_valid_actions():\n",
    "            raise ValueError(f\"Action {action} is not valid from state {self.current_state}.\")\n",
    "\n",
    "        # If we're already in a terminal (9 or 10), episode is over.\n",
    "        if self.current_state in [self.rewarded_terminal, self.unrewarded_terminal]:\n",
    "            return self.current_state, 0, True\n",
    "\n",
    "        # Move\n",
    "        row, col = self.state_to_pos[self.current_state]\n",
    "        dr, dc = self.base_actions[action]\n",
    "        next_row = row + dr\n",
    "        next_col = col + dc\n",
    "\n",
    "        next_state = self.pos_to_state[(next_row, next_col)]\n",
    "\n",
    "        # Check cue\n",
    "        if next_state == self.cue_state:\n",
    "            self.visited_cue = True\n",
    "\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Terminal condition: 8 -> 9\n",
    "        if next_state == 15:\n",
    "            done = True\n",
    "            if self.visited_cue:\n",
    "                reward = +1\n",
    "                next_state = self.rewarded_terminal\n",
    "            else:\n",
    "                reward = -1\n",
    "                next_state = self.unrewarded_terminal\n",
    "\n",
    "        # Update\n",
    "        self.current_state = next_state\n",
    "        return next_state, reward, done\n",
    "    \n",
    "def generate_dataset(env, n_episodes=10, max_steps=20):\n",
    "    \"\"\"\n",
    "    Run 'n_episodes' episodes in the environment. Each episode ends\n",
    "    either when the environment signals 'done' or when we hit 'max_steps'.\n",
    "\n",
    "    Returns:\n",
    "        A list of (state_sequence, action_sequence) pairs.\n",
    "        - state_sequence: list of visited states\n",
    "        - action_sequence: list of chosen actions\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    for episode_idx in range(n_episodes):\n",
    "        # Prepare lists to store states & actions for this episode\n",
    "        states = []\n",
    "        actions = []\n",
    "\n",
    "        # Reset env to start a new episode\n",
    "        state = env.reset()\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            states.append(state)\n",
    "\n",
    "            valid_actions = env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                # No valid actions => we must be in a terminal or stuck\n",
    "                break\n",
    "\n",
    "            # Example: pick a random valid action\n",
    "            action = np.random.choice(valid_actions)\n",
    "            actions.append(action)\n",
    "\n",
    "            # Step in the environment\n",
    "            next_state, reward, done = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # Also record the final state\n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                break\n",
    "\n",
    "        # Store (states, actions) for this episode\n",
    "        dataset.append([states, actions])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridEnvRightDownNoSelf(cue_state=5)\n",
    "\n",
    "n_episodes = 500\n",
    "max_steps_per_episode = 10\n",
    "\n",
    "dataset = generate_dataset(env, n_episodes, max_steps_per_episode)\n",
    "# x = dataset[0][0]\n",
    "# a = dataset[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room = np.array(\n",
    "#     [\n",
    "#         [1, 2, 3, 0, 3, 1, 1, 1],\n",
    "#         [1, 1, 3, 2, 3, 2, 3, 1],\n",
    "#         [1, 1, 2, 0, 1, 2, 1, 0],\n",
    "#         [0, 2, 1, 1, 3, 0, 0, 2],\n",
    "#         [3, 3, 1, 0, 1, 0, 3, 0],\n",
    "#         [2, 1, 2, 3, 3, 3, 2, 0],\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "n_emissions = 17 #room.max() + 1\n",
    "\n",
    "# a, x, rc = datagen_structured_obs_room(room, length=50000)\n",
    "\n",
    "\n",
    "n_clones = np.ones(n_emissions, dtype=np.int64) * 3\n",
    "x = dataset[0][0]\n",
    "a = dataset[0][1]\n",
    "a = np.array(a)\n",
    "x = np.array(x)\n",
    "# np.append(a,0)\n",
    "# dataset = dataset[:1]\n",
    "chmm = CHMM(n_clones=n_clones, pseudocount=2e-3, x=x, a=a, seed=42)  # Initialize the model\n",
    "for d, curr_dataset in enumerate(dataset):\n",
    "    x = curr_dataset[0]\n",
    "    a = curr_dataset[1]\n",
    "    a = np.array(a)\n",
    "    # np.append(a,0)\n",
    "    x = np.array(x)\n",
    "\n",
    "    progression = chmm.learn_em_T(x, a, n_iter=1000)  # Training\n",
    "    \n",
    "    # refine learning\n",
    "    chmm.pseudocount = 0.0\n",
    "    chmm.learn_viterbi_T(x, a, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "len(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = plot_graph(\n",
    "    chmm, x, a, output_file=\"figures/rectangular_room_graph.pdf\", \n",
    "    \n",
    ")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
