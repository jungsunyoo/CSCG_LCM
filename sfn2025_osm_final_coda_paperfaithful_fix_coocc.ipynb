{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CoDA (uncertainty‑aware) — OSM Fig. 4c/4i/4j with **CSCG‑style color‑coded states**\n",
    "\n",
    "**New:** CSCG‑style node colors (uniform gray arrows), three coloring modes (`blocks`, `state_id`, `obs_step`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch, Circle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def posterior_prob_p_greater_than(theta: float, success: float, failure: float, alpha0: float=0.5, beta0: float=0.5) -> float:\n",
    "    if not _HAS_MPMATH:\n",
    "        return 0.0\n",
    "    a = alpha0 + max(0.0, float(success))\n",
    "    b = beta0 + max(0.0, float(failure))\n",
    "    cdf = betainc(a, b, 0, theta, regularized=True)\n",
    "    return float(1.0 - cdf)\n",
    "\n",
    "def wilson_lower_bound(phat: float, n: float, confidence: float=0.95) -> float:\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    if _HAS_MPMATH:\n",
    "        z = float((2.0**0.5) * erfcinv(2*(1.0-confidence)))\n",
    "    else:\n",
    "        z = 1.6448536269514722\n",
    "    denom = 1.0 + (z*z)/n\n",
    "    center = phat + (z*z)/(2.0*n)\n",
    "    adj = z * ((phat*(1.0-phat) + (z*z)/(4.0*n))/n)**0.5\n",
    "    return (center - adj)/denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "near = [1,1,1,1,1,1, 2,2,2,2, 1,1,1, 4,6, 1,1,1, 5,5, 1,1, 7, 0,0,0]\n",
    "far  = [1,1,1,1,1,1, 3,3,3,3, 1,1,1, 4,4, 1,1,1, 5,6, 1,1, 7, 0,0,0]\n",
    "\n",
    "preR1_idx = list(range(10,13))\n",
    "preR2_idx = list(range(15,18))\n",
    "\n",
    "def block_indices(rows, cols): return [(r,c) for r in rows for c in cols]\n",
    "offdiag_pairs     = block_indices(preR1_idx, preR2_idx) + block_indices(preR2_idx, preR1_idx)\n",
    "same_preR1_pairs  = block_indices(preR1_idx, preR1_idx)\n",
    "same_preR2_pairs  = block_indices(preR2_idx, preR2_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CoDA agent (trial-by-trial; paper-faithful) ---\n",
    "# This notebook-local agent is designed to follow the *key concepts* in the CoDA paper:\n",
    "#   1) Outcome-conditioned eligibility traces (Alg. 1) accumulate evidence for cues.\n",
    "#   2) Prospective contingency (PC) triggers *state-space augmentation* via successor cloning:\n",
    "#        when a cue becomes salient, we clone its outgoing successor states and rewire edges.\n",
    "#   3) Utility = (prospective × retrospective) can trigger merging (Alg. 2).\n",
    "# And it also includes the *practical stabilizers* used in coda_trial_by_trial_util.py:\n",
    "#   - confidence-gated splitting (Wilson lower bound)\n",
    "#   - evidence / exposure gates\n",
    "#   - optional decay (counts / traces / retrospective)\n",
    "#   - edge-mass-based merging safeguard\n",
    "#\n",
    "# NOTE: This agent is action-free because the notebook is a 1D symbol stream.\n",
    "# We therefore learn a deterministic \"cognitive graph\" over latent states by keying edges\n",
    "# on the next *observation symbol* (parent_sid, next_obs) -> child_sid, with counts for evidence.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Set, Tuple\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Config (mirrors key knobs in paper + python implementation)\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class UncCfg:\n",
    "    # Eligibility traces (Alg. 1)\n",
    "    gamma: float = 0.9\n",
    "    lam: float = 0.8\n",
    "\n",
    "    # Split / merge thresholds (Alg. 2)\n",
    "    theta_split: float = 0.7\n",
    "    theta_merge: float = 0.5\n",
    "\n",
    "    # Evidence gates\n",
    "    n_threshold: float = 2.0              # minimum effective \"n\" for contingency estimate\n",
    "    min_presence_episodes: int = 2        # must appear in >= this many episodes\n",
    "    min_effective_exposure: float = 2.0   # must accumulate >= this much eligibility exposure\n",
    "\n",
    "    # Confidence gate (as in python file): require Wilson LB > theta_split\n",
    "    split_confidence: float = 0.75\n",
    "\n",
    "    # Optional forgetting / decay (stabilizers, as in python file)\n",
    "    count_decay: float = 1.0              # transition-count decay per episode (1.0 = no decay)\n",
    "    trace_decay: float = 1.0              # eligibility accumulator decay per episode\n",
    "    retro_decay: float = 1.0              # retrospective EMA decay per episode\n",
    "\n",
    "    # Merge safeguard: if cue's outgoing mass to cue-created clones is tiny, merge\n",
    "    edge_eps: float = 1e-6\n",
    "\n",
    "    # Semantics for this notebook\n",
    "    reset_symbols: Tuple[int, ...] = (0,)  # symbols that reset \"episode context\"\n",
    "    us_classes: Tuple[int, int] = (4, 5)   # two US event symbols used in the notebook\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: confidence gating (Wilson LB)\n",
    "# -----------------------------\n",
    "\n",
    "def _z_one_sided(confidence: float) -> float:\n",
    "    # common one-sided z's (enough for notebook usage)\n",
    "    table = {0.90: 1.2815515655446004,\n",
    "             0.95: 1.6448536269514722,\n",
    "             0.975: 1.959963984540054,\n",
    "             0.99: 2.3263478740408408}\n",
    "    key = min(table.keys(), key=lambda k: abs(k - confidence))\n",
    "    return table[key]\n",
    "\n",
    "def wilson_lower_bound(phat: float, n: float, confidence: float = 0.95) -> float:\n",
    "    \"\"\"One-sided Wilson lower bound for a Bernoulli proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    z = _z_one_sided(confidence)\n",
    "    denom = 1.0 + (z * z) / n\n",
    "    center = phat + (z * z) / (2.0 * n)\n",
    "    adj = z * math.sqrt((phat * (1.0 - phat) + (z * z) / (4.0 * n)) / n)\n",
    "    return (center - adj) / denom\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CoDA agent\n",
    "# -----------------------------\n",
    "\n",
    "class CoDAUncAgent:\n",
    "    \"\"\"\n",
    "    Paper-faithful CoDA for a symbol stream.\n",
    "\n",
    "    Latent states live in a \"cognitive graph\" G:\n",
    "      edges[parent_sid][next_obs] = child_sid\n",
    "\n",
    "    Each latent node stores:\n",
    "      - obs: the aliased observation symbol\n",
    "      - path: None for original; \"R1\"/\"R2\" for clones (label derived from which US it predicts)\n",
    "      - original: original state id for this observation (if clone)\n",
    "      - root_cue: which cue caused this clone lineage (for merging descendants)\n",
    "      - alive: whether this node is active (merged nodes are kept but deactivated)\n",
    "\n",
    "    Learning:\n",
    "      - Maintain outcome-conditioned eligibility accumulators:\n",
    "          E[sid][u]  (eligibility mass credited at times US=u occurs)\n",
    "          exposure[sid]  (total eligibility exposure mass)\n",
    "          C[sid]         (effective count; here = sum_u E[sid][u])\n",
    "      - Retrospective:\n",
    "          us_episode_ema[u] and cs_us_presence_ema[sid][u]\n",
    "      - Split:\n",
    "          if max_u (E[sid][u]/C[sid]) has Wilson-LB > theta_split\n",
    "          and evidence gates pass -> mark sid salient with label (\"R1\"/\"R2\"),\n",
    "          then clone *all outgoing successors* of sid and rewire edges sid->clone(succ).\n",
    "      - Merge:\n",
    "          For a salient cue sid with winning u*:\n",
    "             PC = E[sid][u*]/C[sid]\n",
    "             RC = cs_us_presence_ema[sid][u*] / us_episode_ema[u*]\n",
    "             utility = PC * RC\n",
    "          If utility < theta_merge OR edge_mass_to_clones < edge_eps -> merge descendants.\n",
    "\n",
    "    This reproduces the *core components* of the paper while staying compatible with the notebook\n",
    "    (encode_sequence + near_far_corr + states[sid]['path'] for plotting).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_symbols: List[int], cfg: UncCfg = UncCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.us_classes = list(cfg.us_classes)\n",
    "\n",
    "        # --- latent node store ---\n",
    "        self.states: Dict[int, Dict] = {}\n",
    "        self.obs_to_original: Dict[int, int] = {}\n",
    "        self.obs_to_state_ids: Dict[int, List[int]] = {o: [] for o in obs_symbols}\n",
    "\n",
    "        # create originals\n",
    "        sid = 0\n",
    "        for o in obs_symbols:\n",
    "            self.states[sid] = dict(obs=o, path=None, original=sid, root_cue=None, alive=True)\n",
    "            self.obs_to_original[o] = sid\n",
    "            self.obs_to_state_ids[o].append(sid)\n",
    "            sid += 1\n",
    "        self._next_sid = sid\n",
    "\n",
    "        # --- deterministic graph edges + counts ---\n",
    "        self.edges: Dict[int, Dict[int, int]] = {s: {} for s in self.states}         # parent -> next_obs -> child\n",
    "        self.edge_counts: Dict[int, Dict[int, float]] = {s: {} for s in self.states} # parent -> next_obs -> count\n",
    "\n",
    "        # --- outcome-conditioned eligibility (Alg 1) ---\n",
    "        self.E: Dict[int, Dict[int, float]] = {s: {u: 0.0 for u in self.us_classes} for s in self.states}\n",
    "        # backward-compat: notebook checkpoint code expects `co_occ`\n",
    "        self.co_occ = self.E\n",
    "        self.exposure: Dict[int, float] = {s: 0.0 for s in self.states}  # total eligibility exposure\n",
    "        self.C: Dict[int, float] = {s: 0.0 for s in self.states}         # effective evidence count proxy\n",
    "\n",
    "        # --- retrospective EMA (for utility / merge) ---\n",
    "        self.us_episode_ema: Dict[int, float] = {u: 0.0 for u in self.us_classes}\n",
    "        self.cs_us_presence_ema: Dict[int, Dict[int, float]] = {s: {u: 0.0 for u in self.us_classes} for s in self.states}\n",
    "\n",
    "        # evidence gate: how many episodes did this state appear in?\n",
    "        self.presence_episodes: Dict[int, int] = {s: 0 for s in self.states}\n",
    "\n",
    "        # salient cues: sid -> (\"R1\"/\"R2\", winning_us)\n",
    "        self.salient: Dict[int, Tuple[str, int]] = {}\n",
    "\n",
    "        # bookkeeping: cue -> set of clone ids it created (direct)\n",
    "        self.cue_to_clones: Dict[int, Set[int]] = {}\n",
    "\n",
    "    # ---------------------\n",
    "    # utilities\n",
    "    # ---------------------\n",
    "\n",
    "    def _ensure_state_structs(self, sid: int) -> None:\n",
    "        if sid not in self.E:\n",
    "            self.E[sid] = {u: 0.0 for u in self.us_classes}\n",
    "            self.exposure[sid] = 0.0\n",
    "            self.C[sid] = 0.0\n",
    "            self.cs_us_presence_ema[sid] = {u: 0.0 for u in self.us_classes}\n",
    "            self.presence_episodes[sid] = 0\n",
    "            self.edges.setdefault(sid, {})\n",
    "            self.edge_counts.setdefault(sid, {})\n",
    "\n",
    "    def _alloc_sid(self) -> int:\n",
    "        sid = self._next_sid\n",
    "        self._next_sid += 1\n",
    "        return sid\n",
    "\n",
    "    def _clone_node(self, base_sid: int, *, root_cue: int, path_label: str) -> int:\n",
    "        \"\"\"Clone a successor state as in Alg. 2: same obs, copy outgoing edges.\"\"\"\n",
    "        base = self.states[base_sid]\n",
    "        new_sid = self._alloc_sid()\n",
    "        obs = base['obs']\n",
    "        self.states[new_sid] = dict(\n",
    "            obs=obs,\n",
    "            path=path_label,\n",
    "            original=base['original'],\n",
    "            root_cue=root_cue,\n",
    "            alive=True,\n",
    "        )\n",
    "        self._ensure_state_structs(new_sid)\n",
    "\n",
    "        # register by observation\n",
    "        self.obs_to_state_ids.setdefault(obs, []).append(new_sid)\n",
    "\n",
    "        # copy outgoing edges + counts\n",
    "        self.edges[new_sid] = dict(self.edges.get(base_sid, {}))\n",
    "        self.edge_counts[new_sid] = dict(self.edge_counts.get(base_sid, {}))\n",
    "\n",
    "        return new_sid\n",
    "\n",
    "    def _is_descendant_of(self, sid: int, cue: int) -> bool:\n",
    "        st = self.states.get(sid, None)\n",
    "        return (st is not None) and (st.get('root_cue', None) == cue)\n",
    "\n",
    "    # ---------------------\n",
    "    # Prospective / retrospective\n",
    "    # ---------------------\n",
    "\n",
    "    def prospective_dist(self, sid: int) -> Dict[int, float]:\n",
    "        \"\"\"P(US=u | CS=sid) over u in us_classes (normalized E).\"\"\"\n",
    "        self._ensure_state_structs(sid)\n",
    "        tot = sum(self.E[sid][u] for u in self.us_classes)\n",
    "        if tot <= 0:\n",
    "            return {u: 0.0 for u in self.us_classes}\n",
    "        return {u: self.E[sid][u] / tot for u in self.us_classes}\n",
    "\n",
    "    def _winning_us_and_pc(self, sid: int) -> Tuple[int, float, float]:\n",
    "        \"\"\"\n",
    "        Return (u_star, phat, n_eff) where phat = max_u E[sid][u]/sum_u E[sid][u]\n",
    "        and n_eff = sum_u E[sid][u] (effective sample size).\n",
    "        \"\"\"\n",
    "        self._ensure_state_structs(sid)\n",
    "        n_eff = sum(self.E[sid][u] for u in self.us_classes)\n",
    "        if n_eff <= 0:\n",
    "            return self.us_classes[0], 0.0, 0.0\n",
    "        u_star = max(self.us_classes, key=lambda u: self.E[sid][u])\n",
    "        phat = self.E[sid][u_star] / n_eff\n",
    "        return u_star, phat, n_eff\n",
    "\n",
    "    def retrospective(self, sid: int, u: int) -> float:\n",
    "        \"\"\"P(CS=sid present | US=u present), EMA-based.\"\"\"\n",
    "        self._ensure_state_structs(sid)\n",
    "        denom = self.us_episode_ema.get(u, 0.0)\n",
    "        if denom <= 0:\n",
    "            return 0.0\n",
    "        return self.cs_us_presence_ema[sid].get(u, 0.0) / denom\n",
    "\n",
    "    def utility(self, sid: int) -> float:\n",
    "        \"\"\"utility = PC * RC for the cue's winning US.\"\"\"\n",
    "        if sid not in self.salient:\n",
    "            # use current winning US anyway\n",
    "            u_star, phat, _ = self._winning_us_and_pc(sid)\n",
    "        else:\n",
    "            _, u_star = self.salient[sid]\n",
    "            u_star, phat, _ = self._winning_us_and_pc(sid)  # recompute phat on current stats\n",
    "        rc = self.retrospective(sid, u_star)\n",
    "        return phat * rc\n",
    "\n",
    "    # ---------------------\n",
    "    # Graph rollout / episode update\n",
    "    # ---------------------\n",
    "\n",
    "    def rollout_latent(self, obs_seq: List[int], create_missing: bool = True) -> List[int]:\n",
    "        \"\"\"Map observation sequence to latent states by following edges (creating defaults if missing).\"\"\"\n",
    "        if not obs_seq:\n",
    "            return []\n",
    "        # start at original for first obs\n",
    "        cur = self.obs_to_original[obs_seq[0]]\n",
    "        latent = [cur]\n",
    "\n",
    "        for nxt_obs in obs_seq[1:]:\n",
    "            out = self.edges.get(cur, {})\n",
    "            if nxt_obs in out:\n",
    "                nxt = out[nxt_obs]\n",
    "            else:\n",
    "                nxt = self.obs_to_original[nxt_obs]\n",
    "                if create_missing:\n",
    "                    out[nxt_obs] = nxt\n",
    "                    self.edges[cur] = out\n",
    "            cur = nxt\n",
    "            latent.append(cur)\n",
    "        return latent\n",
    "\n",
    "    def update_with_episode(self, obs_seq: List[int], learn: bool = True) -> List[int]:\n",
    "        \"\"\"\n",
    "        Runs an episode, optionally learning:\n",
    "          - update transition counts\n",
    "          - update eligibility E\n",
    "          - update retrospective EMA\n",
    "          - run split/merge\n",
    "        Returns latent state sequence.\n",
    "        \"\"\"\n",
    "        latent = self.rollout_latent(obs_seq, create_missing=learn)\n",
    "        if not learn:\n",
    "            return latent\n",
    "\n",
    "        # 0) decay (stabilizers)\n",
    "        if self.cfg.count_decay != 1.0:\n",
    "            for p in list(self.edge_counts.keys()):\n",
    "                for o in list(self.edge_counts[p].keys()):\n",
    "                    self.edge_counts[p][o] *= self.cfg.count_decay\n",
    "                    if self.edge_counts[p][o] < 1e-12:\n",
    "                        self.edge_counts[p].pop(o, None)\n",
    "        if self.cfg.trace_decay != 1.0:\n",
    "            for s in list(self.E.keys()):\n",
    "                for u in self.us_classes:\n",
    "                    self.E[s][u] *= self.cfg.trace_decay\n",
    "                self.exposure[s] *= self.cfg.trace_decay\n",
    "                self.C[s] *= self.cfg.trace_decay\n",
    "        if self.cfg.retro_decay != 1.0:\n",
    "            for u in self.us_classes:\n",
    "                self.us_episode_ema[u] *= self.cfg.retro_decay\n",
    "            for s in list(self.cs_us_presence_ema.keys()):\n",
    "                for u in self.us_classes:\n",
    "                    self.cs_us_presence_ema[s][u] *= self.cfg.retro_decay\n",
    "\n",
    "        # 1) update transition counts along the episode\n",
    "        visited = set(latent)\n",
    "        for sid in visited:\n",
    "            self.presence_episodes[sid] = self.presence_episodes.get(sid, 0) + 1\n",
    "\n",
    "        for t in range(len(latent) - 1):\n",
    "            p = latent[t]\n",
    "            nxt_obs = obs_seq[t + 1]\n",
    "            self.edge_counts.setdefault(p, {})\n",
    "            self.edge_counts[p][nxt_obs] = self.edge_counts[p].get(nxt_obs, 0.0) + 1.0\n",
    "\n",
    "        # 2) retrospective EMA: which US occurred in this episode?\n",
    "        us_present = {u: any(o == u for o in obs_seq) for u in self.us_classes}\n",
    "        for u, pres in us_present.items():\n",
    "            if pres:\n",
    "                self.us_episode_ema[u] = self.us_episode_ema.get(u, 0.0) + 1.0\n",
    "                for sid in visited:\n",
    "                    self._ensure_state_structs(sid)\n",
    "                    self.cs_us_presence_ema[sid][u] = self.cs_us_presence_ema[sid].get(u, 0.0) + 1.0\n",
    "\n",
    "        # 3) contextual eligibility traces (Alg 1): snapshot trace at each time\n",
    "        decay = self.cfg.gamma * self.cfg.lam\n",
    "        trace: Dict[int, float] = {}\n",
    "        snapshots: List[Dict[int, float]] = []\n",
    "        for sid in latent:\n",
    "            # decay trace\n",
    "            for k in list(trace.keys()):\n",
    "                trace[k] *= decay\n",
    "                if trace[k] < 1e-12:\n",
    "                    trace.pop(k, None)\n",
    "            trace[sid] = trace.get(sid, 0.0) + 1.0\n",
    "            snapshots.append(dict(trace))\n",
    "\n",
    "        # 4) add snapshot mass at each US event time to E[*][u]\n",
    "        for t, o in enumerate(obs_seq):\n",
    "            if o not in self.us_classes:\n",
    "                continue\n",
    "            snap = snapshots[t]\n",
    "            u = o\n",
    "            for k, v in snap.items():\n",
    "                self._ensure_state_structs(k)\n",
    "                self.E[k][u] = self.E[k].get(u, 0.0) + v\n",
    "                self.exposure[k] = self.exposure.get(k, 0.0) + v\n",
    "                # evidence proxy tracks total mass credited to any US\n",
    "                self.C[k] = self.C.get(k, 0.0) + v\n",
    "\n",
    "        # 5) split / merge updates (Alg 2)\n",
    "        self._maybe_split()\n",
    "        self._maybe_merge()\n",
    "\n",
    "        return latent\n",
    "\n",
    "    # ---------------------\n",
    "    # Split / merge (Alg 2)\n",
    "    # ---------------------\n",
    "\n",
    "    def _maybe_split(self) -> None:\n",
    "        # consider all currently alive states\n",
    "        for sid in list(self.states.keys()):\n",
    "            if not self.states[sid].get('alive', True):\n",
    "                continue\n",
    "            if sid in self.salient:\n",
    "                continue\n",
    "\n",
    "            # evidence gates\n",
    "            if self.presence_episodes.get(sid, 0) < self.cfg.min_presence_episodes:\n",
    "                continue\n",
    "            if self.exposure.get(sid, 0.0) < self.cfg.min_effective_exposure:\n",
    "                continue\n",
    "            if self.C.get(sid, 0.0) < self.cfg.n_threshold:\n",
    "                continue\n",
    "\n",
    "            u_star, phat, n_eff = self._winning_us_and_pc(sid)\n",
    "            lb = wilson_lower_bound(phat, n_eff, confidence=self.cfg.split_confidence)\n",
    "            if lb <= self.cfg.theta_split:\n",
    "                continue\n",
    "\n",
    "            # Become salient cue. Label path by winning US.\n",
    "            label = \"R1\" if u_star == self.us_classes[0] else \"R2\"\n",
    "            self.salient[sid] = (label, u_star)\n",
    "\n",
    "            # Split: clone *all outgoing successors* and rewire edges sid->clone(succ)\n",
    "            self._split_cue_successors(sid, label)\n",
    "\n",
    "    def _split_cue_successors(self, cue_sid: int, label: str) -> None:\n",
    "        out = self.edges.get(cue_sid, {})\n",
    "        if cue_sid not in self.cue_to_clones:\n",
    "            self.cue_to_clones[cue_sid] = set()\n",
    "\n",
    "        # iterate over snapshot because we mutate\n",
    "        for nxt_obs, child_sid in list(out.items()):\n",
    "            # avoid repeated cloning if already a cue-descendant clone\n",
    "            if self._is_descendant_of(child_sid, cue_sid):\n",
    "                continue\n",
    "            clone_sid = self._clone_node(child_sid, root_cue=cue_sid, path_label=label)\n",
    "            out[nxt_obs] = clone_sid\n",
    "            self.cue_to_clones[cue_sid].add(clone_sid)\n",
    "\n",
    "        self.edges[cue_sid] = out\n",
    "\n",
    "    def _edge_mass_to_descendants(self, cue_sid: int) -> float:\n",
    "        \"\"\"Fraction of cue's outgoing transition count mass that goes to descendants of cue.\"\"\"\n",
    "        counts = self.edge_counts.get(cue_sid, {})\n",
    "        if not counts:\n",
    "            return 0.0\n",
    "        tot = sum(counts.values())\n",
    "        if tot <= 0:\n",
    "            return 0.0\n",
    "        mass = 0.0\n",
    "        out = self.edges.get(cue_sid, {})\n",
    "        for nxt_obs, cnt in counts.items():\n",
    "            child = out.get(nxt_obs, None)\n",
    "            if child is not None and self._is_descendant_of(child, cue_sid):\n",
    "                mass += cnt\n",
    "        return mass / tot\n",
    "\n",
    "    def _maybe_merge(self) -> None:\n",
    "        if self.cfg.theta_merge <= 0:\n",
    "            return\n",
    "\n",
    "        for cue_sid in list(self.salient.keys()):\n",
    "            if not self.states[cue_sid].get('alive', True):\n",
    "                self.salient.pop(cue_sid, None)\n",
    "                continue\n",
    "\n",
    "            # Compute utility using cue's winning US\n",
    "            label, u_star = self.salient[cue_sid]\n",
    "            # recompute PC on current stats\n",
    "            u_star_now, phat, _ = self._winning_us_and_pc(cue_sid)\n",
    "            # keep u_star from salience unless it vanished\n",
    "            if self.C.get(cue_sid, 0.0) > 0:\n",
    "                u_use = u_star\n",
    "            else:\n",
    "                u_use = u_star_now\n",
    "\n",
    "            rc = self.retrospective(cue_sid, u_use)\n",
    "            util = phat * rc\n",
    "\n",
    "            # extra merge safeguard from python file\n",
    "            edge_mass = self._edge_mass_to_descendants(cue_sid)\n",
    "\n",
    "            if (util < self.cfg.theta_merge) or (edge_mass < self.cfg.edge_eps):\n",
    "                self._merge_descendants_of_cue(cue_sid)\n",
    "                self.salient.pop(cue_sid, None)\n",
    "\n",
    "    def _merge_descendants_of_cue(self, cue_sid: int) -> None:\n",
    "        \"\"\"\n",
    "        Merge all descendants (clones with root_cue==cue_sid) back into originals:\n",
    "          - redirect edges that point to descendants back to descendant.original\n",
    "          - mark descendant nodes as inactive (alive=False)\n",
    "        \"\"\"\n",
    "        descendants = {sid for sid, st in self.states.items()\n",
    "                       if st.get('alive', True) and st.get('root_cue', None) == cue_sid}\n",
    "        if not descendants:\n",
    "            return\n",
    "\n",
    "        # Redirect all incoming edges\n",
    "        for p in list(self.edges.keys()):\n",
    "            for nxt_obs, child in list(self.edges[p].items()):\n",
    "                if child in descendants:\n",
    "                    orig = self.states[child].get('original', child)\n",
    "                    self.edges[p][nxt_obs] = orig\n",
    "\n",
    "        # Deactivate descendants (keep ids stable for notebook)\n",
    "        for sid in descendants:\n",
    "            self.states[sid]['alive'] = False\n",
    "\n",
    "    # ---------------------\n",
    "    # Notebook interface\n",
    "    # ---------------------\n",
    "\n",
    "    def run_episode(self, obs_seq, learn: bool = True):\n",
    "        return self.update_with_episode(list(obs_seq), learn=learn)\n",
    "\n",
    "    def encode_sequence(self, obs_seq) -> np.ndarray:\n",
    "        lat = self.run_episode(obs_seq, learn=False)\n",
    "        S = self._next_sid\n",
    "        X = np.zeros((len(lat), S), dtype=float)\n",
    "        for t, sid in enumerate(lat):\n",
    "            if self.states.get(sid, {}).get('alive', True):\n",
    "                X[t, sid] = 1.0\n",
    "            else:\n",
    "                # If a merged-out state appears (should be rare), fall back to its original\n",
    "                orig = self.states.get(sid, {}).get('original', sid)\n",
    "                if orig < S:\n",
    "                    X[t, orig] = 1.0\n",
    "        return X[:, :self._next_sid]\n",
    "\n",
    "    def near_far_corr(self, near_seq, far_seq) -> np.ndarray:\n",
    "        A = self.encode_sequence(near_seq)\n",
    "        B = self.encode_sequence(far_seq)\n",
    "        C = np.zeros((A.shape[0], B.shape[0]))\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(B.shape[0]):\n",
    "                a = A[i]; b = B[j]\n",
    "                if np.allclose(a, 0) or np.allclose(b, 0):\n",
    "                    C[i, j] = 0.0\n",
    "                    continue\n",
    "                a0 = a - a.mean()\n",
    "                b0 = b - b.mean()\n",
    "                den = (np.linalg.norm(a0) * np.linalg.norm(b0))\n",
    "                C[i, j] = (a0 @ b0) / den if den > 0 else 0.0\n",
    "        return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_RUNS=6; SESSIONS=9; TRIALS_PER_SESSION=80; THRESH=0.3\n",
    "def block_mean(C, pairs): \n",
    "    return float(np.mean([C[i,j] for (i,j) in pairs])) if pairs else np.nan\n",
    "rng=np.random.default_rng(123)\n",
    "all_final_blocks=[]; all_time_to_thr=[]; mat_by_session={s:[] for s in [1,3,4,9]}\n",
    "checkpoint_sessions=[1,3,4,9]; demo_checkpoints={}\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    agent=CoDAUncAgent(obs_symbols=sorted(set(near)|set(far)), cfg=UncCfg())\n",
    "    tt={'offdiag':None,'preR2':None,'preR1':None}\n",
    "    for session in range(1, SESSIONS+1):\n",
    "        episodes=[near]*(TRIALS_PER_SESSION//2)+[far]*(TRIALS_PER_SESSION//2)\n",
    "        rng.shuffle(episodes)\n",
    "        for ep in episodes: agent.run_episode(ep, learn=True)\n",
    "        C=agent.near_far_corr(near, far)\n",
    "        if session in mat_by_session: mat_by_session[session].append(C)\n",
    "        if run==0 and session in checkpoint_sessions:\n",
    "            snap=CoDAUncAgent(obs_symbols=sorted(set(near)|set(far)), cfg=agent.cfg)\n",
    "            snap.states={k:v.copy() for k,v in agent.states.items()}\n",
    "            snap._next_sid=agent._next_sid\n",
    "            snap.obs_to_state_ids={k:list(v) for k,v in agent.obs_to_state_ids.items()}\n",
    "            snap.co_occ={k:dict(v) for k,v in agent.co_occ.items()}\n",
    "            snap.exposure=dict(agent.exposure); snap.presence_episodes=dict(agent.presence_episodes)\n",
    "            snap.salient=dict(agent.salient); demo_checkpoints[session]=snap\n",
    "        b_off=block_mean(C,offdiag_pairs); b_r2=block_mean(C,same_preR2_pairs); b_r1=block_mean(C,same_preR1_pairs)\n",
    "        if tt['offdiag'] is None and b_off<THRESH: tt['offdiag']=session\n",
    "        if tt['preR2']  is None and b_r2<THRESH: tt['preR2']=session\n",
    "        if tt['preR1']  is None and b_r1<THRESH: tt['preR1']=session\n",
    "    C_final=agent.near_far_corr(near, far)\n",
    "    all_final_blocks.append((run, block_mean(C_final, offdiag_pairs), block_mean(C_final, same_preR2_pairs), block_mean(C_final, same_preR1_pairs)))\n",
    "    def norm(x): return x/SESSIONS if x is not None else np.nan\n",
    "    all_time_to_thr.append((run, norm(tt['offdiag']), norm(tt['preR2']), norm(tt['preR1'])))\n",
    "\n",
    "\n",
    "    print(\"salient cues:\", agent.salient)   # should become non-empty\n",
    "    print(\"num clones:\", sum(1 for s in agent.states.values() if s.get(\"is_clone\", False)))\n",
    "    for cue, clones in getattr(agent, \"cue_to_clones\", {}).items():\n",
    "        print(\"cue\", cue, \"-> #clones\", len(clones))\n",
    "\n",
    "\n",
    "blocks_df=pd.DataFrame(all_final_blocks, columns=['run','offdiag','preR2','preR1']).set_index('run')\n",
    "times_df =pd.DataFrame(all_time_to_thr, columns=['run','offdiag_t','preR2_t','preR1_t']).set_index('run')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def canonical_latents(agent, seq):\n",
    "    lat = agent.run_episode(seq, learn=False)\n",
    "    out = []\n",
    "    for t, (obs, sid) in enumerate(zip(seq, lat)):\n",
    "        if obs == 0:\n",
    "            break\n",
    "        out.append((t, obs, sid, agent.states[sid]['path']))\n",
    "    return out\n",
    "\n",
    "\n",
    "def ring_positions(T: int, r_base=1.0, r_near=1.12, r_far=0.88, start_angle=np.pi/2):\n",
    "    pos_by_t = {}\n",
    "    for t in range(T):\n",
    "        theta = start_angle - 2 * np.pi * (t / max(T, 1))\n",
    "        pos_by_t[t] = {\n",
    "            'theta': theta,\n",
    "            'base': (r_base * np.cos(theta), r_base * np.sin(theta)),\n",
    "            'R1': (r_near * np.cos(theta), r_near * np.sin(theta)),\n",
    "            'R2': (r_far * np.cos(theta), r_far * np.sin(theta)),\n",
    "        }\n",
    "    return pos_by_t\n",
    "\n",
    "\n",
    "def build_color_assignments(scheme: str, near_lat, far_lat):\n",
    "    import matplotlib as mpl\n",
    "\n",
    "    colors = {'near': {}, 'far': {}}\n",
    "\n",
    "    def set_color(target, lat_seq, fn):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            target[(t, ring)] = fn(t, obs, sid, ring)\n",
    "\n",
    "    if scheme == 'state_id':\n",
    "        tab20 = mpl.cm.get_cmap('tab20')\n",
    "        set_color(colors['near'], near_lat, lambda t, o, s, ring: tab20(s % 20))\n",
    "        set_color(colors['far'],  far_lat,  lambda t, o, s, ring: tab20(s % 20))\n",
    "\n",
    "    elif scheme == 'obs_step':\n",
    "        hsv = mpl.cm.get_cmap('hsv')\n",
    "        set_color(colors['near'], near_lat, lambda t, o, s, ring: hsv((t % 26) / 26.0))\n",
    "        set_color(colors['far'],  far_lat,  lambda t, o, s, ring: hsv((t % 26) / 26.0))\n",
    "\n",
    "    else:\n",
    "        # Default: color-code by the \"third element\" (latent state id) with overrides\n",
    "        unique_sids = sorted({sid for (_, _, sid, _) in near_lat + far_lat})\n",
    "        cmap = mpl.cm.get_cmap('tab20', max(1, len(unique_sids)))\n",
    "        sid_to_color = {sid: cmap(i % cmap.N) for i, sid in enumerate(unique_sids)}\n",
    "        overrides = {1: '#b3b3b3', 5: '#9467bd', 9: '#6a6a6a', 11: '#000000', 6: '#d62728', 8: '#d62728'}\n",
    "        sid_to_color.update({sid: color for sid, color in overrides.items() if sid in unique_sids})\n",
    "\n",
    "        set_color(colors['near'], near_lat, lambda t, o, s, ring: sid_to_color[s])\n",
    "        set_color(colors['far'],  far_lat,  lambda t, o, s, ring: sid_to_color[s])\n",
    "\n",
    "    return colors\n",
    "\n",
    "\n",
    "def draw_cscg_style_ring(\n",
    "    ax,\n",
    "    agent,\n",
    "    title=None,\n",
    "    scheme='blocks',\n",
    "    close_loop=True,\n",
    "    edge_color='#5a5a5a',\n",
    "    edge_lw=2.2,\n",
    " ):\n",
    "    # --- build sequences and ring geometry ---\n",
    "    near_lat = canonical_latents(agent, near)\n",
    "    far_lat = canonical_latents(agent, far)\n",
    "    T = max(len(near_lat), len(far_lat))\n",
    "    pos = ring_positions(T)\n",
    "\n",
    "    # --- node colors and occupancy ---\n",
    "    node_colors = build_color_assignments(scheme, near_lat, far_lat)\n",
    "    from collections import defaultdict\n",
    "    occupancy = defaultdict(list)\n",
    "    sid_shared = set()\n",
    "    near_by_t = {t: sid for (t, _, sid, _) in near_lat}\n",
    "    far_by_t = {t: sid for (t, _, sid, _) in far_lat}\n",
    "    for t, sid in near_by_t.items():\n",
    "        if far_by_t.get(t) == sid:\n",
    "            sid_shared.add((t, sid))\n",
    "    for label, lat_seq in (('near', near_lat), ('far', far_lat)):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            occupancy[(t, ring)].append((label, sid))\n",
    "\n",
    "    node_positions = {}\n",
    "    offset_mag = 0.07\n",
    "    radial_offset = 0.09\n",
    "    prev_pos = {'near': None, 'far': None}\n",
    "    all_times = sorted({t for (t, _) in occupancy.keys()})\n",
    "    rings_order = ['base', 'R1', 'R2']\n",
    "    force_swap_times = {6, 19}\n",
    "    arrow_mutation = 14.0\n",
    "\n",
    "    for t in all_times:\n",
    "        for ring in rings_order:\n",
    "            key = (t, ring)\n",
    "            if key not in occupancy:\n",
    "                continue\n",
    "            entries = occupancy[key]\n",
    "            base_x, base_y = pos[t][ring]\n",
    "            sids = {sid for (_, sid) in entries}\n",
    "            shared_here = any((t, sid) in sid_shared for (_, sid) in entries)\n",
    "            if len(entries) == 1 or (len(sids) == 1 and shared_here):\n",
    "                for label, sid in entries:\n",
    "                    node_positions[(label, t, ring)] = (base_x, base_y)\n",
    "                    prev_pos[label] = (base_x, base_y)\n",
    "                continue\n",
    "            labels_here = {label for (label, _) in entries}\n",
    "            vx, vy = base_x, base_y\n",
    "            norm = (vx * vx + vy * vy) ** 0.5\n",
    "            if norm == 0.0:\n",
    "                ux, uy = 1.0, 0.0\n",
    "            else:\n",
    "                ux, uy = vx / norm, vy / norm\n",
    "            if len(entries) == 2 and labels_here == {'near', 'far'}:\n",
    "                def assign(sign_map):\n",
    "                    out = {}\n",
    "                    for label, sid in entries:\n",
    "                        direction = radial_offset * sign_map[label]\n",
    "                        out[label] = (base_x + direction * ux, base_y + direction * uy)\n",
    "                    return out\n",
    "\n",
    "                default_map = {'near': 1.0, 'far': -1.0}\n",
    "                swapped_map = {'near': -1.0, 'far': 1.0}\n",
    "\n",
    "                def mapping_cost(mapped):\n",
    "                    cost = 0.0\n",
    "                    for label, (x, y) in mapped.items():\n",
    "                        prev = prev_pos.get(label)\n",
    "                        if prev is None:\n",
    "                            continue\n",
    "                        px, py = prev\n",
    "                        cost += (x - px) * (x - px) + (y - py) * (y - py)\n",
    "                    return cost\n",
    "\n",
    "                opt_default = assign(default_map)\n",
    "                opt_swapped = assign(swapped_map)\n",
    "                if t in force_swap_times:\n",
    "                    chosen = opt_swapped\n",
    "                elif mapping_cost(opt_swapped) < mapping_cost(opt_default):\n",
    "                    chosen = opt_swapped\n",
    "                else:\n",
    "                    chosen = opt_default\n",
    "                for label, coords in chosen.items():\n",
    "                    node_positions[(label, t, ring)] = coords\n",
    "                    prev_pos[label] = coords\n",
    "                continue\n",
    "            if len(entries) == 1:\n",
    "                label, sid = entries[0]\n",
    "                node_positions[(label, t, ring)] = (base_x, base_y)\n",
    "                prev_pos[label] = (base_x, base_y)\n",
    "                continue\n",
    "            if norm == 0.0:\n",
    "                px, py = 0.0, 1.0\n",
    "            else:\n",
    "                px, py = -vy / norm, vx / norm\n",
    "            ordered = sorted(entries, key=lambda item: item[0])\n",
    "            span = len(ordered) - 1\n",
    "            for idx, (label, sid) in enumerate(ordered):\n",
    "                factor = idx - span / 2.0\n",
    "                coords = (base_x + factor * offset_mag * px, base_y + factor * offset_mag * py)\n",
    "                node_positions[(label, t, ring)] = coords\n",
    "                prev_pos[label] = coords\n",
    "\n",
    "    def node_xy(label, t, ring):\n",
    "        return node_positions[(label, t, ring)]\n",
    "\n",
    "    def draw_edges(lat_seq, label, z=1):\n",
    "        for i in range(len(lat_seq) - 1):\n",
    "            t, _, _, p = lat_seq[i]\n",
    "            t2, _, _, p2 = lat_seq[i + 1]\n",
    "            r1 = 'base' if p is None else p\n",
    "            r2 = 'base' if p2 is None else p2\n",
    "            x1, y1 = node_xy(label, t, r1)\n",
    "            x2, y2 = node_xy(label, t2, r2)\n",
    "            ax.add_patch(\n",
    "                FancyArrowPatch(\n",
    "                    (x1, y1),\n",
    "                    (x2, y2),\n",
    "                    arrowstyle='-|>',\n",
    "                    mutation_scale=arrow_mutation,\n",
    "                    lw=edge_lw,\n",
    "                    color=edge_color,\n",
    "                    alpha=0.9,\n",
    "                    shrinkA=2.5,\n",
    "                    shrinkB=2.5,\n",
    "                    zorder=z,\n",
    "                )\n",
    "            )\n",
    "        if close_loop and len(lat_seq) >= 2:\n",
    "            t0, _, _, p0 = lat_seq[0]\n",
    "            tL, _, _, pL = lat_seq[-1]\n",
    "            r0 = 'base' if p0 is None else p0\n",
    "            rL = 'base' if pL is None else pL\n",
    "            x1, y1 = node_xy(label, tL, rL)\n",
    "            x2, y2 = node_xy(label, t0, r0)\n",
    "            ax.add_patch(\n",
    "                FancyArrowPatch(\n",
    "                    (x1, y1),\n",
    "                    (x2, y2),\n",
    "                    arrowstyle='-|>',\n",
    "                    mutation_scale=arrow_mutation,\n",
    "                    lw=edge_lw,\n",
    "                    color=edge_color,\n",
    "                    alpha=0.9,\n",
    "                    shrinkA=2.5,\n",
    "                    shrinkB=2.5,\n",
    "                    zorder=z,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def draw_nodes(lat_seq, label, z=3):\n",
    "        for (t, obs, sid, path) in lat_seq:\n",
    "            ring = 'base' if path is None else path\n",
    "            x, y = node_xy(label, t, ring)\n",
    "            face = node_colors[label].get((t, ring), '#bfbfbf')\n",
    "            ax.add_patch(\n",
    "                Circle(\n",
    "                    (x, y),\n",
    "                    radius=0.065,\n",
    "                    facecolor=face,\n",
    "                    edgecolor='#3a3a3a',\n",
    "                    lw=1.1,\n",
    "                    alpha=0.98,\n",
    "                    zorder=z,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    draw_edges(near_lat, 'near', z=1)\n",
    "    draw_edges(far_lat, 'far', z=1)\n",
    "    draw_nodes(far_lat, 'far', z=3)\n",
    "    draw_nodes(near_lat, 'near', z=4)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(-1.55, 1.55)\n",
    "    ax.set_ylim(-1.55, 1.55)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_lat = canonical_latents(demo_checkpoints[4], near)\n",
    "near_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "far_lat = canonical_latents(demo_checkpoints[4], far)\n",
    "far_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"figures/poster\", exist_ok=True)\n",
    "\n",
    "export_specs = [\n",
    "    (\"svg\", {\"format\": \"svg\"}),\n",
    "    (\"pdf\", {\"format\": \"pdf\"}),\n",
    "    (\"png\", {\"format\": \"png\", \"dpi\": 400})\n",
    "]\n",
    "\n",
    "final_session = max([s for s in [1, 3, 4, 9] if s in demo_checkpoints])\n",
    "fig, ax = plt.subplots(figsize=(7.4, 4.6), constrained_layout=True)\n",
    "draw_cscg_style_ring(\n",
    "    ax,\n",
    "    demo_checkpoints[final_session],\n",
    "    title=\"CoDA — transition graph (CSCG-style colors)\",\n",
    "    scheme='blocks'\n",
    ")\n",
    "for ext, kwargs in export_specs:\n",
    "    fig.savefig(\n",
    "        os.path.join(\"figures\", \"poster\", f\"coda_transition_final_session.{ext}\"),\n",
    "        bbox_inches='tight',\n",
    "        **kwargs\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "for s in sorted(demo_checkpoints.keys()):\n",
    "    fig_s, ax_s = plt.subplots(figsize=(7.4, 4.6), constrained_layout=True)\n",
    "    draw_cscg_style_ring(\n",
    "        ax_s,\n",
    "        demo_checkpoints[s],\n",
    "        title=f\"Session {s}\",\n",
    "        scheme='blocks'\n",
    "    )\n",
    "    for ext, kwargs in export_specs:\n",
    "        fig_s.savefig(\n",
    "            os.path.join(\"figures\", \"poster\", f\"coda_transition_session_{s}.{ext}\"),\n",
    "            bbox_inches='tight',\n",
    "            **kwargs\n",
    "        )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Trajectory of decorrelation during learning (CSCG-style) ===\n",
    "import matplotlib as mpl\n",
    "\n",
    "check_sessions = [1, 3, 4, 9]\n",
    "mean_mats = {s: np.mean(mat_by_session[s], axis=0) for s in check_sessions}\n",
    "\n",
    "# CSCG-style colormap (dark background, warm high values)\n",
    "# 'magma' or 'inferno' gives similar look; both start dark→warm→bright\n",
    "cmap = mpl.cm.get_cmap('magma')\n",
    "\n",
    "# Pre/indicator windows to highlight (indices are inclusive, 0-based)\n",
    "highlight_windows = [(6, 10), (13, 15), (18, 20)]\n",
    "dash_lines = [6, 10, 13, 15, 18, 20]\n",
    "\n",
    "# Make independent figures for each checkpoint session\n",
    "for s in check_sessions:\n",
    "    fig, ax = plt.subplots(figsize=(4.8, 4.8), constrained_layout=True)\n",
    "\n",
    "    last_im = ax.imshow(\n",
    "        mean_mats[s],\n",
    "        vmin=-0.1,\n",
    "        vmax=1.0,\n",
    "        cmap=cmap,\n",
    "        origin='upper',\n",
    "        aspect='equal',\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    ny, nx = mean_mats[s].shape\n",
    "    ax.set_xticks(np.arange(-0.5, nx, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, ny, 1), minor=True)\n",
    "    ax.grid(which='minor', color='white', linestyle=':', linewidth=0.4)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(colors='white', labelsize=0, length=0)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    for idx in dash_lines:\n",
    "        if idx <= nx:\n",
    "            ax.axvline(idx - 0.5, color='white', linewidth=1.2, linestyle=(0, (2, 4)))\n",
    "        if idx <= ny:\n",
    "            ax.axhline(idx - 0.5, color='white', linewidth=1.2, linestyle=(0, (2, 4)))\n",
    "\n",
    "    for low, high in highlight_windows:\n",
    "        if high <= min(nx, ny):\n",
    "            x0, x1 = low - 0.5, high - 0.5\n",
    "            y0, y1 = low - 0.5, high - 0.5\n",
    "            ax.plot(\n",
    "                [x0, x1, x1, x0, x0],\n",
    "                [y0, y0, y1, y1, y0],\n",
    "                color='white',\n",
    "                linewidth=2.5\n",
    "            )\n",
    "\n",
    "    fig.patch.set_facecolor('black')\n",
    "    ax.set_facecolor('black')\n",
    "\n",
    "    cbar = fig.colorbar(last_im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"\")\n",
    "    cbar.set_ticks([])\n",
    "    cbar.ax.tick_params(length=0)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fig. 4i\n",
    "means = blocks_df.mean(); ses = blocks_df.sem()\n",
    "labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels)); y = [means[l] for l in labels]; yerr = [ses[l] for l in labels]\n",
    "fig, ax = plt.subplots(figsize=(6.5,4.6))\n",
    "bars = ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(labels)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Mean correlation (final)\")\n",
    "ax.set_title(\"CoDA (uncertainty‑aware) — Fig. 4i analogue\")\n",
    "for i, (b, val) in enumerate(zip(bars, y)):\n",
    "    ax.text(b.get_x()+b.get_width()/2, (val-0.05 if val>0.85 else min(1.02, val+0.05)), f\"{val:.2f}\", ha='center',\n",
    "            va=('top' if val>0.85 else 'bottom'), color=('white' if val>0.85 else 'black'), fontsize=9)\n",
    "fig.tight_layout(); plt.show()\n",
    "\n",
    "# Fig. 4j\n",
    "means_t = times_df.mean(skipna=True); ses_t = times_df.sem(skipna=True)\n",
    "labels_t = ['offdiag_t','preR2_t','preR1_t']; disp = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels_t)); y = [means_t[l] for l in labels_t]; yerr = [ses_t[l] for l in labels_t]\n",
    "fig, ax = plt.subplots(figsize=(6.5,4.6))\n",
    "bars = ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(disp)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Fraction of training (first corr < 0.3)\")\n",
    "ax.set_title(\"CoDA (uncertainty‑aware) — Fig. 4j analogue\")\n",
    "for i, (b, val) in enumerate(zip(bars, y)):\n",
    "    ax.text(b.get_x()+b.get_width()/2, min(1.02, val+0.05), f\"{val:.2f}\", ha='center', va='bottom', fontsize=9)\n",
    "fig.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
