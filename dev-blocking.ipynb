{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import trange\n",
    "import copy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import igraph\n",
    "from matplotlib import cm, colors\n",
    "random.seed(42)\n",
    "import seaborn as sns\n",
    "from spatial_environments import * #ContinuousTMaze, GridEnvRightDownNoCue, GridEnvRightDownNoSelf, GridEnvDivergingMultipleReward, GridEnvDivergingSingleReward\n",
    "from util import *\n",
    "import itertools, random\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm.auto import trange\n",
    "# from util import transition_matrix_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "CoDA evaluation – clone‑aware KL curve\n",
    "=====================================\n",
    "* Runs online CoDA learning under several random seeds.\n",
    "* Computes KL divergence **after aligning clone indices** between the\n",
    "  ground‑truth tensor (built offline) and the online tensor.\n",
    "* Plots mean ± SE learning curve and prints the headline drop.\n",
    "\n",
    "The script depends on all helper functions and classes used in your\n",
    "original notebook (GridEnv*, generate_dataset, etc.).  Put this file in\n",
    "the same folder or add that folder to PYTHONPATH.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# ---------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import trange\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. Row‑normalisation helper\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _renorm_rows(P: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    \"\"\"Row-normalise each (state, action) categorical distribution.\n",
    "    Safe for broadcast: P shape (S, A, S).\n",
    "    \"\"\"\n",
    "    P = P.copy()\n",
    "    row_sum = P.sum(axis=-1, keepdims=True)            # (S, A, 1)\n",
    "    # Avoid division by zero: where sum==0 leave row unchanged (all zeros)\n",
    "    P = np.divide(P, np.where(row_sum == 0, 1, row_sum), dtype=P.dtype)\n",
    "    return P + eps\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. Alignment utilities (keep clones separate)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def build_alignment(\n",
    "    env_ref,          # environment with GT tensor\n",
    "    env_cmp,          # environment with online tensor\n",
    "    grid_size: int    # e.g. 16 for 4×4 grid\n",
    ") -> Tuple[Dict[int, int], Dict[int, int], int]:\n",
    "    \"\"\"Return two mapping dicts (ref→canon, cmp→canon) and canonical size.\"\"\"\n",
    "    # Identity for base grid states 0‥grid_size‑1\n",
    "    ref2can = {s: s for s in range(grid_size)}\n",
    "    cmp2can = {s: s for s in range(grid_size)}\n",
    "    next_idx = grid_size\n",
    "\n",
    "    # Gather *all* clones that exist in either env\n",
    "    clones_ref = set(env_ref.clone_dict.keys())\n",
    "    clones_cmp = set(env_cmp.clone_dict.keys())\n",
    "    all_clones = sorted(clones_ref | clones_cmp)\n",
    "\n",
    "    for c in all_clones:\n",
    "        if c in ref2can or c in cmp2can:\n",
    "            continue  # already assigned (shared clone id)\n",
    "        ref2can[c] = next_idx\n",
    "        cmp2can[c] = next_idx\n",
    "        next_idx += 1\n",
    "\n",
    "    return ref2can, cmp2can, next_idx  # S_canonical = next_idx\n",
    "\n",
    "\n",
    "def project_tensor(P: np.ndarray, mapping: Dict[int, int], S_can: int) -> np.ndarray:\n",
    "    \"\"\"Re‑index rows/cols of *P* into canonical shape (S_can, A, S_can).\"\"\"\n",
    "    S_src, A, _ = P.shape\n",
    "    P_can = np.zeros((S_can, A, S_can), dtype=P.dtype)\n",
    "    for s in range(S_src):\n",
    "        if s not in mapping:\n",
    "            continue\n",
    "        row = mapping[s]\n",
    "        for a in range(A):\n",
    "            for sp in np.nonzero(P[s, a])[0]:\n",
    "                if sp not in mapping:\n",
    "                    continue\n",
    "                col = mapping[sp]\n",
    "                P_can[row, a, col] = P[s, a, sp]\n",
    "    return P_can\n",
    "\n",
    "\n",
    "def aligned_kl(\n",
    "    P_true: np.ndarray,\n",
    "    env_true,\n",
    "    P_model: np.ndarray,\n",
    "    env_model,\n",
    "    grid_size: int,\n",
    "    eps: float = 1e-12,\n",
    ") -> float:\n",
    "    \"\"\"KL after aligning clone indices *without collapsing* clones.\"\"\"\n",
    "    ref2can, cmp2can, S_can = build_alignment(env_true, env_model, grid_size)\n",
    "\n",
    "    Pt = _renorm_rows(project_tensor(P_true,  ref2can, S_can), eps)\n",
    "    Pm = _renorm_rows(project_tensor(P_model, cmp2can, S_can), eps)\n",
    "\n",
    "    kl = (Pt * np.log(Pt / Pm)).sum(axis=-1)  # shape (S_can, A)\n",
    "    mask = Pt.sum(axis=-1) > 0               # rows with mass in GT\n",
    "    return kl[mask].mean()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. Offline ground‑truth builder (unchanged logic, now returns env)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# def latent_inhibition(\n",
    "#     *,\n",
    "#     seed: int,\n",
    "#     size: int = 4,\n",
    "#     n_episodes: int = 1000,\n",
    "#     max_steps: int = 100,\n",
    "#     iterations: int = 100,\n",
    "#     cue = 5,\n",
    "# ) -> Tuple[np.ndarray, 'GridEnvRightDownNoSelf']:\n",
    "#     \"\"\"Run the offline splitter to obtain fully expanded GT tensor.\"\"\"\n",
    "#     env_size = (size, size)\n",
    "#     rewarded_terminal = [env_size[0]*env_size[1]-1]\n",
    "#     cue_states = [cue]\n",
    "\n",
    "#     env = GridEnvRightDownNoSelf(env_size=env_size,\n",
    "#                                  rewarded_terminal=rewarded_terminal,\n",
    "#                                  cue_states=cue_states,\n",
    "#                                  seed=seed)\n",
    "\n",
    "#     dataset = generate_dataset(env, n_episodes, max_steps)\n",
    "    \n",
    "#     extinction = [[[16 if x == 15 else x for x in idxs], labels]\n",
    "#            for idxs, labels in dataset]\n",
    "#     # dataset = extinction\n",
    "    \n",
    "    \n",
    "    \n",
    "#     transition_counts = transition_matrix_action(extinction_data)\n",
    "#     denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "#     denominators[denominators == 0] = 1\n",
    "#     transition_probs = transition_counts / denominators\n",
    "\n",
    "#     used_cues = []\n",
    "#     for _ in range(iterations):\n",
    "#         ent = compute_transition_entropies(transition_probs)\n",
    "#         pairs = find_stochastic_state_actions_by_entropy(ent, eps=1e-9)\n",
    "#         if not pairs:\n",
    "#             break\n",
    "#         cues_tmp = []\n",
    "#         for s, a in pairs:\n",
    "#             spr1, spr2 = get_successor_states(transition_counts, s, a)\n",
    "#             cue = calculate_backward_contingency(dataset, spr1, spr2, env_size)\n",
    "#             cues_tmp.append(cue)\n",
    "#         unique_cues = np.unique([x for sub in cues_tmp for x in sub])\n",
    "#         for cue in unique_cues:\n",
    "#             if cue in used_cues:\n",
    "#                 continue\n",
    "#             used_cues.append(cue)\n",
    "#             valid_actions = env.get_valid_actions(env.clone_dict.get(cue, cue))\n",
    "#             for a in valid_actions:\n",
    "#                 succ = get_successor_states(transition_counts, cue, a)[0]\n",
    "#                 if succ in env.reverse_clone_dict:\n",
    "#                     clone = env.reverse_clone_dict[succ]\n",
    "#                 else:\n",
    "#                     clone = len(get_unique_states(dataset))\n",
    "#                     env.add_clone_dict(clone, succ)\n",
    "#                     env.add_reverse_clone_dict(clone, succ)\n",
    "#                 for d, seq in enumerate(dataset):\n",
    "#                     if has_state(seq[0], succ) and has_transition(cue, succ, seq[0]):\n",
    "#                         dataset[d][0] = [clone if x == succ else x for x in seq[0]]\n",
    "#             # update counts\n",
    "#             transition_counts = transition_matrix_action(dataset)\n",
    "#             denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "#             denominators[denominators == 0] = 1\n",
    "#             transition_probs = transition_counts / denominators\n",
    "\n",
    "#     return transition_probs, env\n",
    "\n",
    "def build_ground_truth(\n",
    "    *,\n",
    "    seed: int,\n",
    "    size: int = 4,\n",
    "    n_episodes: int = 1000,\n",
    "    max_steps: int = 100,\n",
    "    iterations: int = 100,\n",
    "    cue = 5,\n",
    ") -> Tuple[np.ndarray, 'GridEnvRightDownNoSelf']:\n",
    "    \"\"\"Run the offline splitter to obtain fully expanded GT tensor.\"\"\"\n",
    "    env_size = (size, size)\n",
    "    rewarded_terminal = [env_size[0]*env_size[1]-1]\n",
    "    cue_states = cue\n",
    "\n",
    "    env = GridEnvRightDownNoSelf(env_size=env_size,\n",
    "                                 rewarded_terminal=rewarded_terminal,\n",
    "                                 cue_states=cue_states,\n",
    "                                 seed=seed)\n",
    "\n",
    "    dataset = generate_dataset(env, n_episodes, max_steps)\n",
    "    transition_counts = transition_matrix_action(dataset)\n",
    "    denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "    denominators[denominators == 0] = 1\n",
    "    transition_probs = transition_counts / denominators\n",
    "\n",
    "    used_cues = []\n",
    "    for _ in range(iterations):\n",
    "        ent = compute_transition_entropies(transition_probs)\n",
    "        pairs = find_stochastic_state_actions_by_entropy(ent, eps=1e-9)\n",
    "        if not pairs:\n",
    "            break\n",
    "        cues_tmp = []\n",
    "        for s, a in pairs:\n",
    "            spr1, spr2 = get_successor_states(transition_counts, s, a)\n",
    "            cue = calculate_backward_contingency(dataset, spr1, spr2, env_size)\n",
    "            cues_tmp.append(cue)\n",
    "        unique_cues = np.unique([x for sub in cues_tmp for x in sub])\n",
    "        for cue in unique_cues:\n",
    "            if cue in used_cues:\n",
    "                continue\n",
    "            used_cues.append(cue)\n",
    "            valid_actions = env.get_valid_actions(env.clone_dict.get(cue, cue))\n",
    "            for a in valid_actions:\n",
    "                succ = get_successor_states(transition_counts, cue, a)[0]\n",
    "                if succ in env.reverse_clone_dict:\n",
    "                    clone = env.reverse_clone_dict[succ]\n",
    "                else:\n",
    "                    clone = len(get_unique_states(dataset))\n",
    "                    env.add_clone_dict(clone, succ)\n",
    "                    env.add_reverse_clone_dict(clone, succ)\n",
    "                for d, seq in enumerate(dataset):\n",
    "                    if has_state(seq[0], succ) and has_transition(cue, succ, seq[0]):\n",
    "                        dataset[d][0] = [clone if x == succ else x for x in seq[0]]\n",
    "            # update counts\n",
    "            transition_counts = transition_matrix_action(dataset)\n",
    "            denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "            denominators[denominators == 0] = 1\n",
    "            transition_probs = transition_counts / denominators\n",
    "\n",
    "    return transition_probs, env\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4. Plot helper (mean ± SE)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def plot_kl_curve_se(kl_hist: np.ndarray, *, color=\"tab:blue\"):\n",
    "    n_runs, n_eps = kl_hist.shape\n",
    "    mean = np.nanmean(kl_hist, axis=0)\n",
    "    se   = np.nanstd(kl_hist, axis=0, ddof=1) / np.sqrt(n_runs)\n",
    "    x = np.arange(1, n_eps+1)\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(x, mean, color=color, label=f\"mean KL ({n_runs} seeds)\")\n",
    "    plt.fill_between(x, mean-se, mean+se, color=color, alpha=0.25, label=\"±1 SE\")\n",
    "    plt.xlabel(\"Episode\"); plt.ylabel(\"KL (nats)\")\n",
    "    # plt.title(\"CoDA convergence – clone‑aligned KL\")\n",
    "    plt.title(\"Convergence of CoDA – KL (Cued reward)\")\n",
    "    plt.grid(alpha=0.3); plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5.  Single‑seed online run\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def run_single_seed(cue: int, seed: int,  *, n_episodes: int = 1000, max_steps: int = 100, size: int = 4) -> List[float]:\n",
    "    np.random.seed(seed)\n",
    "    # size = 4\n",
    "    env_size = (size, size)\n",
    "    rewarded_terminal = [env_size[0]*env_size[1]-1]\n",
    "    cue_states = [cue]\n",
    "    # transition_probs, env = latent_inhibition(seed=seed, cue=cue)\n",
    "    env = GridEnvRightDownNoSelf(env_size=env_size,\n",
    "                                 rewarded_terminal=rewarded_terminal,\n",
    "                                 cue_states=cue_states,\n",
    "                                 seed=seed)\n",
    "\n",
    "    episodes = generate_dataset(env, n_episodes, max_steps)\n",
    "    \n",
    "    blocking_env = GridEnvRightDownNoSelf(env_size=env_size,\n",
    "                                 rewarded_terminal=rewarded_terminal,\n",
    "                                 cue_states=[cue, 16],\n",
    "                                 seed=seed)\n",
    "\n",
    "    blocking_episodes = generate_dataset(blocking_env, n_episodes, max_steps)    \n",
    "    \n",
    "    n_states = max(max(pair[0]) for pair in episodes) + 1\n",
    "    E_r = np.zeros((1, n_states)); E_nr = np.zeros_like(E_r); C = np.zeros_like(E_r)\n",
    "\n",
    "    # ---- pre‑compute ground truth (tensor + env) -------------------\n",
    "    P_true, env_gt = build_ground_truth(seed=seed, cue=[cue, 16], size=size)\n",
    "    env_gt.plot_graph(P_true,'GT',savename='GT.png')\n",
    "    grid_size = size * size\n",
    "\n",
    "    kl_trace: List[float] = []\n",
    "    used_cues: List[int] = []\n",
    "\n",
    "    # LATENT INHIBITION\n",
    "    # for e in range(200):\n",
    "    for e in range(len(episodes)):    \n",
    "        obs, _ = episodes[e]\n",
    "        # obs[-1] = 16\n",
    "        # transition counts online\n",
    "        if e == 0:\n",
    "            t_counts = transition_matrix_action_trial_by_trial(episodes, episodes[e])\n",
    "        else:\n",
    "            t_counts = transition_matrix_action_trial_by_trial(episodes, episodes[e], t_counts)\n",
    "\n",
    "        ent, conf = compute_transition_entropies_thresholded(t_counts)\n",
    "        pairs = find_stochastic_state_actions_by_entropy_thresholded(ent, conf, n_threshold=3)\n",
    "\n",
    "        # ----------- (online splitting code: trimmed version) --------\n",
    "        if pairs:\n",
    "            cues_tmp = []\n",
    "            for s,a in pairs:\n",
    "                spr1, spr2 = get_successor_states(t_counts, s, a)\n",
    "                E_r, E_nr, C = accumulate_conditioned_eligibility_traces(E_r, E_nr, C, obs, spr1, spr2,\n",
    "                                                                         n_states, lam=0.8, gamma=0.9)\n",
    "                cue = calculate_backward_contingency_trial_by_trial(E_r, E_nr, C, env_size, n_threshold=20)\n",
    "                cues_tmp.append(cue)\n",
    "            for cue in np.unique([x for sub in cues_tmp for x in sub]):\n",
    "                if cue in used_cues:\n",
    "                    continue\n",
    "                used_cues.append(cue)\n",
    "                valid_actions = env.get_valid_actions(env.clone_dict.get(cue, cue))\n",
    "                for a in valid_actions:\n",
    "                    succ = get_successor_states(t_counts, cue, a)[0]\n",
    "                    if succ in env.reverse_clone_dict:\n",
    "                        clone = env.reverse_clone_dict[succ]\n",
    "                    else:\n",
    "                        clone = len(get_unique_states(episodes))\n",
    "                        env.add_clone_dict(clone, succ)\n",
    "                        env.add_reverse_clone_dict(clone, succ)\n",
    "                        for d, seq in enumerate(episodes):\n",
    "                            if has_state(seq[0], succ) and has_transition(cue, succ, seq[0]):\n",
    "                                episodes[d][0] = [clone if x == succ else x for x in seq[0]]\n",
    "                                blocking_episodes[d][0] = [clone if x == succ else x for x in seq[0]]\n",
    "                                \n",
    "                        n_states += 1\n",
    "                        C  = np.concatenate([C, np.zeros((1,1))], axis=1)\n",
    "                        E_r = np.concatenate([E_r, np.zeros((1,1))], axis=1)\n",
    "                        E_nr= np.concatenate([E_nr, np.zeros((1,1))], axis=1)\n",
    "                t_counts = transition_matrix_action(episodes[:e+1])\n",
    "\n",
    "        # ---- compute online tensor & KL -----------------------------\n",
    "        denom = t_counts.sum(axis=2, keepdims=True); denom[denom==0] = 1\n",
    "        P_model = t_counts / denom\n",
    "        # kl = aligned_kl(P_true, env_gt, P_model, env, grid_size)\n",
    "        # kl_trace.append(kl)\n",
    "    # env.plot_graph(P_model,1, new_clone,savename=savename)\n",
    "    env.plot_graph(P_model,'Acquisition',savename='pre_cr.png')  \n",
    "    \n",
    "    episodes = blocking_episodes\n",
    "    for e in range(len(episodes)):\n",
    "        obs, _ = episodes[e]\n",
    "        # transition counts online\n",
    "        # if e == 0:\n",
    "            # t_counts = transition_matrix_action_trial_by_trial(episodes, episodes[e])\n",
    "        # else:\n",
    "        t_counts = transition_matrix_action_trial_by_trial(episodes, episodes[e], t_counts)\n",
    "\n",
    "        ent, conf = compute_transition_entropies_thresholded(t_counts)\n",
    "        pairs = find_stochastic_state_actions_by_entropy_thresholded(ent, conf, n_threshold=3)\n",
    "\n",
    "        # ----------- (online splitting code: trimmed version) --------\n",
    "        if pairs:\n",
    "            cues_tmp = []\n",
    "            for s,a in pairs:\n",
    "                spr1, spr2 = get_successor_states(t_counts, s, a)\n",
    "                E_r, E_nr, C = accumulate_conditioned_eligibility_traces(E_r, E_nr, C, obs, spr1, spr2,\n",
    "                                                                         n_states, lam=0.8, gamma=0.9)\n",
    "                cue = calculate_backward_contingency_trial_by_trial(E_r, E_nr, C, env_size, n_threshold=20)\n",
    "                cues_tmp.append(cue)\n",
    "            for cue in np.unique([x for sub in cues_tmp for x in sub]):\n",
    "                if cue in used_cues:\n",
    "                    continue\n",
    "                used_cues.append(cue)\n",
    "                valid_actions = env.get_valid_actions(env.clone_dict.get(cue, cue))\n",
    "                for a in valid_actions:\n",
    "                    succ = get_successor_states(t_counts, cue, a)[0]\n",
    "                    if succ in env.reverse_clone_dict:\n",
    "                        clone = env.reverse_clone_dict[succ]\n",
    "                    else:\n",
    "                        clone = len(get_unique_states(episodes))\n",
    "                        env.add_clone_dict(clone, succ)\n",
    "                        env.add_reverse_clone_dict(clone, succ)\n",
    "                        for d, seq in enumerate(episodes):\n",
    "                            if has_state(seq[0], succ) and has_transition(cue, succ, seq[0]):\n",
    "                                episodes[d][0] = [clone if x == succ else x for x in seq[0]]\n",
    "                        n_states += 1\n",
    "                        C  = np.concatenate([C, np.zeros((1,1))], axis=1)\n",
    "                        E_r = np.concatenate([E_r, np.zeros((1,1))], axis=1)\n",
    "                        E_nr= np.concatenate([E_nr, np.zeros((1,1))], axis=1)\n",
    "                t_counts = transition_matrix_action(episodes[:e+1])\n",
    "\n",
    "        # ---- compute online tensor & KL -----------------------------\n",
    "        denom = t_counts.sum(axis=2, keepdims=True); denom[denom==0] = 1\n",
    "        P_model = t_counts / denom\n",
    "        kl = aligned_kl(P_true, env_gt, P_model, env, grid_size)\n",
    "        kl_trace.append(kl)\n",
    "    env.plot_graph(P_model,'Cued reward',savename='post_cr.png')  \n",
    "    return kl_trace\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6.  Main – run multiple seeds\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    seeds = np.arange(2)#np.arange(20) #[0, 1, 2, 3, 4]\n",
    "    cues  = np.array([8])\n",
    "    size=5\n",
    "\n",
    "    # 1. build the full Cartesian product  → 20 pairs\n",
    "    pairs = list(itertools.product(cues, seeds))   # (cue, seed)\n",
    "\n",
    "    # 2. shuffle in-place for a random order\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    kl_mat = []\n",
    "    for pair in pairs:\n",
    "        # print(f\"Seed {sd} …\")\n",
    "        cue = pair[0]\n",
    "        sd = pair[1]\n",
    "        kl_mat.append(run_single_seed(cue, sd, size=size))    \n",
    "    # for sd in seeds:\n",
    "    #     print(f\"Seed {sd} …\")\n",
    "    #     kl_mat.append(run_single_seed(sd))\n",
    "\n",
    "    # pad ragged to rectangular with NaNs\n",
    "    max_len = max(len(v) for v in kl_mat)\n",
    "    kl_padded = np.full((len(pairs), max_len), np.nan)\n",
    "    for i, v in enumerate(kl_mat):\n",
    "        kl_padded[i, :len(v)] = v\n",
    "\n",
    "    plot_kl_curve_se(kl_padded)\n",
    "    plt.savefig(\"kl_curve_cr.png\", dpi=300)\n",
    "    first = np.nanmean(kl_padded[:,0]); last = np.nanmean(kl_padded[:,-1])\n",
    "    print(f\"KL drops from {first:.3f} to {last:.3f} in {max_len} episodes (mean of {len(seeds)} seeds).  See kl_curve.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_true, env_gt = build_ground_truth(seed=seed, cue=[cue, 16], size=size)\n",
    "env_gt.plot_graph(P_true,'GT',savename='pre_cr.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(20) #[0, 1, 2, 3, 4]\n",
    "cues  = np.array([6])\n",
    "\n",
    "\n",
    "# 1. build the full Cartesian product  → 20 pairs\n",
    "pairs = list(itertools.product(cues, seeds))   # (cue, seed)\n",
    "pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
