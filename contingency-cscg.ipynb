{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chmm_actions import CHMM, forwardE, datagen_structured_obs_room\n",
    "import matplotlib.pyplot as plt\n",
    "import igraph \n",
    "from matplotlib import cm, colors\n",
    "import os\n",
    "\n",
    "custom_colors = (\n",
    "    np.array(\n",
    "        [\n",
    "            [214, 214, 214],\n",
    "            [85, 35, 157],\n",
    "            [253, 252, 144],\n",
    "            [114, 245, 144],\n",
    "            [151, 38, 20],\n",
    "            [239, 142, 192],\n",
    "            [214, 134, 48],\n",
    "            [140, 194, 250],\n",
    "            [72, 160, 162],\n",
    "        ]\n",
    "    )\n",
    "    / 256\n",
    ")\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(\n",
    "    chmm, x, a, output_file, cmap=cm.Spectral, multiple_episodes=False, vertex_size=30\n",
    "):\n",
    "    states = chmm.decode(x, a)[1]\n",
    "\n",
    "    v = np.unique(states)\n",
    "    if multiple_episodes:\n",
    "        T = chmm.C[:, v][:, :, v][:-1, 1:, 1:]\n",
    "        v = v[1:]\n",
    "    else:\n",
    "        T = chmm.C[:, v][:, :, v]\n",
    "    A = T.sum(0)\n",
    "    A /= A.sum(1, keepdims=True)\n",
    "\n",
    "    g = igraph.Graph.Adjacency((A > 0).tolist())\n",
    "    node_labels = np.arange(x.max() + 1).repeat(n_clones)[v]\n",
    "    if multiple_episodes:\n",
    "        node_labels -= 1\n",
    "    colors = [cmap(nl)[:3] for nl in node_labels / node_labels.max()]\n",
    "    out = igraph.plot(\n",
    "        g,\n",
    "        output_file,\n",
    "        layout=g.layout(\"kamada_kawai\"),\n",
    "        vertex_color=colors,\n",
    "        vertex_label=v,\n",
    "        vertex_size=vertex_size,\n",
    "        margin=50,\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mess_fwd(chmm, x, pseudocount=0.0, pseudocount_E=0.0):\n",
    "    n_clones = chmm.n_clones\n",
    "    E = np.zeros((n_clones.sum(), len(n_clones)))\n",
    "    last = 0\n",
    "    for c in range(len(n_clones)):\n",
    "        E[last : last + n_clones[c], c] = 1\n",
    "        last += n_clones[c]\n",
    "    E += pseudocount_E\n",
    "    norm = E.sum(1, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    E /= norm\n",
    "    T = chmm.C + pseudocount\n",
    "    norm = T.sum(2, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    T /= norm\n",
    "    T = T.mean(0, keepdims=True)\n",
    "    log2_lik, mess_fwd = forwardE(\n",
    "        T.transpose(0, 2, 1), E, chmm.Pi_x, chmm.n_clones, x, x * 0, store_messages=True\n",
    "    )\n",
    "    return mess_fwd\n",
    "\n",
    "\n",
    "def place_field(mess_fwd, rc, clone):\n",
    "    assert mess_fwd.shape[0] == rc.shape[0] and clone < mess_fwd.shape[1]\n",
    "    field = np.zeros(rc.max(0) + 1)\n",
    "    count = np.zeros(rc.max(0) + 1, int)\n",
    "    for t in range(mess_fwd.shape[0]):\n",
    "        r, c = rc[t]\n",
    "        field[r, c] += mess_fwd[t, clone]\n",
    "        count[r, c] += 1\n",
    "    count[count == 0] = 1\n",
    "    return field / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for setting up the environment\n",
    "class GridEnvRightDownNoSelf:\n",
    "    \"\"\"\n",
    "    A 3x3 grid with states numbered 1..9:\n",
    "\n",
    "        1   2   3\n",
    "        4   5   6\n",
    "        7   8   9\n",
    "\n",
    "    - The agent can only move RIGHT (0) or DOWN (1).\n",
    "    - No self-transitions at borders:\n",
    "        If an action would go out of bounds, that action is not allowed\n",
    "        from that state.\n",
    "    - Same cue logic: must visit 5 for a +1 reward at 9, else goes to 10 with -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cue_state=2):\n",
    "        # Grid layout: (row, col) -> state\n",
    "        self.pos_to_state = {\n",
    "            (0,0): 0, (0,1): 1, (0,2): 2, (0,3): 3,\n",
    "            (1,0): 4, (1,1): 5, (1,2): 6, (1,3): 7,\n",
    "            (2,0): 8, (2,1): 9, (2,2): 10, (2,3): 11,\n",
    "            (3,0): 12, (3,1): 13, (3,2): 14, (3,3): 15,\n",
    "        }\n",
    "        self.state_to_pos = {s: rc for rc, s in self.pos_to_state.items()}\n",
    "        \n",
    "        # Actions as integers: 0=right, 1=down\n",
    "        # right => (0, +1)\n",
    "        # down  => (+1, 0)\n",
    "        self.base_actions = {\n",
    "            0: (0, +1),   # right\n",
    "            1: (+1, 0)    # down\n",
    "        }\n",
    "        \n",
    "        # Instead of having a static [0,1] action space, we have a\n",
    "        # per-state action set (no invalid moves).\n",
    "        self.valid_actions = self._build_valid_actions()\n",
    "\n",
    "        # Special states\n",
    "        self.start_state = 0\n",
    "        self.cue_state = cue_state\n",
    "        self.rewarded_terminal = 15\n",
    "        self.unrewarded_terminal = 16  # not in the grid, just a label\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _build_valid_actions(self):\n",
    "        \"\"\"\n",
    "        Precompute valid actions for each non-terminal grid state.\n",
    "        A 'valid' action is one that leads to a NEW in-bounds state.\n",
    "        \"\"\"\n",
    "        valid_dict = {}\n",
    "        for row in range(4):\n",
    "            for col in range(4):\n",
    "                s = self.pos_to_state[(row, col)]\n",
    "                # We'll store all actions that yield a different state (no self-transitions)\n",
    "                valid_dict[s] = []\n",
    "                for a, (dr, dc) in self.base_actions.items():\n",
    "                    new_r = row + dr\n",
    "                    new_c = col + dc\n",
    "                    if 0 <= new_r < 4 and 0 <= new_c < 4:\n",
    "                        next_s = self.pos_to_state[(new_r, new_c)]\n",
    "                        # Only count it if next_s != s (which can't happen in 3x3, but let's be explicit)\n",
    "                        if next_s != s:\n",
    "                            valid_dict[s].append(a)\n",
    "\n",
    "        # For terminal states 9 and 10, no actions are valid\n",
    "        # valid_dict[9] = []\n",
    "        # valid_dict[10] = []\n",
    "        valid_dict[15] = []\n",
    "        valid_dict[16] = []\n",
    "\n",
    "        return valid_dict\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset environment to the start:\n",
    "          - current_state=1\n",
    "          - visited_cue=False\n",
    "        Returns current_state (1).\n",
    "        \"\"\"\n",
    "        self.current_state = self.start_state\n",
    "        self.visited_cue = False\n",
    "        return self.current_state\n",
    "\n",
    "    def get_valid_actions(self, state=None):\n",
    "        \"\"\"\n",
    "        Return the list of valid actions for the current state\n",
    "        (or a given state).\n",
    "        \"\"\"\n",
    "        if state is None:\n",
    "            state = self.current_state\n",
    "        return self.valid_actions[state]\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Step with a guaranteed valid action. If an invalid action is given,\n",
    "        we can either ignore or raise an Exception. We'll raise an error.\n",
    "        \"\"\"\n",
    "        if action not in self.get_valid_actions():\n",
    "            raise ValueError(f\"Action {action} is not valid from state {self.current_state}.\")\n",
    "\n",
    "        # If we're already in a terminal (9 or 10), episode is over.\n",
    "        if self.current_state in [self.rewarded_terminal, self.unrewarded_terminal]:\n",
    "            return self.current_state, 0, True\n",
    "\n",
    "        # Move\n",
    "        row, col = self.state_to_pos[self.current_state]\n",
    "        dr, dc = self.base_actions[action]\n",
    "        next_row = row + dr\n",
    "        next_col = col + dc\n",
    "\n",
    "        next_state = self.pos_to_state[(next_row, next_col)]\n",
    "\n",
    "        # Check cue\n",
    "        if next_state == self.cue_state:\n",
    "            self.visited_cue = True\n",
    "\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Terminal condition: 8 -> 9\n",
    "        if next_state == 15:\n",
    "            done = True\n",
    "            if self.visited_cue:\n",
    "                reward = +1\n",
    "                next_state = self.rewarded_terminal\n",
    "            else:\n",
    "                reward = -1\n",
    "                next_state = self.unrewarded_terminal\n",
    "\n",
    "        # Update\n",
    "        self.current_state = next_state\n",
    "        return next_state, reward, done\n",
    "    \n",
    "def generate_dataset(env, n_episodes=10, max_steps=20):\n",
    "    \"\"\"\n",
    "    Run 'n_episodes' episodes in the environment. Each episode ends\n",
    "    either when the environment signals 'done' or when we hit 'max_steps'.\n",
    "\n",
    "    Returns:\n",
    "        A list of (state_sequence, action_sequence) pairs.\n",
    "        - state_sequence: list of visited states\n",
    "        - action_sequence: list of chosen actions\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    for episode_idx in range(n_episodes):\n",
    "        # Prepare lists to store states & actions for this episode\n",
    "        states = []\n",
    "        actions = []\n",
    "\n",
    "        # Reset env to start a new episode\n",
    "        state = env.reset()\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            states.append(state)\n",
    "\n",
    "            valid_actions = env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                # No valid actions => we must be in a terminal or stuck\n",
    "                break\n",
    "\n",
    "            # Example: pick a random valid action\n",
    "            action = np.random.choice(valid_actions)\n",
    "            actions.append(action)\n",
    "\n",
    "            # Step in the environment\n",
    "            next_state, reward, done = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # Also record the final state\n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                break\n",
    "\n",
    "        # Store (states, actions) for this episode\n",
    "        dataset.append([states, actions])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridEnvRightDownNoSelf(cue_state=5)\n",
    "\n",
    "n_episodes = 500\n",
    "max_steps_per_episode = 10\n",
    "\n",
    "dataset = generate_dataset(env, n_episodes, max_steps_per_episode)\n",
    "# x = dataset[0][0]\n",
    "# a = dataset[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clones: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [00:02<01:41,  9.56it/s, train_bps=0.735]\n",
      "  2%|▏         | 2/100 [00:01<01:02,  1.58it/s, train_bps=0.81]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# np.append(a,0)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x)\n\u001b[0;32m---> 32\u001b[0m progression \u001b[39m=\u001b[39m chmm\u001b[39m.\u001b[39mlearn_em_T(x, a, n_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)  \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# refine learning\u001b[39;00m\n\u001b[1;32m     35\u001b[0m chmm\u001b[39m.\u001b[39mpseudocount \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Repositories/CSCG_LCM/chmm_actions.py:207\u001b[0m, in \u001b[0;36mCHMM.learn_em_T\u001b[0;34m(self, x, a, n_iter, term_early)\u001b[0m\n\u001b[1;32m    204\u001b[0m log2_lik_old \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[1;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m    206\u001b[0m     \u001b[39m# E\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     log2_lik, mess_fwd \u001b[39m=\u001b[39m forward(\n\u001b[1;32m    208\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[1;32m    209\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPi_x,\n\u001b[1;32m    210\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clones,\n\u001b[1;32m    211\u001b[0m         x,\n\u001b[1;32m    212\u001b[0m         a,\n\u001b[1;32m    213\u001b[0m         store_messages\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    215\u001b[0m     mess_bwd \u001b[39m=\u001b[39m backward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clones, x, a)\n\u001b[1;32m    216\u001b[0m     updateC(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clones, mess_fwd, mess_bwd, x, a)\n",
      "File \u001b[0;32m~/Desktop/Repositories/CSCG_LCM/chmm_actions.py:486\u001b[0m, in \u001b[0;36mforward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    482\u001b[0m message \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(T_tr[aij, j_start:j_stop, i_start:i_stop])\u001b[39m.\u001b[39mdot(\n\u001b[1;32m    483\u001b[0m     message\n\u001b[1;32m    484\u001b[0m )\n\u001b[1;32m    485\u001b[0m p_obs \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39msum()\n\u001b[0;32m--> 486\u001b[0m \u001b[39massert\u001b[39;00m p_obs \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    487\u001b[0m message \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m p_obs\n\u001b[1;32m    488\u001b[0m log2_lik[t] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog2(p_obs)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# room = np.array(\n",
    "#     [\n",
    "#         [1, 2, 3, 0, 3, 1, 1, 1],\n",
    "#         [1, 1, 3, 2, 3, 2, 3, 1],\n",
    "#         [1, 1, 2, 0, 1, 2, 1, 0],\n",
    "#         [0, 2, 1, 1, 3, 0, 0, 2],\n",
    "#         [3, 3, 1, 0, 1, 0, 3, 0],\n",
    "#         [2, 1, 2, 3, 3, 3, 2, 0],\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "n_emissions = 17 #room.max() + 1\n",
    "\n",
    "# a, x, rc = datagen_structured_obs_room(room, length=50000)\n",
    "\n",
    "\n",
    "n_clones = np.ones(n_emissions, dtype=np.int64) * 3\n",
    "x = dataset[0][0]\n",
    "a = dataset[0][1]\n",
    "a = np.array(a)\n",
    "x = np.array(x)\n",
    "# np.append(a,0)\n",
    "# dataset = dataset[:1]\n",
    "chmm = CHMM(n_clones=n_clones, pseudocount=2e-3, x=x, a=a, seed=42)  # Initialize the model\n",
    "for d, curr_dataset in enumerate(dataset):\n",
    "    x = curr_dataset[0]\n",
    "    a = curr_dataset[1]\n",
    "    a = np.array(a)\n",
    "    # np.append(a,0)\n",
    "    x = np.array(x)\n",
    "\n",
    "    progression = chmm.learn_em_T(x, a, n_iter=1000)  # Training\n",
    "    \n",
    "    # refine learning\n",
    "    chmm.pseudocount = 0.0\n",
    "    chmm.learn_viterbi_T(x, a, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "len(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[39m=\u001b[39m plot_graph(\n\u001b[1;32m      2\u001b[0m     chmm, x, a, output_file\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfigures/rectangular_room_graph.pdf\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m graph\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mplot_graph\u001b[0;34m(chmm, x, a, output_file, cmap, multiple_episodes, vertex_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_graph\u001b[39m(\n\u001b[1;32m      2\u001b[0m     chmm, x, a, output_file, cmap\u001b[39m=\u001b[39mcm\u001b[39m.\u001b[39mSpectral, multiple_episodes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, vertex_size\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m\n\u001b[1;32m      3\u001b[0m ):\n\u001b[0;32m----> 4\u001b[0m     states \u001b[39m=\u001b[39m chmm\u001b[39m.\u001b[39mdecode(x, a)[\u001b[39m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m     v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(states)\n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m multiple_episodes:\n",
      "File \u001b[0;32m~/Desktop/Repositories/CSCG_LCM/chmm_actions.py:173\u001b[0m, in \u001b[0;36mCHMM.decode\u001b[0;34m(self, x, a)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, x, a):\n\u001b[1;32m    172\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the MAP assignment of latent variables using max-product message passing.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     log2_lik, mess_fwd \u001b[39m=\u001b[39m forward_mp(\n\u001b[1;32m    174\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[1;32m    175\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPi_x,\n\u001b[1;32m    176\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clones,\n\u001b[1;32m    177\u001b[0m         x,\n\u001b[1;32m    178\u001b[0m         a,\n\u001b[1;32m    179\u001b[0m         store_messages\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m     states \u001b[39m=\u001b[39m backtrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clones, x, a, mess_fwd)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mlog2_lik, states\n",
      "File \u001b[0;32m~/Desktop/Repositories/CSCG_LCM/chmm_actions.py:571\u001b[0m, in \u001b[0;36mforward_mp\u001b[0;34m()\u001b[0m\n\u001b[1;32m    569\u001b[0m message \u001b[39m=\u001b[39m new_message\n\u001b[1;32m    570\u001b[0m p_obs \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39mmax()\n\u001b[0;32m--> 571\u001b[0m \u001b[39massert\u001b[39;00m p_obs \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    572\u001b[0m message \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m p_obs\n\u001b[1;32m    573\u001b[0m log2_lik[t] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog2(p_obs)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph = plot_graph(\n",
    "    chmm, x, a, output_file=\"figures/rectangular_room_graph.pdf\", \n",
    "    \n",
    ")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 9, 13, 14, 15, 17]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
