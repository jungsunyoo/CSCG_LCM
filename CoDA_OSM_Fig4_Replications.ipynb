{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CoDA in the 2ACDC near/far task — Reproductions of OSM Fig. 4c, 4i, 4j\n",
    "\n",
    "This notebook mirrors the code structure of the official OSM figure notebooks to:\n",
    "\n",
    "- Simulate **CoDA** on the 2ACDC near/far symbol sequences used in the CSCG simulation.\n",
    "- Reproduce the **Fig. 4c** transition graph (clear layout and colored branches),\n",
    "- Reproduce **Fig. 4i** final correlation block quantification, and\n",
    "- Reproduce **Fig. 4j** decorrelation order (time-to-threshold).\n",
    "\n",
    "References to the original notebooks:\n",
    "- Transition graph: `fig_4/fig_4_CSCG/fig_4_c_Transition_graph.ipynb`.\n",
    "- Final correlation quantification: `fig_4/fig_4i_Final_correlation_quantification.ipynb`.\n",
    "- Decorrelation order: `fig_4/fig_4j_decorr_order.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core imports\n",
    "import math, random, itertools, collections\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graphing\n",
    "import networkx as nx\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(0); np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Task definition (2ACDC near/far symbol sequences)\n",
    "\n",
    "We use the exact discrete sequences used by the CSCG simulation in the OSM repo. Symbols: `1`=grey corridor, `2`=near-indicator, `3`=far-indicator, `4`=R1 visual, `5`=R2 visual, `6`=water, `7`=wall, `0`=teleport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "near = [1,1,1,1,1,1, 2,2,2,2, 1,1,1, 4, 6, 1,1,1, 5,5, 1,1, 7, 0,0,0]\n",
    "far  = [1,1,1,1,1,1, 3,3,3,3, 1,1,1, 4,4, 1,1,1, 5, 6, 1,1, 7, 0,0,0]\n",
    "assert len(near)==len(far)==26\n",
    "\n",
    "# Indices for Fig. 4 blocks\n",
    "preR1_idx = list(range(10,13))   # between indicator and R1 visual\n",
    "preR2_idx = list(range(15,18))   # between (R1/water) and R2 visual\n",
    "\n",
    "def block_indices(rows, cols):\n",
    "    return [(r,c) for r in rows for c in cols]\n",
    "\n",
    "offdiag_pairs     = block_indices(preR1_idx, preR2_idx) + block_indices(preR2_idx, preR1_idx)\n",
    "same_preR1_pairs  = block_indices(preR1_idx, preR1_idx)\n",
    "same_preR2_pairs  = block_indices(preR2_idx, preR2_idx)\n",
    "\n",
    "symbols = sorted(set(near) | set(far))\n",
    "symbols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## CoDA (minimal, tabular) with contextual eligibility traces\n",
    "\n",
    "This implementation follows the split/merge logic in the CoDA manuscript and adds a bookkeeping fix so clones get their own contingency counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class LatentState:\n",
    "    id: int\n",
    "    obs: int\n",
    "    path: Optional[str] = None   # None, 'R1', or 'R2'\n",
    "    parent: Optional[int] = None\n",
    "\n",
    "class CoDAAgent:\n",
    "    def __init__(self, obs_symbols, gamma=0.9, lam=0.8, theta_split=0.9, theta_merge=0.5):\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.theta_split = theta_split\n",
    "        self.theta_merge = theta_merge\n",
    "        self.reset_symbols = {0}\n",
    "        \n",
    "        # Base latent states\n",
    "        self.states: Dict[int, LatentState] = {}\n",
    "        self.obs_to_state_ids: Dict[int, List[int]] = {o: [] for o in obs_symbols}\n",
    "        sid = 0\n",
    "        for o in obs_symbols:\n",
    "            st = LatentState(id=sid, obs=o, path=None, parent=None)\n",
    "            self.states[sid] = st\n",
    "            self.obs_to_state_ids[o].append(sid)\n",
    "            sid += 1\n",
    "        self._next_sid = sid\n",
    "        \n",
    "        # Transition counts (for graph)\n",
    "        self.edge_counts = collections.Counter()\n",
    "        \n",
    "        # Contingency storage\n",
    "        self.us_classes = [4,5]  # R1_vis, R2_vis\n",
    "        self.co_occ = {s: {u: 0.0 for u in self.us_classes} for s in self.states}\n",
    "        self.state_exposure = collections.Counter()\n",
    "        self.salient: Dict[int, str] = {}\n",
    "    \n",
    "    # --- helpers ---\n",
    "    def _ensure_state_keys(self, sid):\n",
    "        if sid not in self.co_occ:\n",
    "            self.co_occ[sid] = {u: 0.0 for u in self.us_classes}\n",
    "        if sid not in self.state_exposure:\n",
    "            self.state_exposure[sid] = 0.0\n",
    "    \n",
    "    def _clone_state(self, orig_state_id: int, path: str) -> int:\n",
    "        orig = self.states[orig_state_id]\n",
    "        clone_id = self._next_sid\n",
    "        clone = LatentState(id=clone_id, obs=orig.obs, path=path, parent=orig_state_id)\n",
    "        self.states[clone_id] = clone\n",
    "        self.obs_to_state_ids[orig.obs].append(clone_id)\n",
    "        self._ensure_state_keys(clone_id)  # FIX\n",
    "        self._next_sid += 1\n",
    "        return clone_id\n",
    "    \n",
    "    def _select_state_for_obs(self, obs: int, current_context: Optional[str]) -> int:\n",
    "        # Choose state that matches context if available, else base\n",
    "        candidates = self.obs_to_state_ids[obs]\n",
    "        if current_context is not None:\n",
    "            for sid in candidates:\n",
    "                if self.states[sid].path == current_context:\n",
    "                    return sid\n",
    "        for sid in candidates:\n",
    "            if self.states[sid].path is None:\n",
    "                return sid\n",
    "        return candidates[0]\n",
    "    \n",
    "    # --- learning ---\n",
    "    def run_episode(self, obs_seq: List[int], learn=True):\n",
    "        context = None\n",
    "        latent_seq = []\n",
    "        for t, obs in enumerate(obs_seq):\n",
    "            sid = self._select_state_for_obs(obs, context)\n",
    "            latent_seq.append(sid)\n",
    "            if sid in self.salient:\n",
    "                context = self.salient[sid]\n",
    "            if obs in self.reset_symbols:\n",
    "                context = None\n",
    "        \n",
    "        if not learn:\n",
    "            return latent_seq\n",
    "        \n",
    "        # Identify US events\n",
    "        us_positions = {4: [i for i,o in enumerate(obs_seq) if o==4],\n",
    "                        5: [i for i,o in enumerate(obs_seq) if o==5]}\n",
    "        # Update contextual eligibilities\n",
    "        for u, pos_list in us_positions.items():\n",
    "            for t_us in pos_list:\n",
    "                e = np.zeros(max(self.states)+1, dtype=float)\n",
    "                for t in range(t_us+1):\n",
    "                    sid = latent_seq[t]\n",
    "                    e *= (self.gamma * self.lam)\n",
    "                    e[sid] += 1.0\n",
    "                    self.state_exposure[sid] += e[sid]\n",
    "                # Add snapshot\n",
    "                for s_id, val in enumerate(e):\n",
    "                    if val>0 and s_id in self.states:\n",
    "                        self._ensure_state_keys(s_id)\n",
    "                        self.co_occ[s_id][u] += val\n",
    "        \n",
    "        # Prospective contingency P(u|s)\n",
    "        P = {}\n",
    "        for s in list(self.states.keys()):\n",
    "            self._ensure_state_keys(s)\n",
    "            tot = sum(self.co_occ[s][u] for u in self.us_classes)\n",
    "            if tot<=0: P[s] = {u:0.0 for u in self.us_classes}\n",
    "            else:      P[s] = {u:self.co_occ[s][u]/tot for u in self.us_classes}\n",
    "        \n",
    "        newly_salient = []\n",
    "        for s in list(self.states.keys()):\n",
    "            if s in self.salient: \n",
    "                continue\n",
    "            if sum(self.co_occ[s].values())<=0: \n",
    "                continue\n",
    "            u_star = max(self.us_classes, key=lambda u: P[s][u])\n",
    "            if P[s][u_star] > self.theta_split:\n",
    "                path = 'R1' if u_star==4 else 'R2'\n",
    "                self.salient[s] = path\n",
    "                newly_salient.append((s, path))\n",
    "        \n",
    "        # Propagate splitting: clone immediate successors along same path\n",
    "        for s, path in newly_salient:\n",
    "            idxs = [t for t, sid in enumerate(latent_seq[:-1]) if sid==s]\n",
    "            for t in idxs:\n",
    "                next_obs = obs_seq[t+1]\n",
    "                cands = self.obs_to_state_ids[next_obs]\n",
    "                has_clone = any(self.states[c].path==path for c in cands)\n",
    "                if not has_clone:\n",
    "                    self._clone_state(cands[0], path)\n",
    "        \n",
    "        # Record edges from a single pass to keep graph simple\n",
    "        context = None\n",
    "        for t in range(len(obs_seq)-1):\n",
    "            sid = self._select_state_for_obs(obs_seq[t], context)\n",
    "            if sid in self.salient:\n",
    "                context = self.salient[sid]\n",
    "            nid = self._select_state_for_obs(obs_seq[t+1], context)\n",
    "            self.edge_counts[(sid, nid)] += 1\n",
    "            if obs_seq[t+1] in self.reset_symbols:\n",
    "                context = None\n",
    "        \n",
    "        return latent_seq\n",
    "    \n",
    "    # --- analysis ---\n",
    "    def encode_sequence(self, obs_seq: List[int]) -> np.ndarray:\n",
    "        lat = self.run_episode(obs_seq, learn=False)\n",
    "        S = max(self.states)+1\n",
    "        X = np.zeros((len(lat), S), dtype=float)\n",
    "        for t, sid in enumerate(lat):\n",
    "            X[t, sid] = 1.0\n",
    "        return X[:, :len(self.states)]\n",
    "    \n",
    "    def near_far_corr(self, near_seq, far_seq) -> np.ndarray:\n",
    "        A = self.encode_sequence(near_seq)\n",
    "        B = self.encode_sequence(far_seq)\n",
    "        C = np.zeros((A.shape[0], B.shape[0]))\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(B.shape[0]):\n",
    "                a = A[i]; b = B[j]\n",
    "                if np.allclose(a,0) or np.allclose(b,0):\n",
    "                    C[i,j] = 0.0\n",
    "                else:\n",
    "                    a0 = a - a.mean(); b0 = b - b.mean()\n",
    "                    denom = (np.linalg.norm(a0)*np.linalg.norm(b0))\n",
    "                    C[i,j] = (a0@b0)/denom if denom>0 else 0.0\n",
    "        return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Train CoDA and gather matrices across sessions (as in Fig. 4i & 4j)\n",
    "\n",
    "We randomize near/far episodes within session. After each session we compute the near–far correlation matrix, then extract the three key block averages used by the OSM notebooks (`offdiag`, `preR2`, `preR1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_RUNS = 8\n",
    "SESSIONS = 9\n",
    "TRIALS_PER_SESSION = 80\n",
    "THRESH = 0.3\n",
    "\n",
    "def block_mean(C, pairs):\n",
    "    if not pairs: return np.nan\n",
    "    return float(np.mean([C[i,j] for (i,j) in pairs]))\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "# Storage\n",
    "all_final_blocks = []     # (run, offdiag, preR2, preR1)\n",
    "all_time_to_thr = []      # (run, t_off, t_preR2, t_preR1) normalized to [0,1]\n",
    "mat_by_session = {s: [] for s in [1,3,4,9]}\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    agent = CoDAAgent(obs_symbols=sorted(set(near)|set(far)))\n",
    "    tt = {'offdiag': None, 'preR2': None, 'preR1': None}\n",
    "    for session in range(1, SESSIONS+1):\n",
    "        episodes = [near]*(TRIALS_PER_SESSION//2) + [far]*(TRIALS_PER_SESSION//2)\n",
    "        rng.shuffle(episodes)\n",
    "        for ep in episodes:\n",
    "            agent.run_episode(ep, learn=True)\n",
    "        # Evaluate\n",
    "        C = agent.near_far_corr(near, far)\n",
    "        if session in mat_by_session:\n",
    "            mat_by_session[session].append(C)\n",
    "        b_off = block_mean(C, offdiag_pairs)\n",
    "        b_r2  = block_mean(C, same_preR2_pairs)\n",
    "        b_r1  = block_mean(C, same_preR1_pairs)\n",
    "        if tt['offdiag'] is None and b_off < THRESH: tt['offdiag'] = session\n",
    "        if tt['preR2']  is None and b_r2  < THRESH: tt['preR2']  = session\n",
    "        if tt['preR1']  is None and b_r1  < THRESH: tt['preR1']  = session\n",
    "    # Final\n",
    "    C_final = agent.near_far_corr(near, far)\n",
    "    all_final_blocks.append((run, block_mean(C_final, offdiag_pairs),\n",
    "                                  block_mean(C_final, same_preR2_pairs),\n",
    "                                  block_mean(C_final, same_preR1_pairs)))\n",
    "    def norm(x): return x/SESSIONS if x is not None else np.nan\n",
    "    all_time_to_thr.append((run, norm(tt['offdiag']), norm(tt['preR2']), norm(tt['preR1'])))\n",
    "\n",
    "blocks_df = pd.DataFrame(all_final_blocks, columns=['run','offdiag','preR2','preR1']).set_index('run')\n",
    "times_df  = pd.DataFrame(all_time_to_thr, columns=['run','offdiag_t','preR2_t','preR1_t']).set_index('run')\n",
    "\n",
    "display(blocks_df.describe())\n",
    "display(times_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Fig. 4c (transition graph) — OSM‑style clean layout\n",
    "\n",
    "We render **two colored trajectories** (near=R1 branch, far=R2 branch) on a layered layout:\n",
    "- y=0: base (pre‑split) latent states, y=+1: R1 path (near), y=−1: R2 path (far).\n",
    "- x‑position is the **mean step index** where a latent state appears across the two trajectories (gives left‑to‑right flow).\n",
    "- Only edges along **canonical near/far trajectories** are drawn (no cross‑episode shortcuts), with arc offsets to avoid overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def latent_path(agent, seq):\n",
    "    # Return list of (t, sid) for a single pass without learning\n",
    "    lat = agent.run_episode(seq, learn=False)\n",
    "    return list(enumerate(lat))\n",
    "\n",
    "# Retrain a fresh agent and fit it (to get a representative final graph)\n",
    "agent = CoDAAgent(obs_symbols=sorted(set(near)|set(far)))\n",
    "rng = np.random.default_rng(0)\n",
    "for session in range(SESSIONS):\n",
    "    episodes = [near]*(TRIALS_PER_SESSION//2) + [far]*(TRIALS_PER_SESSION//2)\n",
    "    rng.shuffle(episodes)\n",
    "    for ep in episodes:\n",
    "        agent.run_episode(ep, learn=True)\n",
    "\n",
    "# Collect canonical near and far latent sequences\n",
    "near_path = latent_path(agent, near)\n",
    "far_path  = latent_path(agent, far)\n",
    "\n",
    "# Compute node positions: x = mean time of occurrence across both paths; y by path tag\n",
    "from collections import defaultdict\n",
    "time_acc = defaultdict(list)\n",
    "for t,sid in near_path: time_acc[sid].append(t)\n",
    "for t,sid in far_path:  time_acc[sid].append(t)\n",
    "\n",
    "pos = {}\n",
    "def y_level(st):\n",
    "    return {None:0.0, 'R1':1.0, 'R2':-1.0}[st.path]\n",
    "\n",
    "for sid, st in agent.states.items():\n",
    "    if sid in time_acc:\n",
    "        x = np.mean(time_acc[sid])\n",
    "        pos[sid] = (x, y_level(st))\n",
    "    else:\n",
    "        # states never used in the canonical near/far path; push them far left and lightly alpha\n",
    "        pos[sid] = (-1.0, y_level(st))\n",
    "\n",
    "# Build edges only from canonical consecutive pairs within each path\n",
    "near_edges = [(near_path[i][1], near_path[i+1][1]) for i in range(len(near_path)-1)]\n",
    "far_edges  = [(far_path[i][1],  far_path[i+1][1])  for i in range(len(far_path)-1)]\n",
    "\n",
    "# Draw\n",
    "fig, ax = plt.subplots(figsize=(12,3), constrained_layout=True)\n",
    "\n",
    "# Nodes (color by path)\n",
    "node_colors = []\n",
    "for sid in agent.states:\n",
    "    path = agent.states[sid].path\n",
    "    node_colors.append({None:'#cfcfcf','R1':'#ff9bb0','R2':'#8fbff5'}[path])\n",
    "\n",
    "nx.draw_networkx_nodes(nx.DiGraph(), pos, nodelist=list(agent.states.keys()),\n",
    "                       node_color=node_colors, node_size=420, ax=ax)\n",
    "\n",
    "# Draw edges with slight opposite curvature for near vs far\n",
    "def draw_edges(edge_list, color, rad):\n",
    "    for (u,v) in edge_list:\n",
    "        if u not in pos or v not in pos: \n",
    "            continue\n",
    "        con = 'arc3,rad={}'.format(rad)\n",
    "        ax.annotate('', xy=pos[v], xytext=pos[u],\n",
    "                    arrowprops=dict(arrowstyle='-|>', lw=1.6, color=color, alpha=0.9,\n",
    "                                    connectionstyle=con))\n",
    "\n",
    "draw_edges(near_edges, color='#d64b5a', rad=0.18)   # near (R1)\n",
    "draw_edges(far_edges,  color='#2f6db3', rad=-0.18)  # far  (R2)\n",
    "\n",
    "# Labels (only for informative symbols)\n",
    "for sid, st in agent.states.items():\n",
    "    lab_obs = st.obs\n",
    "    if lab_obs in (2,3,4,5,6,7):  # annotate key points\n",
    "        ax.text(pos[sid][0], pos[sid][1]+0.12, f'obs={lab_obs}\\n{st.path or \"base\"}',\n",
    "                fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "ax.set_title('CoDA transition graph (OSM-style clean layout)')\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_xlim(-1, 26)\n",
    "ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Example near–far correlation matrices across sessions (sanity check)\n",
    "We show the mean across runs at sessions 1, 3, 4, 9 (style similar to OSM matrices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_sessions = [1,3,4,9]\n",
    "mean_mats = {s: np.mean(mat_by_session[s], axis=0) for s in check_sessions}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(check_sessions), figsize=(4.5*len(check_sessions),4), constrained_layout=True)\n",
    "vmin, vmax = -0.1, 1.0\n",
    "for ax, s in zip(axes, check_sessions):\n",
    "    im = ax.imshow(mean_mats[s], vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
    "    ax.set_title(f\"Session {s}\")\n",
    "    ax.set_xlabel(\"Far position index\")\n",
    "    ax.set_ylabel(\"Near position index\")\n",
    "fig.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Fig. 4i — Final correlation quantification (bars with mean ± s.e.m.)\n",
    "This follows the OSM pipeline: compute block means from the final near–far matrix per run, then aggregate across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "means = blocks_df.mean()\n",
    "ses   = blocks_df.sem()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels))\n",
    "y = [means[l] for l in labels]\n",
    "yerr = [ses[l] for l in labels]\n",
    "\n",
    "ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Mean correlation (final)\")\n",
    "ax.set_title(\"CoDA — Final correlation quantification (Fig. 4i analogue)\")\n",
    "ax.set_ylim(0,1.0)\n",
    "for i,val in enumerate(y):\n",
    "    ax.text(i, val+0.03, f\"{val:.2f}\", ha='center', fontsize=9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Fig. 4j — Decorrelation order (time to reach correlation < 0.3)\n",
    "For each block we find the first session at which the mean correlation drops below 0.3, then plot the fraction of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "means_t = times_df.mean(skipna=True)\n",
    "ses_t   = times_df.sem(skipna=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "labels = ['offdiag_t','preR2_t','preR1_t']\n",
    "disp_labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels))\n",
    "y = [means_t[l] for l in labels]\n",
    "yerr = [ses_t[l] for l in labels]\n",
    "\n",
    "ax.bar(x, y, yerr=yerr, capsize=4, color=['#777','#2f6db3','#d64b5a'])\n",
    "ax.set_xticks(x); ax.set_xticklabels(disp_labels)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Fraction of training (to corr < 0.3)\")\n",
    "ax.set_title(\"CoDA — Decorrelation order (Fig. 4j analogue)\")\n",
    "for i,val in enumerate(y):\n",
    "    ax.text(i, min(1.02, val+0.04), f\"{val:.2f}\", ha='center', fontsize=9)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coda-minigrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
