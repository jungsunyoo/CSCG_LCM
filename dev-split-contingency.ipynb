{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import trange\n",
    "import copy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import igraph\n",
    "from matplotlib import cm, colors\n",
    "random.seed(42)\n",
    "import seaborn as sns\n",
    "from abstract_environments import * #ContinuousTMaze, GridEnvRightDownNoCue, GridEnvRightDownNoSelf, GridEnvDivergingMultipleReward, GridEnvDivergingSingleReward\n",
    "from util import *\n",
    "# from util import transition_matrix_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Simulating experiments described in this paper: [The role of prospective contingency in the control of behavior and dopamine signals during associative learning](https://pmc.ncbi.nlm.nih.gov/articles/PMC10871210/#S30) (Qian et al., 2024 bioRxiv)\n",
    "\n",
    "our hypothesis:\n",
    "\n",
    "degradation --> less split in delay. so more stochastic, therefore devaluation of A\n",
    "\n",
    "cued reward --> delay splits. therefore no devaluation of A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=0.8\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(np.random.binomial(n=1, p=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 1. Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: 1 = A, 4 = B, 2 = R, 3 = nR, 0 = delay\n",
    "observation_1 = [1,0,2] # start 1, left turn, rewarded\n",
    "observation_2 = [1,0,3] # start 1, left turn, rewarded\n",
    "observation_3 = [4,0,3] # start 2, right turn, rewarded\n",
    "observation_4 = [0,2] # start 1, right turn, no reward\n",
    "observation_5 = [0,3] # start 2, left turn, no reward\n",
    "# 2: left turn, 4: right turn, 5: reward, 6: no reward\n",
    "actions_1 = [0,0]\n",
    "actions_2 = [0,0]\n",
    "actions_3 = [0,0]\n",
    "actions_4 = [0]\n",
    "actions_5 = [0]\n",
    "\n",
    "a = 1\n",
    "b = 4\n",
    "r = 2\n",
    "nr = 3\n",
    "d = 0\n",
    "\n",
    "super_observations = (([observation_1] * 30) +\n",
    "                     ([observation_2] * 10) +\n",
    "                     ([observation_3] * 20) +\n",
    "                     ([observation_4] * 30) + \n",
    "                     ([observation_5] * 10))\n",
    "# and similarly for actions:\n",
    "super_actions =( ([actions_1] * 30) +\n",
    "                ([actions_2] * 10) +\n",
    "                ([actions_3] * 20) +\n",
    "                ([actions_4] * 30) +\n",
    "                ([actions_5] * 10))\n",
    "\n",
    "combined = list(zip(super_observations, super_actions))\n",
    "random.shuffle(combined)\n",
    "super_observations, super_actions = zip(*combined)  # unzip\n",
    "\n",
    "dataset=[]\n",
    "for l in range(len(super_observations)):\n",
    "    dataset.append([super_observations[l], super_actions[l]])\n",
    "\n",
    "\n",
    "\n",
    "transition_counts = transition_matrix_action(dataset)\n",
    "denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "denominators[denominators == 0] = 1\n",
    "transition_probs = transition_counts / denominators\n",
    "# denominators.shape\n",
    "actions = [0]\n",
    "iterations=20\n",
    "used_cues = []\n",
    "# clone_map = []\n",
    "clone_dict = {}\n",
    "reverse_clone_dict = {}\n",
    "graphiter = 0\n",
    "savename='tmaze'\n",
    "# plot_graph_nogrid(transition_probs,'initial',savename=savename)  \n",
    "# Actual code\n",
    "for i in range(iterations):\n",
    "    print(\"Iteration {}\".format(i))\n",
    "    entropies = compute_transition_entropies(transition_probs)\n",
    "    stochastic_pairs = find_stochastic_state_actions_by_entropy(entropies, eps=1e-9) # (s,a,sprime,sprime2)\n",
    "    \n",
    "    if stochastic_pairs: \n",
    "        cues = []\n",
    "        for (s, a) in stochastic_pairs:\n",
    "            print(\"Stochastic pairs: {}\".format((s,a)))\n",
    "            # if len(vali)\n",
    "            # valid_actions = env.get_valid_actions(s)\n",
    "            sprime, sprime2 = get_successor_states(transition_counts,s,a)\n",
    "            cue = calculate_contingency_tmaze(dataset, s, sprime, sprime2)\n",
    "            print(cue)\n",
    "            cues.append(cue)\n",
    "            \n",
    "        # split out the successor states\n",
    "        unique_cues = np.unique([x for sublist in cues for x in sublist])\n",
    "        print(unique_cues)\n",
    "        split = False\n",
    "        \n",
    "        for cue in unique_cues:\n",
    "            if cue in used_cues: \n",
    "                continue\n",
    "            if split == True: \n",
    "                continue\n",
    "            if cue > 6:\n",
    "                print(\"Current cue: {} (clone of {})\".format(cue, clone_dict[cue]))\n",
    "            else:\n",
    "                print(\"Current cue: {}\".format(cue))\n",
    "            \n",
    "            # if cue not in used_cues:\n",
    "            split=True # just split one at a time\n",
    "            # valid actions\n",
    "            # valid_actions = env.get_valid_actions(cue)\n",
    "            # for a in valid_actions:  \n",
    "            # if cue > 6: # cloned state, so need to get the valid actions from the original state\n",
    "            #     valid_actions = env.get_valid_actions(clone_dict[cue])\n",
    "            # else:\n",
    "            #     valid_actions = env.get_valid_actions(cue)\n",
    "            # clone_orig = clone_dict[]\n",
    "            for a in actions:\n",
    "                # print(cue,a)\n",
    "                if get_successor_states(transition_counts,cue,a).size>0:\n",
    "                    successor = get_successor_states(transition_counts,cue,a)[0] # suppose 7\n",
    "                    # if reverse_clone_dict[successor]: # this has been created before\n",
    "                    if successor in reverse_clone_dict:\n",
    "                        existing_clone = reverse_clone_dict[successor]\n",
    "                        for d, seq in enumerate(dataset):\n",
    "                            states_seq = seq[0]\n",
    "                            if has_state(states_seq, successor): # get all the sequence that has 7\n",
    "                                if has_transition(cue, successor,states_seq): # this is sequence that 6->7, clone 7\n",
    "                                    # 1. modify dataset\n",
    "\n",
    "                                    dataset[d][0] = [existing_clone if x==successor else x for x in dataset[d][0]] \n",
    "\n",
    "                    else:    # hasn't been created before. split        \n",
    "                        # split this as a function of whether it came from cue (6) vs. others\n",
    "                        # has_state(sequence,)\n",
    "                        n_unique_states = len(get_unique_states(dataset))\n",
    "                        new_clone = n_unique_states + 1            \n",
    "                        \n",
    "                        # clone_map.append((successor,new_clone))\n",
    "                        clone_dict[new_clone] = successor\n",
    "                        reverse_clone_dict[successor] = new_clone\n",
    "                        for d, seq in enumerate(dataset):\n",
    "                            states_seq = seq[0]\n",
    "                            if has_state(states_seq, successor): # get all the sequence that has 7\n",
    "                                if has_transition(cue, successor,states_seq): # this is sequence that 6->7, clone 7\n",
    "                                    # 1. modify dataset\n",
    "\n",
    "                                    dataset[d][0] = [new_clone if x==successor else x for x in dataset[d][0]] \n",
    "                    # 2. modify transition count\n",
    "                    transition_counts = transition_matrix_action(dataset)\n",
    "                    denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "                    denominators[denominators == 0] = 1\n",
    "                    transition_probs = transition_counts / denominators\n",
    "                    # graphiter = 0\n",
    "                    # plot_graph_nogrid(transition_probs,graphiter, cue, new_clone,savename=savename)\n",
    "                    graphiter+=1\n",
    "            used_cues.append(cue)\n",
    "    \n",
    "        print('\\n')\n",
    "    else:\n",
    "        print('Finished splitting at iteration {}'.format(i))\n",
    "        break        \n",
    "# plot_graph_nogrid(transition_probs,'final', savename=savename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 4\n",
    "r = 2\n",
    "nr = 3\n",
    "d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_r, E_nr = conditioned_eligibility_traces(dataset, r, nr, lam=lam, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(E_r, '\\n', E_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_r[E_r==0] = 1e-3\n",
    "# E_nr[E_nr==0] = 1e-3\n",
    "E_c = E_r / (E_r + E_nr )    \n",
    "E_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(E_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# 2. Cued Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: 1 = A, 4 = B, 2 = R, 3 = nR, 0 = delay\n",
    "observation_1 = [1,0,2] # start 1, left turn, rewarded\n",
    "observation_2 = [1,0,3] # start 1, left turn, rewarded\n",
    "observation_3 = [4,0,3] # start 2, right turn, rewarded\n",
    "observation_4 = [5,0,2] # start 1, right turn, no reward\n",
    "observation_5 = [5,0,3] # start 2, left turn, no reward\n",
    "# 2: left turn, 4: right turn, 5: reward, 6: no reward\n",
    "actions_1 = [0,0]\n",
    "actions_2 = [0,0]\n",
    "actions_3 = [0,0]\n",
    "actions_4 = [0,0]\n",
    "actions_5 = [0,0]\n",
    "\n",
    "a = 1\n",
    "b = 4\n",
    "r = 2\n",
    "nr = 3\n",
    "d = 0\n",
    "c = 5\n",
    "\n",
    "super_observations = (([observation_1] * 30) +\n",
    "                     ([observation_2] * 10) +\n",
    "                     ([observation_3] * 20) +\n",
    "                     ([observation_4] * 30) + \n",
    "                     ([observation_5] * 10))\n",
    "# and similarly for actions:\n",
    "super_actions =( ([actions_1] * 30) +\n",
    "                ([actions_2] * 10) +\n",
    "                ([actions_3] * 20) +\n",
    "                ([actions_4] * 30) +\n",
    "                ([actions_5] * 10))\n",
    "\n",
    "combined = list(zip(super_observations, super_actions))\n",
    "random.shuffle(combined)\n",
    "super_observations, super_actions = zip(*combined)  # unzip\n",
    "\n",
    "dataset=[]\n",
    "for l in range(len(super_observations)):\n",
    "    dataset.append([super_observations[l], super_actions[l]])\n",
    "\n",
    "\n",
    "\n",
    "transition_counts = transition_matrix_action(dataset)\n",
    "denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "denominators[denominators == 0] = 1\n",
    "transition_probs = transition_counts / denominators\n",
    "# denominators.shape\n",
    "actions = [0]\n",
    "iterations=20\n",
    "used_cues = []\n",
    "# clone_map = []\n",
    "clone_dict = {}\n",
    "reverse_clone_dict = {}\n",
    "graphiter = 0\n",
    "savename='tmaze'\n",
    "# plot_graph_nogrid(transition_probs,'initial',savename=savename)  \n",
    "# Actual code\n",
    "for i in range(iterations):\n",
    "    print(\"Iteration {}\".format(i))\n",
    "    entropies = compute_transition_entropies(transition_probs)\n",
    "    stochastic_pairs = find_stochastic_state_actions_by_entropy(entropies, eps=1e-9) # (s,a,sprime,sprime2)\n",
    "    \n",
    "    if stochastic_pairs: \n",
    "        cues = []\n",
    "        for (s, a) in stochastic_pairs:\n",
    "            print(\"Stochastic pairs: {}\".format((s,a)))\n",
    "            # if len(vali)\n",
    "            # valid_actions = env.get_valid_actions(s)\n",
    "            sprime, sprime2 = get_successor_states(transition_counts,s,a)\n",
    "            cue = calculate_contingency_tmaze(dataset, s, sprime, sprime2)\n",
    "            print(cue)\n",
    "            cues.append(cue)\n",
    "            \n",
    "        # split out the successor states\n",
    "        unique_cues = np.unique([x for sublist in cues for x in sublist])\n",
    "        print(unique_cues)\n",
    "        split = False\n",
    "        \n",
    "        for cue in unique_cues:\n",
    "            if cue in used_cues: \n",
    "                continue\n",
    "            if split == True: \n",
    "                continue\n",
    "            if cue > 6:\n",
    "                print(\"Current cue: {} (clone of {})\".format(cue, clone_dict[cue]))\n",
    "            else:\n",
    "                print(\"Current cue: {}\".format(cue))\n",
    "            \n",
    "            # if cue not in used_cues:\n",
    "            split=True # just split one at a time\n",
    "            # valid actions\n",
    "            # valid_actions = env.get_valid_actions(cue)\n",
    "            # for a in valid_actions:  \n",
    "            # if cue > 6: # cloned state, so need to get the valid actions from the original state\n",
    "            #     valid_actions = env.get_valid_actions(clone_dict[cue])\n",
    "            # else:\n",
    "            #     valid_actions = env.get_valid_actions(cue)\n",
    "            # clone_orig = clone_dict[]\n",
    "            for a in actions:\n",
    "                # print(cue,a)\n",
    "                if get_successor_states(transition_counts,cue,a).size>0:\n",
    "                    successor = get_successor_states(transition_counts,cue,a)[0] # suppose 7\n",
    "                    # if reverse_clone_dict[successor]: # this has been created before\n",
    "                    if successor in reverse_clone_dict:\n",
    "                        existing_clone = reverse_clone_dict[successor]\n",
    "                        for d, seq in enumerate(dataset):\n",
    "                            states_seq = seq[0]\n",
    "                            if has_state(states_seq, successor): # get all the sequence that has 7\n",
    "                                if has_transition(cue, successor,states_seq): # this is sequence that 6->7, clone 7\n",
    "                                    # 1. modify dataset\n",
    "\n",
    "                                    dataset[d][0] = [existing_clone if x==successor else x for x in dataset[d][0]] \n",
    "\n",
    "                    else:    # hasn't been created before. split        \n",
    "                        # split this as a function of whether it came from cue (6) vs. others\n",
    "                        # has_state(sequence,)\n",
    "                        n_unique_states = len(get_unique_states(dataset))\n",
    "                        new_clone = n_unique_states + 1            \n",
    "                        \n",
    "                        # clone_map.append((successor,new_clone))\n",
    "                        clone_dict[new_clone] = successor\n",
    "                        reverse_clone_dict[successor] = new_clone\n",
    "                        for d, seq in enumerate(dataset):\n",
    "                            states_seq = seq[0]\n",
    "                            if has_state(states_seq, successor): # get all the sequence that has 7\n",
    "                                if has_transition(cue, successor,states_seq): # this is sequence that 6->7, clone 7\n",
    "                                    # 1. modify dataset\n",
    "\n",
    "                                    dataset[d][0] = [new_clone if x==successor else x for x in dataset[d][0]] \n",
    "                    # 2. modify transition count\n",
    "                    transition_counts = transition_matrix_action(dataset)\n",
    "                    denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "                    denominators[denominators == 0] = 1\n",
    "                    transition_probs = transition_counts / denominators\n",
    "                    # graphiter = 0\n",
    "                    # plot_graph_nogrid(transition_probs,graphiter, cue, new_clone,savename=savename)\n",
    "                    graphiter+=1\n",
    "            used_cues.append(cue)\n",
    "    \n",
    "        print('\\n')\n",
    "    else:\n",
    "        print('Finished splitting at iteration {}'.format(i))\n",
    "        break        \n",
    "# plot_graph_nogrid(transition_probs,'final', savename=savename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_r, E_nr = conditioned_eligibility_traces(dataset, r, nr, lam=lam, gamma=gamma)\n",
    "print(E_r, '\\n', E_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_r[E_r==0] = 1e-3\n",
    "# E_nr[E_nr==0] = 1e-3\n",
    "E_c = E_r / (E_r + E_nr )    \n",
    "E_c\n",
    "sns.heatmap(E_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Latent Inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "size = 3\n",
    "env_size = (size,size)\n",
    "rewarded_terminal = env_size[0]*env_size[1]-1\n",
    "cue_states = [4]\n",
    "env = GridLatentInhibition(env_size=env_size, \n",
    "                             rewarded_terminal = [rewarded_terminal],\n",
    "                             cue_states=cue_states)\n",
    "\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "dataset = generate_inhibition_dataset(env, n_episodes=36)\n",
    "\n",
    "for walk in dataset:\n",
    "    print(walk)\n",
    "\n",
    "\n",
    "transition_counts = transition_matrix_action(dataset)\n",
    "denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "denominators[denominators == 0] = 1\n",
    "transition_probs = transition_counts / denominators\n",
    "# denominators.shape\n",
    "actions = [0,1]\n",
    "iterations=100\n",
    "used_cues = []\n",
    "graphiter = 0\n",
    "savename='cued'\n",
    "env.plot_graph(transition_probs,'initial',savename=savename)  \n",
    "\n",
    "for i in range(iterations):\n",
    "    print(\"Iteration {}\".format(i))\n",
    "\n",
    "    entropies = compute_transition_entropies(transition_probs)\n",
    "    stochastic_pairs = find_stochastic_state_actions_by_entropy(entropies, eps=1e-9) # (s,a,sprime,sprime2)\n",
    "    \n",
    "    if stochastic_pairs: \n",
    "        cues = []\n",
    "        for (s, a) in stochastic_pairs: # s is something like 15 (->16)\n",
    "            # print(\"Stochastic pairs: {}\".format((s,a)))\n",
    "            sprime, sprime2 = get_successor_states(transition_counts,s,a) # this is something like 16, 17\n",
    "            cue = calculate_contingency(dataset, sprime, sprime2, env_size)\n",
    "            cues.append(cue)\n",
    "            \n",
    "        # split out the successor states\n",
    "        unique_cues = np.unique([x for sublist in cues for x in sublist])\n",
    "        split = False\n",
    "        \n",
    "        for cue in unique_cues:\n",
    "            if cue in used_cues: \n",
    "                continue\n",
    "            if split == True: \n",
    "                continue\n",
    "            split=True # just split one at a time\n",
    "\n",
    "            if cue > env.num_unique_states-1: #17: # cloned state, so need to get the valid actions from the original state\n",
    "                valid_actions = env.get_valid_actions(env.clone_dict[cue])\n",
    "            else:\n",
    "                valid_actions = env.get_valid_actions(cue)\n",
    "            for a in valid_actions:\n",
    "                # print(cue,a)\n",
    "                successor = get_successor_states(transition_counts,cue,a)[0] # suppose 7\n",
    "                if successor in env.reverse_clone_dict: # this has been created before\n",
    "                    existing_clone = env.reverse_clone_dict[successor]\n",
    "                    for d, seq in enumerate(dataset):\n",
    "                        states_seq = seq[0]\n",
    "                        if has_state(states_seq, successor): # get all the sequence that has 7\n",
    "                            if has_transition(cue, successor,states_seq): # this is sequence that 6->7, clone 7\n",
    "                                # 1. modify dataset\n",
    "                                dataset[d][0] = [existing_clone if x==successor else x for x in dataset[d][0]] \n",
    "\n",
    "                else:    # hasn't been created before. split        \n",
    "                    # split this as a function of whether it came from cue (6) vs. others\n",
    "                    # has_state(sequence,)\n",
    "                    n_unique_states = len(get_unique_states(dataset))\n",
    "                    new_clone = n_unique_states            \n",
    "                    \n",
    "                    # clone_map.append((successor,new_clone))\n",
    "                    env.add_clone_dict(new_clone, successor)\n",
    "                    # clone_dict[new_clone] = successor\n",
    "                    env.add_reverse_clone_dict(new_clone, successor)\n",
    "                    # reverse_clone_dict[successor] = new_clone\n",
    "                    for d, seq in enumerate(dataset):\n",
    "                        states_seq = seq[0]\n",
    "                        if has_state(states_seq, successor): # get all the sequence that has 7\n",
    "                            if has_transition(cue, successor,states_seq): # this is sequence that 6->7, clone 7\n",
    "                                # 1. modify dataset\n",
    "\n",
    "                                dataset[d][0] = [new_clone if x==successor else x for x in dataset[d][0]] \n",
    "                # 2. modify transition count\n",
    "                transition_counts = transition_matrix_action(dataset)\n",
    "                denominators = transition_counts.sum(axis=2, keepdims=True)\n",
    "                denominators[denominators == 0] = 1\n",
    "                transition_probs = transition_counts / denominators\n",
    "                # graphiter = 0\n",
    "                env.plot_graph(transition_probs,graphiter, cue, new_clone,savename=savename)\n",
    "                graphiter+=1\n",
    "            used_cues.append(cue)\n",
    "    \n",
    "        print('\\n')\n",
    "    else:\n",
    "        print('Finished splitting at iteration {}'.format(i))\n",
    "        break        \n",
    "env.plot_graph(transition_probs,'final', savename=savename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cscg",
   "language": "python",
   "name": "cscg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
