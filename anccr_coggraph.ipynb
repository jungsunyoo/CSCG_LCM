{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import trange\n",
    "import copy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import igraph\n",
    "from matplotlib import cm, colors\n",
    "random.seed(42)\n",
    "import seaborn as sns\n",
    "from testing_environments import ContinuousTMaze, GridEnv,GridEnvRightDownNoCue, GridEnvRightDownNoSelf, GridEnvDivergingMultipleReward, GridEnvDivergingSingleReward\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distribution_eig(P):\n",
    "    \"\"\"\n",
    "    Computes the stationary distribution of transition matrix P\n",
    "    by solving P^T * v = v, and normalizing v so sum(v)=1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : 2D np.ndarray, shape (N, N)\n",
    "        Transition matrix of a Markov chain (rows sum to 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z : 1D np.ndarray, shape (N,)\n",
    "        The stationary distribution (row vector) such that zP = z.\n",
    "    \"\"\"\n",
    "    # Eigen-decomposition of P^T\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "\n",
    "    # Find index of eigenvalue 1 (within a numerical tolerance)\n",
    "    idx = np.argmin(np.abs(eigenvalues - 1.0))\n",
    "\n",
    "    # The corresponding eigenvector\n",
    "    v = np.real(eigenvectors[:, idx])  # ensure it's real\n",
    "\n",
    "    # Normalize so that it sums to 1\n",
    "    # We also make sure all entries are non-negative (small numerical errors can introduce tiny negatives)\n",
    "    v = np.where(v < 0, 0, v)  # clip negative values to 0 if needed\n",
    "    if np.sum(v) == 0:\n",
    "        raise ValueError(\"No non-negative eigenvector found corresponding to eigenvalue 1.\")\n",
    "    z = v / np.sum(v)\n",
    "\n",
    "    return z\n",
    "\n",
    "def stationary_distribution_power(P, max_iter=1000, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Computes the stationary distribution of transition matrix P\n",
    "    by repeated multiplication (power iteration).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : 2D np.ndarray, shape (N, N)\n",
    "        Transition matrix of a Markov chain (rows sum to 1).\n",
    "    max_iter : int\n",
    "        Maximum number of iterations.\n",
    "    tol : float\n",
    "        Convergence tolerance (on L1 or L2 difference).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z : 1D np.ndarray, shape (N,)\n",
    "        The stationary distribution (row vector).\n",
    "    \"\"\"\n",
    "    N = P.shape[0]\n",
    "    # Start from a uniform distribution (or random)\n",
    "    z = np.ones(N) / N  \n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        z_next = z @ P  # matrix multiplication from the left\n",
    "        # Check convergence by comparing difference\n",
    "        if np.linalg.norm(z_next - z, 1) < tol:\n",
    "            break\n",
    "        z = z_next\n",
    "\n",
    "    # Normalize (just in case of tiny drift)\n",
    "    z /= np.sum(z)\n",
    "    return z\n",
    "def row_normalize(matrix):\n",
    "    \"\"\"\n",
    "    Returns a row-normalized copy of 'matrix'.\n",
    "    Each row of the result sums to 1.\n",
    "    \"\"\"\n",
    "    # Convert to float to avoid integer division issues\n",
    "    matrix = matrix.astype(float)\n",
    "    \n",
    "    # Sum over columns, keep dimension for broadcasting\n",
    "    row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Avoid division by zero by replacing zeros with 1.0\n",
    "    row_sums[row_sums == 0] = 1.0\n",
    "    \n",
    "    # Divide each row by its sum\n",
    "    normalized = matrix / row_sums\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 4\n",
    "env_size = (size,size)\n",
    "rewarded_terminal = env_size[0]*env_size[1]\n",
    "cue_states = [6]\n",
    "# env = GridEnvRightDownNoSelf(env_size=env_size, \n",
    "#                              rewarded_terminal = [rewarded_terminal],\n",
    "#                              cue_states=cue_states)\n",
    "env = GridEnv(env_size=env_size, \n",
    "                             rewarded_terminal = [rewarded_terminal],\n",
    "                             cue_states=cue_states)\n",
    "# env = GridEnvRightDownNoSelf(cue_states=[6])\n",
    "\n",
    "n_episodes = 1000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "dataset = generate_dataset(env, n_episodes, max_steps_per_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = transition_matrix(dataset)\n",
    "\n",
    "# P = P[1:, 1:]\n",
    "\n",
    "P = row_normalize(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = np.array([\n",
    "#     [0.9, 0.1, 0.0],\n",
    "#     [0.9, 0.0, 0.1],\n",
    "#     [1.0, 0.0, 0.0]\n",
    "# ])\n",
    "\n",
    "z = stationary_distribution_eig(P)\n",
    "print(\"Stationary distribution (via eigenvector):\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# P = np.array([\n",
    "#     [0.9, 0.1, 0.0],\n",
    "#     [0.9, 0.0, 0.1],\n",
    "#     [1.0, 0.0, 0.0]\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "z = stationary_distribution_power(P[1:,1:])\n",
    "print(\"Stationary distribution (via power iteration):\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = np.array([\n",
    "#     [0.9, 0.1, 0.0],\n",
    "#     [0.9, 0.0, 0.1],\n",
    "#     [1.0, 0.0, 0.0]\n",
    "# ])\n",
    "\n",
    "# z = stationary_distribution_eig(P)\n",
    "# print(\"Stationary distribution (via eigenvector):\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[P[0,0]*z[0]/z[0], P[0,1]*z[0]/z[1], P[0,2]*z[0]/z[2]], \n",
    "#  [P[1,0]*z[1]/z[0], P[1,1]*z[1]/z[1], P[1,2]*z[1]/z[2]], \n",
    "#  [P[2,0]*z[2]/z[0], P[2,1]*z[2]/z[1], P[2,2]*z[2]/z[2]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_r = retrospective_transition_matrix(P[1:,1:], z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(P_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "def successor_representation(P, gamma=0.9):\n",
    "    \"\"\"\n",
    "    Compute the Successor Representation (SR) for a Markov chain or MDP \n",
    "    given a prospective (forward) transition matrix P and a discount factor gamma.\n",
    "\n",
    "    SR = (I - gamma*P)^{-1}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : np.ndarray of shape (n, n)\n",
    "        The forward (prospective) transition matrix, where P[i,j] \n",
    "        is the probability of transitioning from state i to state j.\n",
    "        Typically, rows sum to 1.\n",
    "    gamma : float\n",
    "        The discount factor in [0, 1). Commonly 0.9 or similar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    SR : np.ndarray of shape (n, n)\n",
    "        The successor representation matrix.\n",
    "        SR[i, j] can be interpreted as the expected discounted time \n",
    "        spent in state j if you start in state i.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    I = np.eye(n)\n",
    "    # Compute (I - gamma * P)^{-1} if it's invertible\n",
    "    SR = np.linalg.inv(I - gamma * P)\n",
    "    return SR\n",
    "\n",
    "def predecessor_representation(P_r, gamma=0.9):\n",
    "    \"\"\"\n",
    "    Compute the predecessor representation for a time-reversed (retrospective)\n",
    "    transition matrix P_r and discount factor gamma.\n",
    "\n",
    "    PR = (I - gamma*P_r)^{-1}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P_r : 2D np.ndarray, shape (n, n)\n",
    "        The time-reversed transition matrix.\n",
    "    gamma : float\n",
    "        Discount factor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PR : 2D np.ndarray, shape (n, n)\n",
    "        The predecessor representation matrix.\n",
    "    \"\"\"\n",
    "    n = P_r.shape[0]\n",
    "    I = np.eye(n)\n",
    "    # Compute (I - gamma * P_r)^{-1}\n",
    "    PR = np.linalg.inv(I - gamma * P_r)\n",
    "    return PR\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Example usage\n",
    "# -----------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "    # Suppose we have the retrospective transition matrix (approx from your example)\n",
    "    # This is the \"time-reversed\" version of the original P_s, with z ~ [0.9009, 0.0901, 0.009].\n",
    "    # NOTE: The exact numbers may vary slightly based on rounding.\n",
    "# P_r = np.array([\n",
    "#     [0.9,   1.0,  0.0],\n",
    "#     [0.09,  0.0,  1.0],\n",
    "#     [0.01,  0.0,  1.0]\n",
    "# ])\n",
    "\n",
    "gamma = 0.9\n",
    "PR = predecessor_representation(P_r, gamma)\n",
    "\n",
    "print(\"Retrospective transition matrix, P_r:\")\n",
    "print(P_r, \"\\n\")\n",
    "\n",
    "print(f\"Predecessor Representation (gamma={gamma}):\")\n",
    "# Rounded for readability\n",
    "print(PR.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = successor_representation(P, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(PR,             xticklabels=range(1, 17), \n",
    "            yticklabels=range(1, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(SR[1:,1:], xticklabels=range(1, 17), yticklabels=range(1, 17) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "def predecessor_representation_contingency(Mp):\n",
    "    \"\"\"\n",
    "    Compute the 'contingency' version of the Predecessor Representation (PR).\n",
    "\n",
    "    Mp : np.ndarray of shape (n, n)\n",
    "        The Predecessor Representation matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Mp_cont : np.ndarray of shape (n, n)\n",
    "        The PR contingency matrix, Mp - (Mp*E)/m.\n",
    "    \"\"\"\n",
    "    n = Mp.shape[0]\n",
    "    E = np.ones((n, n))\n",
    "    # Mp * E is shape (n, n), each row i is the sum of row i repeated across columns.\n",
    "    # Divide by n to get the row average, then subtract from Mp.\n",
    "    Mp_cont = Mp - (Mp @ E) / n\n",
    "    return Mp_cont\n",
    "\n",
    "def successor_representation_contingency(Ms):\n",
    "    \"\"\"\n",
    "    Compute the 'contingency' version of the Successor Representation (SR).\n",
    "\n",
    "    Ms : np.ndarray of shape (n, n)\n",
    "        The Successor Representation matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Ms_cont : np.ndarray of shape (n, n)\n",
    "        The SR contingency matrix, Ms - (Ms*E)/m.\n",
    "    \"\"\"\n",
    "    n = Ms.shape[0]\n",
    "    E = np.ones((n, n))\n",
    "    Ms_cont = Ms - (Ms @ E) / n\n",
    "    return Ms_cont\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Example Usage\n",
    "# --------------------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "    # Example: Suppose we have a 3x3 PR matrix from earlier\n",
    "# Mp = np.array([\n",
    "#     [ 9.01,  9.11,  8.20],\n",
    "#     [ 0.90,  0.81,  1.73],\n",
    "#     [ 0.09,  0.08,  0.07]\n",
    "# ])\n",
    "Mp = PR\n",
    "# And an example SR matrix (made-up values)\n",
    "# Ms = np.array([\n",
    "#     [ 1.2,  1.0,  0.8],\n",
    "#     [ 0.1,  1.6,  2.5],\n",
    "#     [ 0.3,  0.9,  3.1]\n",
    "# ])\n",
    "Ms = SR\n",
    "\n",
    "Mp_cont = predecessor_representation_contingency(Mp)\n",
    "Ms_cont = successor_representation_contingency(Ms)\n",
    "\n",
    "print(\"Predecessor Representation (Mp):\")\n",
    "print(Mp.round(2), \"\\n\")\n",
    "\n",
    "print(\"Mp contingency = Mp - (Mp*E)/n :\")\n",
    "print(Mp_cont.round(2), \"\\n\")\n",
    "\n",
    "print(\"Successor Representation (Ms):\")\n",
    "print(Ms.round(2), \"\\n\")\n",
    "\n",
    "print(\"Ms contingency = Ms - (Ms*E)/n :\")\n",
    "print(Ms_cont.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Mp_cont, xticklabels=range(1, 17), yticklabels=range(1, 17) , cmap='RdBu_r', center=0)\n",
    "plt.title('Predecessor representation contingency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRC_MAP = Mp_cont[:,-1]\n",
    "PRC_MAP = np.reshape(PRC_MAP, (4,4))\n",
    "num_rows, num_cols = PRC_MAP.shape\n",
    "annotations = np.arange(1, num_rows * num_cols + 1).reshape(num_rows, num_cols)\n",
    "sns.heatmap(PRC_MAP,  xticklabels=range(1, 5), yticklabels=range(1, 5),  \n",
    "            cmap='RdBu_r', \n",
    "                      annot=annotations,  # Provide the annotation array\n",
    "            fmt='d',            # Integer formatting\n",
    "            # cmap='viridis',\n",
    "            center=0 , \n",
    "            annot_kws={\"size\": 20} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Ms_cont[1:,1:], xticklabels=range(1, 17), yticklabels=range(1, 17) )\n",
    "plt.title('Successor representation contingency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_r_ = np.reshape(P_r, (env_size[0],env_size[1]))\n",
    "# P_r_ = np.transpose(P_r_)\n",
    "# sns.heatmap(P_r_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('cscg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4c7db56e4aa600ad0a9a975c34bbf2d671fd5a4715ac0a7956790af44717dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
