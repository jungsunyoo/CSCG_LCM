{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CoDA in Sun et al. (2025) 2ACDC near/far task — reproducing Fig. 4c (bonus), Fig. 4i and Fig. 4j\n",
    "\n",
    "**What this notebook does**\n",
    "- Builds the **2ACDC near/far** stimulus sequences exactly as used for the CSCG simulations in Sun et al. (2025).\n",
    "- Runs **CoDA** (Contingency‑Dependent State Augmentation) on those sequences, using contextual eligibility traces and split/merge rules.\n",
    "- Computes **near–far cross‑correlation matrices** from the model’s internal latent states over learning, then\n",
    "  - **Fig. 4i analogue:** summarizes the final matrix by the same **key blocks** (off‑diagonal, pre‑R2, pre‑R1),\n",
    "  - **Fig. 4j analogue:** measures the **time to reach a correlation threshold (0.3)** in each block to recover the decorrelation order (off‑diag → pre‑R2 → pre‑R1).\n",
    "- **Bonus (Fig. 4c analogue):** plots CoDA’s final latent-state transition graph for the two branches.\n",
    "\n",
    "> Citations for task definition and evaluation scheme are included inline below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## References used to match Sun et al.'s environment\n",
    "\n",
    "- **Task & CSCG simulation details** (symbol sequences, key blocks, correlation threshold): see _Learning produces an orthogonalized state machine in the hippocampus_, Sun et al., **Nature** (2025), Fig. 4 and Methods. We use their near/far sequences and the same 0.3 correlation threshold and three “key regions/blocks.”\n",
    "- **CoDA algorithm** (contextual eligibility traces; split/merge via prospective/retrospective contingency): see Yoo et al., _Contingency‑dependent state augmentation as a normative learning rule for non‑Markovian tasks_ (paper provided).\n",
    "\n",
    "> If you have the CSCG repository and source data available locally, there are optional hooks below to overlay animal/CSCG bars, but the core of this notebook produces **CoDA‑only** versions of Fig. 4i and 4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Imports & basic setup ====\n",
    "import math, random, itertools, collections\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "random.seed(0); np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Optional) Use your own CoDA implementation if present\n",
    "# If you have the CoDA zip (e.g., coda_minigrid_project_coda-fixed.zip) next to this notebook, uncomment and run:\n",
    "# import os, zipfile, sys\n",
    "# zip_path = \"coda_minigrid_project_coda-fixed.zip\"  # adjust if needed\n",
    "# if os.path.exists(zip_path):\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "#         zf.extractall(\"coda_repo\")\n",
    "#     sys.path.insert(0, os.path.abspath(\"coda_repo\"))\n",
    "#     try:\n",
    "#         from coda import CoDAAgent as RepoCoDAAgent\n",
    "#         print(\"Using CoDAAgent from your repository (RepoCoDAAgent).\")\n",
    "#     except Exception as e:\n",
    "#         print(\"Could not import RepoCoDAAgent from your repo:\", e)\n",
    "# else:\n",
    "#     print(\"No local CoDA zip found; using the minimal CoDA defined in this notebook.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Sun et al. (2025) 2ACDC near/far sequences and block definitions\n",
    "\n",
    "Following Sun et al. Methods (CSCG section), we use the exact discrete sequences of **sensory symbols** (each element is a 10 cm segment):\n",
    "\n",
    "- **Symbol legend**: `1` = grey corridor, `2` = near indicator (Ind_near), `3` = far indicator (Ind_far), `4` = visual cue at near reward zone (R1_vis), `5` = visual cue at far reward zone (R2_vis), `6` = water reward (shared), `7` = brick wall (end), `0` = teleportation.\n",
    "\n",
    "- **Near trial**: `[1×6, 2×4, 1×3, 4, 6, 1×3, 5×2, 1×2, 7, 0×3]`  \n",
    "  Expanded: `[1,1,1,1,1,1, 2,2,2,2, 1,1,1, 4, 6, 1,1,1, 5,5, 1,1, 7, 0,0,0]`\n",
    "\n",
    "- **Far trial**: `[1×6, 3×4, 1×3, 4×2, 1×3, 5, 6, 1×2, 7, 0×3]`  \n",
    "  Expanded: `[1,1,1,1,1,1, 3,3,3,3, 1,1,1, 4,4, 1,1,1, 5, 6, 1,1, 7, 0,0,0]`\n",
    "\n",
    "**Key blocks (Fig. 4i/j):**\n",
    "- `preR1` = the grey region between indicator and **visual R1** (`4`): indices `10..12` (inclusive) in both sequences.\n",
    "- `preR2` = the grey region between (R1_vis/water) and **visual R2** (`5`): indices `15..17` in both sequences.\n",
    "- `offdiag` = the two off‑diagonal cross‑blocks between `preR1` (near) × `preR2` (far) **and** `preR2` (near) × `preR1` (far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Task sequences & index helpers ====\n",
    "near = [1,1,1,1,1,1, 2,2,2,2, 1,1,1, 4, 6, 1,1,1, 5,5, 1,1, 7, 0,0,0]\n",
    "far  = [1,1,1,1,1,1, 3,3,3,3, 1,1,1, 4,4, 1,1,1, 5, 6, 1,1, 7, 0,0,0]\n",
    "assert len(near)==len(far)==26\n",
    "\n",
    "# Indices for key blocks (inclusive ranges)\n",
    "preR1_idx = list(range(10,13))   # 10,11,12\n",
    "preR2_idx = list(range(15,18))   # 15,16,17\n",
    "\n",
    "def block_indices(rows, cols):\n",
    "    return [(r,c) for r in rows for c in cols]\n",
    "\n",
    "offdiag_pairs     = block_indices(preR1_idx, preR2_idx) + block_indices(preR2_idx, preR1_idx)\n",
    "same_preR1_pairs  = block_indices(preR1_idx, preR1_idx)\n",
    "same_preR2_pairs  = block_indices(preR2_idx, preR2_idx)\n",
    "\n",
    "symbols = sorted(set(near) | set(far))\n",
    "symbols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Minimal CoDA implementation (tabular, with contextual eligibility traces)\n",
    "\n",
    "We implement CoDA following the paper’s pseudocode:\n",
    "\n",
    "- Contextual eligibility traces (reward‑conditioned) to compute a **prospective contingency** for each state, `P(US | CS)`.\n",
    "- **Split rule:** when `max_u P(u|s) > theta_split`, mark `s` as a cue for outcome `u` and **clone** all successors so that downstream states can encode the cue‑dependent history.\n",
    "- **Merge rule:** included for completeness (via `P(CS | US)` and the utility product), but it is not expected to trigger in this fixed environment.\n",
    "- **Multi‑US generalization:** for the 2ACDC task, we treat the two **visual reward zone cues** as the salient outcomes (`US ∈ {4 (R1_vis), 5 (R2_vis)}`), exactly because the **indicator** (`2` or `3`) perfectly predicts which **visual** reward cue will occur later (this avoids the trivial case where water `6` follows every state).\n",
    "\n",
    "Default parameters mirror the paper: `lambda=0.8`, `gamma=0.9`, `theta_split=0.9`, `theta_merge=0.5` (see Table 2 in the CoDA manuscript)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== CoDA agent ====\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LatentState:\n",
    "    id: int\n",
    "    obs: int                     # emitted observation symbol (aliased)\n",
    "    path: Optional[str] = None   # None, 'R1', or 'R2' history tag\n",
    "    parent: Optional[int] = None # id of original parent (for merges/visualization)\n",
    "\n",
    "class CoDAAgent:\n",
    "    def __init__(self, obs_symbols, gamma=0.9, lam=0.8, theta_split=0.9, theta_merge=0.5):\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.theta_split = theta_split\n",
    "        self.theta_merge = theta_merge\n",
    "        self.reset_symbols = {0}         # reset context at teleportation\n",
    "        \n",
    "        # Base latent states: one per observation\n",
    "        self.states: Dict[int, LatentState] = {}\n",
    "        self.obs_to_state_ids: Dict[int, List[int]] = {o: [] for o in obs_symbols}\n",
    "        sid = 0\n",
    "        for o in obs_symbols:\n",
    "            st = LatentState(id=sid, obs=o, path=None, parent=None)\n",
    "            self.states[sid] = st\n",
    "            self.obs_to_state_ids[o].append(sid)\n",
    "            sid += 1\n",
    "        self._next_sid = sid\n",
    "        \n",
    "        # Edges: count transitions actually experienced (for viz)\n",
    "        self.edge_counts = collections.Counter()  # (sid_from, sid_to) -> count\n",
    "        \n",
    "        # Contingency tracking (multi-US): co-occurrence eligibility sums per state × outcome\n",
    "        self.us_classes = [4,5] # R1_vis, R2_vis\n",
    "        self.co_occ = {s: {u: 0.0 for u in self.us_classes} for s in self.states}\n",
    "        \n",
    "        # For retrospective (optional): counts of state presence on episodes with/without a given US\n",
    "        self.state_exposure = collections.Counter()  # s -> total exposure amount (eligibility mass)\n",
    "        self.salient: Dict[int, str] = {}  # state_id -> 'R1' or 'R2'\n",
    "        \n",
    "    def _clone_state(self, orig_state_id: int, path: str) -> int:\n",
    "        orig = self.states[orig_state_id]\n",
    "        clone = LatentState(id=self._next_sid, obs=orig.obs, path=path, parent=orig_state_id)\n",
    "        self.states[self._next_sid] = clone\n",
    "        self.obs_to_state_ids[orig.obs].append(self._next_sid)\n",
    "        self._next_sid += 1\n",
    "        return clone.id\n",
    "    \n",
    "    def _select_state_for_obs(self, obs: int, current_context: Optional[str]) -> int:\n",
    "        # Choose existing latent state for a given observation and current context history.\n",
    "        candidates = self.obs_to_state_ids[obs]\n",
    "        # Prefer a candidate with matching path (context), else fall back to base (path=None)\n",
    "        if current_context is not None:\n",
    "            for sid in candidates:\n",
    "                if self.states[sid].path == current_context:\n",
    "                    return sid\n",
    "        # fallback to base (path=None); if several, pick the very first base (id order)\n",
    "        for sid in candidates:\n",
    "            if self.states[sid].path is None:\n",
    "                return sid\n",
    "        # else return first candidate\n",
    "        return candidates[0]\n",
    "    \n",
    "    def run_episode(self, obs_seq: List[int], learn=True):\n",
    "        # Run one episode. If learn=True, update contingencies and consider splits.\n",
    "        # Returns the sequence of active latent state ids (one per time step).\n",
    "        # Track context based on salient cues encountered\n",
    "        context = None\n",
    "        latent_seq = []\n",
    "        \n",
    "        # First, pass through the sequence to get latent states actually traversed.\n",
    "        # We do not split during traversal; splits happen after contingency updates.\n",
    "        for t, obs in enumerate(obs_seq):\n",
    "            sid = self._select_state_for_obs(obs, context)\n",
    "            latent_seq.append(sid)\n",
    "            # Update context if current sid is a salient cue\n",
    "            if sid in self.salient:\n",
    "                context = self.salient[sid]\n",
    "            if obs in self.reset_symbols:\n",
    "                context = None\n",
    "        \n",
    "        if not learn:\n",
    "            return latent_seq\n",
    "        \n",
    "        # === CONTINGENCY UPDATES via contextual eligibility ===\n",
    "        # Identify positions of US events: visual R1 (4) and visual R2 (5)\n",
    "        us_positions = {4: [i for i,o in enumerate(obs_seq) if o==4],\n",
    "                        5: [i for i,o in enumerate(obs_seq) if o==5]}\n",
    "        \n",
    "        # For each US event, accumulate a decayed eligibility trace over prior states\n",
    "        for u, positions in us_positions.items():\n",
    "            for t_us in positions:\n",
    "                e = np.zeros(len(self.states), dtype=float)\n",
    "                # propagate a backward trace from start..t_us\n",
    "                for t in range(t_us+1):\n",
    "                    sid = latent_seq[t]\n",
    "                    # decay\n",
    "                    e *= (self.gamma * self.lam)\n",
    "                    e[sid] += 1.0\n",
    "                    # store state exposure (for optional retrospective)\n",
    "                    self.state_exposure[sid] += e[sid]\n",
    "                # Add the snapshot at US time to co-occurrence\n",
    "                for s_id, val in enumerate(e):\n",
    "                    if val>0:\n",
    "                        self.co_occ[s_id][u] += val\n",
    "        \n",
    "        # === SPLITTING (forward / prospective) ===\n",
    "        # Compute P(u|s) as normalized co-occurrence over US classes\n",
    "        P = {}\n",
    "        for s in self.states:\n",
    "            tot = sum(self.co_occ[s][u] for u in self.us_classes)\n",
    "            if tot<=0:\n",
    "                P[s] = {u: 0.0 for u in self.us_classes}\n",
    "            else:\n",
    "                P[s] = {u: self.co_occ[s][u]/tot for u in self.us_classes}\n",
    "        \n",
    "        # Mark new salient cues\n",
    "        newly_salient = []\n",
    "        for s in self.states:\n",
    "            if s in self.salient:\n",
    "                continue\n",
    "            if sum(self.co_occ[s].values())<=0:\n",
    "                continue\n",
    "            # strongest US\n",
    "            u_star = max(self.us_classes, key=lambda u: P[s][u])\n",
    "            if P[s][u_star] > self.theta_split:\n",
    "                path = 'R1' if u_star==4 else 'R2'\n",
    "                self.salient[s] = path\n",
    "                newly_salient.append((s, path))\n",
    "        \n",
    "        # Create clones of successors along the same path (propagate downstream splitting)\n",
    "        # We look at actual transitions experienced in this episode and clone the \"next\" state under context\n",
    "        for s, path in newly_salient:\n",
    "            # find all indices where latent_seq[t]==s and t+1 exists\n",
    "            idxs = [t for t, sid in enumerate(latent_seq[:-1]) if sid==s]\n",
    "            for t in idxs:\n",
    "                next_obs = obs_seq[t+1]\n",
    "                # ensure a clone exists for next_obs with matching path\n",
    "                next_candidates = self.obs_to_state_ids[next_obs]\n",
    "                has_clone = any(self.states[cid].path==path for cid in next_candidates)\n",
    "                if not has_clone:\n",
    "                    self._clone_state(orig_state_id=next_candidates[0], path=path)\n",
    "        \n",
    "        # === Record edges (for viz) ===\n",
    "        context = None\n",
    "        for t in range(len(obs_seq)-1):\n",
    "            sid = self._select_state_for_obs(obs_seq[t], context)\n",
    "            nid = self._select_state_for_obs(obs_seq[t+1], context if sid not in self.salient else self.salient[sid])\n",
    "            self.edge_counts[(sid, nid)] += 1\n",
    "            if sid in self.salient:\n",
    "                context = self.salient[sid]\n",
    "            if obs_seq[t+1] in self.reset_symbols:\n",
    "                context = None\n",
    "        \n",
    "        return latent_seq\n",
    "    \n",
    "    # ---------- Evaluation helpers ----------\n",
    "    def encode_sequence(self, obs_seq: List[int]) -> np.ndarray:\n",
    "        # Return T x S one-hot occupancy of latent states for this sequence with current splitting (no learning).\n",
    "        lat = self.run_episode(obs_seq, learn=False)\n",
    "        S = max(self.states)+1\n",
    "        X = np.zeros((len(lat), S), dtype=float)\n",
    "        for t, sid in enumerate(lat):\n",
    "            X[t, sid] = 1.0\n",
    "        return X[:, :len(self.states)]  # in case ids are compact\n",
    "    \n",
    "    def near_far_corr(self, near_seq, far_seq) -> np.ndarray:\n",
    "        A = self.encode_sequence(near_seq)  # 26 x S\n",
    "        B = self.encode_sequence(far_seq)   # 26 x S\n",
    "        # Pearson correlation between rows of A and rows of B\n",
    "        C = np.zeros((A.shape[0], B.shape[0]))\n",
    "        for i in range(A.shape[0]):\n",
    "            for j in range(B.shape[0]):\n",
    "                a = A[i]; b = B[j]\n",
    "                if np.allclose(a,0) or np.allclose(b,0):\n",
    "                    C[i,j] = 0.0\n",
    "                else:\n",
    "                    # center\n",
    "                    a0 = a - a.mean(); b0 = b - b.mean()\n",
    "                    denom = (np.linalg.norm(a0)*np.linalg.norm(b0))\n",
    "                    C[i,j] = (a0@b0)/denom if denom>0 else 0.0\n",
    "        return C\n",
    "    \n",
    "    def graph_for_plot(self):\n",
    "        # Return a NetworkX DiGraph of current latent states and the observed episode-derived edges.\n",
    "        G = nx.DiGraph()\n",
    "        for sid, st in self.states.items():\n",
    "            label = f\"{sid}\\nobs={st.obs}\\n{st.path or 'base'}\"\n",
    "            color = {None:'#cccccc','R1':'#ff88aa','R2':'#88ccff'}[st.path]\n",
    "            G.add_node(sid, label=label, color=color, obs=st.obs, path=st.path)\n",
    "        # only show edges that were experienced\n",
    "        for (u,v), c in self.edge_counts.items():\n",
    "            if u in self.states and v in self.states:\n",
    "                G.add_edge(u,v, weight=c)\n",
    "        return G\n",
    "    \n",
    "# --- Hot‑patch for CoDAAgent: initialize contingency bookkeeping for clones ---\n",
    "def _ensure_state_keys(self, sid):\n",
    "    # Make sure internal counters exist for any state id\n",
    "    if sid not in self.co_occ:\n",
    "        self.co_occ[sid] = {u: 0.0 for u in self.us_classes}\n",
    "    if sid not in self.state_exposure:\n",
    "        self.state_exposure[sid] = 0.0\n",
    "\n",
    "def _clone_state_fixed(self, orig_state_id: int, path: str) -> int:\n",
    "    orig = self.states[orig_state_id]\n",
    "    clone_id = self._next_sid\n",
    "    clone = LatentState(id=clone_id, obs=orig.obs, path=path, parent=orig_state_id)\n",
    "    self.states[clone_id] = clone\n",
    "    self.obs_to_state_ids[orig.obs].append(clone_id)\n",
    "    # NEW: initialize contingency bookkeeping for the clone\n",
    "    _ensure_state_keys(self, clone_id)\n",
    "    self._next_sid += 1\n",
    "    return clone_id\n",
    "\n",
    "# Bind the helpers to the class (monkey-patch)\n",
    "CoDAAgent._ensure_state_keys = _ensure_state_keys\n",
    "CoDAAgent._clone_state = _clone_state_fixed\n",
    "\n",
    "# (Optional, defensive) If you want to “repair” an agent that already exists:\n",
    "def _repair_bookkeeping(self):\n",
    "    for s in list(self.states.keys()):\n",
    "        _ensure_state_keys(self, s)\n",
    "\n",
    "CoDAAgent._repair_bookkeeping = _repair_bookkeeping    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Train CoDA on randomized near/far episodes and evaluate\n",
    "\n",
    "We simulate multiple runs of learning. Each run has several sessions; within a session, we sample a randomized mix of near/far episodes, mirroring the experiment (both trial types, randomized order). After selected sessions we compute:\n",
    "\n",
    "- The near–far cross‑correlation matrix.\n",
    "- The block means for `offdiag`, `preR2`, `preR1`.\n",
    "- The earliest session where each block’s mean drops below the 0.3 threshold (Fig. 4j).\n",
    "\n",
    "You can adjust `N_RUNS`, `SESSIONS`, and `TRIALS_PER_SESSION` to match your compute budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Training params ====\n",
    "N_RUNS = 8\n",
    "SESSIONS = 9\n",
    "TRIALS_PER_SESSION = 80\n",
    "THRESH = 0.3\n",
    "\n",
    "def block_mean(C, pairs):\n",
    "    if len(pairs)==0: return np.nan\n",
    "    vals = [C[i,j] for (i,j) in pairs]\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "all_final_blocks = []   # (run, offdiag, preR2, preR1)\n",
    "time_to_thresh = []     # (run, offdiag_t, preR2_t, preR1_t) in [0,1]\n",
    "\n",
    "checkpoint_sessions = [1,3,4,9]  # to plot example matrices like Fig. 4d (optional)\n",
    "example_mats = {s: [] for s in checkpoint_sessions}\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    agent = CoDAAgent(obs_symbols=symbols, gamma=0.9, lam=0.8, theta_split=0.9, theta_merge=0.5)\n",
    "    tt = {'offdiag': None, 'preR2': None, 'preR1': None}\n",
    "    \n",
    "    for session in range(1, SESSIONS+1):\n",
    "        episodes = [near]*(TRIALS_PER_SESSION//2) + [far]*(TRIALS_PER_SESSION//2)\n",
    "        rng.shuffle(episodes)\n",
    "        for ep in episodes:\n",
    "            agent.run_episode(ep, learn=True)\n",
    "        \n",
    "        C = agent.near_far_corr(near, far)\n",
    "        if session in example_mats: example_mats[session].append(C)\n",
    "        \n",
    "        b_off = block_mean(C, offdiag_pairs)\n",
    "        b_r2  = block_mean(C, same_preR2_pairs)\n",
    "        b_r1  = block_mean(C, same_preR1_pairs)\n",
    "        \n",
    "        if tt['offdiag'] is None and b_off < THRESH: tt['offdiag'] = session\n",
    "        if tt['preR2']  is None and b_r2  < THRESH: tt['preR2']  = session\n",
    "        if tt['preR1']  is None and b_r1  < THRESH: tt['preR1']  = session\n",
    "    \n",
    "    C_final = agent.near_far_corr(near, far)\n",
    "    all_final_blocks.append((run, block_mean(C_final, offdiag_pairs),\n",
    "                                  block_mean(C_final, same_preR2_pairs),\n",
    "                                  block_mean(C_final, same_preR1_pairs)))\n",
    "    \n",
    "    def norm_t(x): \n",
    "        return (x/SESSIONS) if x is not None else np.nan\n",
    "    time_to_thresh.append((run, norm_t(tt['offdiag']), norm_t(tt['preR2']), norm_t(tt['preR1'])))\n",
    "\n",
    "blocks_df = pd.DataFrame(all_final_blocks, columns=['run','offdiag','preR2','preR1']).set_index('run')\n",
    "timet_df = pd.DataFrame(time_to_thresh, columns=['run','offdiag_t','preR2_t','preR1_t']).set_index('run')\n",
    "\n",
    "display(blocks_df.describe())\n",
    "display(timet_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Example near–far correlation matrices over learning (like Fig. 4d)\n",
    "\n",
    "We show the mean across runs at sessions 1, 3, 4, 9 for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_mats = {s: np.mean(example_mats[s], axis=0) for s in checkpoint_sessions}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(checkpoint_sessions), figsize=(4.5*len(checkpoint_sessions),4), constrained_layout=True)\n",
    "vmin, vmax = -0.1, 1.0\n",
    "for ax, s in zip(axes, checkpoint_sessions):\n",
    "    im = ax.imshow(mean_mats[s], vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
    "    ax.set_title(f\"Session {s}\")\n",
    "    ax.set_xlabel(\"Far position index\")\n",
    "    ax.set_ylabel(\"Near position index\")\n",
    "fig.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Fig. 4i analogue — final matrix block quantification (CoDA)\n",
    "\n",
    "Bars summarize the final near–far correlation matrix by **off‑diagonal**, **pre‑R2**, and **pre‑R1** blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "means = blocks_df.mean()\n",
    "ses   = blocks_df.sem()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels))\n",
    "y = [means[l] for l in labels]\n",
    "yerr = [ses[l] for l in labels]\n",
    "ax.bar(x, y, yerr=yerr, capsize=4)\n",
    "ax.set_xticks(x); ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Mean correlation (final)\")\n",
    "ax.set_title(\"CoDA — Fig. 4i analogue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Fig. 4j analogue — time to reach threshold (0.3)\n",
    "\n",
    "Bars show the fraction of training (sessions normalized to 1.0) until each block’s mean correlation first drops below **0.3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "means_t = timet_df.mean(skipna=True)\n",
    "ses_t   = timet_df.sem(skipna=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "labels = ['offdiag_t','preR2_t','preR1_t']\n",
    "disp_labels = ['offdiag','preR2','preR1']\n",
    "x = np.arange(len(labels))\n",
    "y = [means_t[l] for l in labels]\n",
    "yerr = [ses_t[l] for l in labels]\n",
    "ax.bar(x, y, yerr=yerr, capsize=4)\n",
    "ax.set_xticks(x); ax.set_xticklabels(disp_labels)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Fraction of training (to corr < 0.3)\")\n",
    "ax.set_title(\"CoDA — Fig. 4j analogue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Bonus — Fig. 4c analogue: CoDA’s final latent-state transition graph\n",
    "\n",
    "We plot the model’s final graph from one run (run 0). Nodes are colored by history path (base/near/far) and labeled by `(state id, obs, path)`. Edges are those experienced during training (thicker = more traversals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Re-train one agent (run 0) and then plot its graph\n",
    "agent = CoDAAgent(obs_symbols=symbols, gamma=0.9, lam=0.8, theta_split=0.9, theta_merge=0.5)\n",
    "rng = np.random.default_rng(0)\n",
    "for session in range(SESSIONS):\n",
    "    episodes = [near]*(TRIALS_PER_SESSION//2) + [far]*(TRIALS_PER_SESSION//2)\n",
    "    rng.shuffle(episodes)\n",
    "    for ep in episodes:\n",
    "        agent.run_episode(ep, learn=True)\n",
    "\n",
    "G = agent.graph_for_plot()\n",
    "\n",
    "# Lay out nodes roughly along the sequence order: sort by (path, obs) for a simple left-to-right layout\n",
    "pos = {}\n",
    "order_map = {None:0, 'R1':1, 'R2':2}\n",
    "sorted_nodes = sorted(G.nodes(data=True), key=lambda kv: (order_map[kv[1]['path']], kv[1]['obs'], kv[0]))\n",
    "for i,(nid,nd) in enumerate(sorted_nodes):\n",
    "    pos[nid] = (i, order_map[nd['path']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,3), constrained_layout=True)\n",
    "colors = [G.nodes[n]['color'] for n in G.nodes]\n",
    "nx.draw(G, pos, with_labels=False, node_color=colors, node_size=400, arrows=True, ax=ax, width=[max(0.5, G.edges[e].get('weight',1)/50.0) for e in G.edges])\n",
    "\n",
    "# add small text labels\n",
    "for n in G.nodes:\n",
    "    lab = G.nodes[n]['label']\n",
    "    ax.text(pos[n][0], pos[n][1]+0.1, lab, fontsize=7, ha='center')\n",
    "\n",
    "ax.set_title(\"CoDA final latent-state graph (one run)\")\n",
    "ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## (Optional) Overlay animal / CSCG bars\n",
    "\n",
    "If you have Sun et al.’s **Source Data** CSV for Fig. 4 or the CSCG notebook outputs, you can place them in a local folder and point `SOURCE_DATA_CSV` to it to overlay comparison bars. By default this cell does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example scaffold for overlay (disabled by default).\n",
    "SOURCE_DATA_CSV = None  # e.g., \"source_data/figure4_source_data.csv\"\n",
    "if SOURCE_DATA_CSV:\n",
    "    try:\n",
    "        src = pd.read_csv(SOURCE_DATA_CSV)\n",
    "        print(\"Loaded source data with\", len(src), \"rows\")\n",
    "        # Implement overlay if desired\n",
    "    except Exception as e:\n",
    "        print(\"Could not load source data:\", e)\n",
    "else:\n",
    "    print(\"No source data provided; showing CoDA-only figures.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notes & parameters\n",
    "- **CoDA params:** `gamma=0.9`, `lambda=0.8`, `theta_split=0.9`, `theta_merge=0.5` (Table 2 in the CoDA manuscript).\n",
    "- **Training harness:** `SESSIONS=9`, `TRIALS_PER_SESSION=80`, `N_RUNS=8` by default; increase for more stable error bars.\n",
    "- **Threshold for Fig. 4j:** `0.3`, as in Sun et al.’s Methods.\n",
    "- **Generalization of US:** we use `US∈{4,5}` (visual reward zone cues) so that the indicator is the earliest perfectly predictive cue; this is faithful to the CSCG simulation setup and avoids trivialities due to the shared water (`6`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coda-minigrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
